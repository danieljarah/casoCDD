{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antes de ejecutar este código es importante leer el archivo README de la carpeta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primero el dataset de logs_entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "logs_entrenamiento = pd.read_csv('logs_entrenamiento.csv')\n",
    "chapter = pd.read_csv('map_displayname_to_chap_seq_id.csv')\n",
    "notas = pd.read_csv('notas.csv')\n",
    "\n",
    "# Configuración de pandas\n",
    "pd.set_option('display.max_columns', None) # Que se muestren todas las columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede notar que los datos son de los momentos en que una persona interactúa con la página. Existen tipos de interacciones o eventos. Ellos están asociados a una persona, una momento en el tiempo y una sección (chapter) y subsección (sequential) de página."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                0\n",
       "username                  0\n",
       "time                      0\n",
       "event_type                0\n",
       "grouped_event_type        0\n",
       "chapter               31911\n",
       "sequential            31911\n",
       "label                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificamos existencia de NA's\n",
    "logs_entrenamiento.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que los NA estan asociados a las variables de chapter y sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 536610 entries, 0 to 536609\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   Unnamed: 0          536610 non-null  int64 \n",
      " 1   username            536610 non-null  object\n",
      " 2   time                536610 non-null  object\n",
      " 3   event_type          536610 non-null  object\n",
      " 4   grouped_event_type  536610 non-null  object\n",
      " 5   chapter             504699 non-null  object\n",
      " 6   sequential          504699 non-null  object\n",
      " 7   label               536610 non-null  int64 \n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 32.8+ MB\n"
     ]
    }
   ],
   "source": [
    "logs_entrenamiento.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edx.bi.course.upgrade.sidebarupsell.displayed' 'edx.ui.lms.link_clicked'\n",
      " 'edx.course.home.resume_course.clicked' 'edx.course.tool.accessed']\n"
     ]
    }
   ],
   "source": [
    "# Se busca los grouped_event_type asociados a chapter\n",
    "\n",
    "valores_unicos = logs_entrenamiento.loc[logs_entrenamiento['chapter'].isna(), 'grouped_event_type'].unique()\n",
    "print(valores_unicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edx.bi.course.upgrade.sidebarupsell.displayed' 'edx.ui.lms.link_clicked'\n",
      " 'edx.course.home.resume_course.clicked' 'edx.course.tool.accessed']\n"
     ]
    }
   ],
   "source": [
    "# Se busca los grouped_event_type asociados a sequential\n",
    "\n",
    "valores_unicos = logs_entrenamiento.loc[logs_entrenamiento['sequential'].isna(), 'grouped_event_type'].unique()\n",
    "print(valores_unicos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que los NA estan asociados a un tipo específico de dato, es decir, es probable que estos NA no se deban a una falta de un dato existente, sino que, el tipo de registro asociado a edx no posee chapter ni sequential. En consecuencia, se decide no eliminar los NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(logs_entrenamiento['username'], bins=500, edgecolor='black')  # 'bins' define el número de barras en el histograma\n",
    "\n",
    "# Personaliza el título y las etiquetas de los ejes\n",
    "plt.title('Cantidad de veces que un usuario interactuó')\n",
    "\n",
    "# Muestra el histograma\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la eliminación de outlayers, se debe notar que es posible que aquellas personas que menos interactúan con la página, sean las personas que tienen las peores notas. Por lo tanto, se decide eliminar a los outlayers superiores únicamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el número mínimo y máximo de registros basados en el 5% más extremo\n",
    "umbral_minimo = logs_entrenamiento['username'].value_counts().quantile(0.00)\n",
    "umbral_maximo = logs_entrenamiento['username'].value_counts().quantile(0.90)\n",
    "\n",
    "# Filtra el DataFrame para eliminar las filas correspondientes\n",
    "logs_entrenamiento_filtrado = logs_entrenamiento[logs_entrenamiento.groupby('username')['username'].transform('count').between(umbral_minimo, umbral_maximo)]\n",
    "\n",
    "# Se omite la exportación del csv para este notebook en particular\n",
    "#logs_entrenamiento_filtrado.to_csv('logs_entrenamiento_filtrado.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora el dataset de notas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se modifica Not Atempted por -1\n",
    "notas = notas.replace('Not Attempted', -1)\n",
    "\n",
    "for col in notas.columns:\n",
    "    columnas_listas = ['Unnamed: 0','Username','Grade','Grade Scaled','Quiz (Avg)']\n",
    "    if col in columnas_listas:\n",
    "        continue\n",
    "    \n",
    "    notas[col] = pd.to_numeric(notas[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 587 entries, 0 to 586\n",
      "Data columns (total 34 columns):\n",
      " #   Column                                             Non-Null Count  Dtype  \n",
      "---  ------                                             --------------  -----  \n",
      " 0   Unnamed: 0                                         587 non-null    int64  \n",
      " 1   Username                                           587 non-null    object \n",
      " 2   Grade                                              587 non-null    float64\n",
      " 3   Grade Scaled                                       587 non-null    float64\n",
      " 4   Quiz 1: Uso de modelos matemáticos en la economía  587 non-null    float64\n",
      " 5   Quiz 2: Motivación y Función de Producción         587 non-null    float64\n",
      " 6   Quiz 3: Preferencias y Toma de Decisiones          587 non-null    float64\n",
      " 7   Quiz 4: Salario y Efectos                          587 non-null    float64\n",
      " 8   Quiz 5: Explicando Diferencias y Conclusión        587 non-null    float64\n",
      " 9   Quiz 6: Introducción y conceptos iniciales         587 non-null    float64\n",
      " 10  Quiz 7: Prediciendo el resultado de un juego       587 non-null    float64\n",
      " 11  Quiz 8: Evaluación de Resultados                   587 non-null    float64\n",
      " 12  Quiz 9: Determinación de Asignaciones              587 non-null    float64\n",
      " 13  Quiz 10: Desigualdad                               587 non-null    float64\n",
      " 14  Quiz 11: Conceptos centrales                       587 non-null    float64\n",
      " 15  Quiz 12: Profundizando lo aprendido                587 non-null    float64\n",
      " 16  Quiz 13: Conceptos centrales                       587 non-null    float64\n",
      " 17  Quiz 14: Profundizando lo aprendido                587 non-null    float64\n",
      " 18  Quiz 15: Conceptos centrales                       587 non-null    float64\n",
      " 19  Quiz 16: Profundizando lo aprendido                587 non-null    float64\n",
      " 20  Quiz 17: Introducción                              587 non-null    int64  \n",
      " 21  Quiz 18: Oferta, demanda y equilibrio de mercado   587 non-null    float64\n",
      " 22  Quiz 19: Cambios en la oferta y la demanda         587 non-null    float64\n",
      " 23  Quiz 20: Excedentes y la mano invisible            587 non-null    float64\n",
      " 24  Quiz 21: Impuestos y Subsidios                     587 non-null    float64\n",
      " 25  Quiz 22: Eficiencia y externalidades               587 non-null    float64\n",
      " 26  Quiz 23: Corrección de fallas                      587 non-null    float64\n",
      " 27  Quiz 24: Otras fuentes de ineficiencia             587 non-null    float64\n",
      " 28  Quiz 25: Regla de la mayoría                       587 non-null    float64\n",
      " 29  Quiz 26: La paradoja de Condorcet                  587 non-null    float64\n",
      " 30  Quiz 27: Teorema del votante mediano               587 non-null    float64\n",
      " 31  Quiz 28: Decisiones intertemporales                587 non-null    float64\n",
      " 32  Quiz 29: Tópicos Adicionales                       587 non-null    float64\n",
      " 33  Quiz (Avg)                                         587 non-null    float64\n",
      "dtypes: float64(31), int64(2), object(1)\n",
      "memory usage: 156.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Se verifica que funcionó\n",
    "notas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                           0\n",
       "Username                                             0\n",
       "Grade                                                0\n",
       "Grade Scaled                                         0\n",
       "Quiz 1: Uso de modelos matemáticos en la economía    0\n",
       "Quiz 2: Motivación y Función de Producción           0\n",
       "Quiz 3: Preferencias y Toma de Decisiones            0\n",
       "Quiz 4: Salario y Efectos                            0\n",
       "Quiz 5: Explicando Diferencias y Conclusión          0\n",
       "Quiz 6: Introducción y conceptos iniciales           0\n",
       "Quiz 7: Prediciendo el resultado de un juego         0\n",
       "Quiz 8: Evaluación de Resultados                     0\n",
       "Quiz 9: Determinación de Asignaciones                0\n",
       "Quiz 10: Desigualdad                                 0\n",
       "Quiz 11: Conceptos centrales                         0\n",
       "Quiz 12: Profundizando lo aprendido                  0\n",
       "Quiz 13: Conceptos centrales                         0\n",
       "Quiz 14: Profundizando lo aprendido                  0\n",
       "Quiz 15: Conceptos centrales                         0\n",
       "Quiz 16: Profundizando lo aprendido                  0\n",
       "Quiz 17: Introducción                                0\n",
       "Quiz 18: Oferta, demanda y equilibrio de mercado     0\n",
       "Quiz 19: Cambios en la oferta y la demanda           0\n",
       "Quiz 20: Excedentes y la mano invisible              0\n",
       "Quiz 21: Impuestos y Subsidios                       0\n",
       "Quiz 22: Eficiencia y externalidades                 0\n",
       "Quiz 23: Corrección de fallas                        0\n",
       "Quiz 24: Otras fuentes de ineficiencia               0\n",
       "Quiz 25: Regla de la mayoría                         0\n",
       "Quiz 26: La paradoja de Condorcet                    0\n",
       "Quiz 27: Teorema del votante mediano                 0\n",
       "Quiz 28: Decisiones intertemporales                  0\n",
       "Quiz 29: Tópicos Adicionales                         0\n",
       "Quiz (Avg)                                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificamos existencia de NA's (No hay, se traspasó bien el type object a float)\n",
    "notas.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    587.0\n",
       "mean      -1.0\n",
       "std        0.0\n",
       "min       -1.0\n",
       "25%       -1.0\n",
       "50%       -1.0\n",
       "75%       -1.0\n",
       "max       -1.0\n",
       "Name: Quiz 17: Introducción, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# De la revisión del CSV, se observa que Quiz 17 contiene sólo casos 'No Atempted'\n",
    "notas['Quiz 17: Introducción'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos dicha columna\n",
    "notas = notas.drop('Quiz 17: Introducción', axis=1)    \n",
    "\n",
    "# Se observa que las columnas Grade y Grade Scaled contienen la misma información, se decide por querdarse con la original\n",
    "notas = notas.drop('Grade Scaled',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamiento de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Quiz 1: Uso de modelos matemáticos en la economía",
         "type": "histogram",
         "x": [
          0.75,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.75,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          0.75,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.75,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.75,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          -1,
          1,
          -1,
          0.75,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0.75,
          1,
          0.75,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.75,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.75,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0.75,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.75,
          0.75,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          0.5,
          -1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          0.75,
          -1,
          1,
          -1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          0.75,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.75,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          -1,
          1,
          0.75,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          -1,
          1,
          0.75,
          1,
          1,
          1,
          1,
          1,
          1,
          0.75,
          -1,
          0.75,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.75,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.75,
          1,
          1,
          1,
          1,
          0.75,
          1,
          1,
          0.75,
          -1,
          1,
          0.75,
          1,
          1,
          1,
          1,
          0.75,
          1,
          1,
          0.75,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          0.75,
          1,
          1,
          1,
          0.75,
          -1,
          1,
          1,
          -1,
          -1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.75,
          1,
          1,
          1,
          0.75,
          1,
          0.75,
          1,
          1,
          -1,
          -1,
          -1,
          -1,
          0.75,
          1,
          1,
          1,
          -1,
          0.75,
          -1,
          -1,
          1,
          -1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          -1,
          -1,
          -1,
          1,
          1,
          0.75,
          1,
          1,
          -1,
          -1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          0.75,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          0.75,
          1,
          -1,
          1,
          1,
          -1,
          -1,
          1,
          0.75,
          0.75,
          0.75,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1
         ],
         "xaxis": "x",
         "yaxis": "y"
        },
        {
         "name": "Quiz 2: Motivación y Función de Producción",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          0,
          -1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          -1,
          0,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1
         ],
         "xaxis": "x2",
         "yaxis": "y2"
        },
        {
         "name": "Quiz 3: Preferencias y Toma de Decisiones",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          -1,
          1,
          0,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1
         ],
         "xaxis": "x3",
         "yaxis": "y3"
        },
        {
         "name": "Quiz 4: Salario y Efectos",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          0,
          -1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          -1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          -1,
          -1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1
         ],
         "xaxis": "x4",
         "yaxis": "y4"
        },
        {
         "name": "Quiz 5: Explicando Diferencias y Conclusión",
         "type": "histogram",
         "x": [
          0,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          0,
          1,
          1,
          1,
          1,
          -1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          0,
          -1,
          0,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1,
          -1
         ],
         "xaxis": "x5",
         "yaxis": "y5"
        },
        {
         "name": "Quiz 6: Introducción y conceptos iniciales",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0,
          1,
          -1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1
         ],
         "xaxis": "x6",
         "yaxis": "y6"
        },
        {
         "name": "Quiz 7: Prediciendo el resultado de un juego",
         "type": "histogram",
         "x": [
          1,
          1,
          0.75,
          1,
          0.75,
          1,
          0.75,
          0.75,
          0.75,
          0.5,
          1,
          1,
          0.75,
          1,
          0.5,
          0.25,
          -1,
          1,
          1,
          0.75,
          0.25,
          1,
          1,
          0.75,
          1,
          1,
          1,
          1,
          0.25,
          1,
          0.75,
          1,
          0.75,
          0.75,
          0.5,
          1,
          0.75,
          1,
          0.75,
          1,
          1,
          1,
          0.25,
          0.25,
          1,
          1,
          1,
          0.25,
          1,
          1,
          0.75,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          0.5,
          0.25,
          0.75,
          1,
          0.75,
          1,
          0.75,
          0.25,
          1,
          0.5,
          1,
          1,
          1,
          0.5,
          1,
          0.5,
          0.75,
          0.5,
          0.75,
          0.75,
          0.75,
          0.75,
          1,
          1,
          0.75,
          1,
          1,
          0.75,
          0.5,
          0.75,
          1,
          0.5,
          0.75,
          1,
          0.5,
          1,
          1,
          0.75,
          0.75,
          0.5,
          1,
          1,
          1,
          0.5,
          0.75,
          0.25,
          0.25,
          0.75,
          1,
          1,
          1,
          0.5,
          0.5,
          1,
          0.5,
          0.75,
          1,
          0.75,
          1,
          0.75,
          1,
          1,
          0.75,
          1,
          1,
          1,
          1,
          1,
          0.75,
          0.75,
          1,
          1,
          1,
          0.5,
          1,
          0.5,
          0.5,
          1,
          -1,
          1,
          0.75,
          0.5,
          1,
          1,
          1,
          0.75,
          0.5,
          1,
          0,
          1,
          0.75,
          0.75,
          -1,
          1,
          0.75,
          1,
          1,
          0.75,
          1,
          1,
          0.75,
          1,
          0.75,
          -1,
          0.5,
          0.75,
          1,
          1,
          1,
          1,
          1,
          0.75,
          0.75,
          0.75,
          1,
          1,
          1,
          0.25,
          1,
          0.5,
          1,
          0.75,
          1,
          1,
          1,
          1,
          1,
          1,
          0.75,
          0.5,
          1,
          1,
          1,
          0.5,
          1,
          1,
          0.75,
          1,
          1,
          1,
          0.75,
          1,
          1,
          0.75,
          0.5,
          0.25,
          1,
          1,
          0.5,
          1,
          0.75,
          1,
          1,
          0.75,
          0.75,
          1,
          1,
          0.25,
          0.5,
          1,
          0.75,
          1,
          0.75,
          1,
          1,
          0.75,
          1,
          1,
          -1,
          0.5,
          1,
          1,
          1,
          0.5,
          1,
          -1,
          0.75,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.75,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          0.5,
          1,
          1,
          0.75,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.75,
          1,
          1,
          0.5,
          1,
          1,
          0.75,
          0.75,
          1,
          1,
          1,
          1,
          0.75,
          1,
          1,
          0.25,
          1,
          0.5,
          0.75,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          0.5,
          0.75,
          1,
          0.75,
          1,
          1,
          1,
          0.75,
          0,
          1,
          0.75,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          0.5,
          0.75,
          1,
          0.75,
          0.5,
          1,
          1,
          1,
          1,
          1,
          0.25,
          0.25,
          0.75,
          1,
          1,
          0.75,
          1,
          1,
          0.5,
          0.75,
          1,
          1,
          1,
          0.25,
          1,
          1,
          0.75,
          0.75,
          1,
          1,
          0,
          1,
          0.5,
          0.5,
          1,
          1,
          1,
          1,
          1,
          0.75,
          0.5,
          1,
          1,
          1,
          0.75,
          1,
          1,
          0.5,
          0.25,
          1,
          0.25,
          0.25,
          0.75,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          0.5,
          0.5,
          1,
          0.75,
          1,
          1,
          0.75,
          1,
          0.75,
          0.75,
          1,
          0.75,
          0.5,
          0.5,
          1,
          1,
          0.5,
          1,
          1,
          0.75,
          1,
          0.5,
          0.75,
          0.75,
          0.5,
          1,
          0.75,
          1,
          1,
          1,
          1,
          0.5,
          1,
          0.5,
          1,
          0.75,
          0.5,
          1,
          1,
          0.5,
          1,
          1,
          1,
          0.75,
          0.5,
          1,
          1,
          1,
          1,
          0.5,
          1,
          0.75,
          1,
          0,
          1,
          1,
          0.25,
          1,
          1,
          1,
          0.25,
          1,
          1,
          1,
          0.5,
          1,
          0.75,
          1,
          0.75,
          1,
          1,
          0.75,
          1,
          1,
          1,
          1,
          0.75,
          1,
          0.75,
          0.75,
          1,
          1,
          1,
          0.5,
          0.5,
          0.75,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          0.75,
          0.75,
          0.75,
          1,
          0.75,
          1,
          1,
          0.75,
          1,
          1,
          1,
          1,
          1,
          0.75,
          1,
          0.5,
          1,
          1,
          1,
          0.5,
          0.5,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          0.75,
          0.5,
          1,
          -1,
          1,
          1,
          0.75,
          1,
          1,
          0.5,
          1,
          0.75,
          0.5,
          1,
          1,
          0.75,
          1,
          0.75,
          1,
          1,
          0.5,
          1,
          0.75,
          0.5,
          1,
          0.5,
          0.75,
          1,
          1,
          1,
          1,
          0,
          0.75,
          1,
          1,
          0.25,
          1,
          1,
          1,
          1,
          0.25,
          1,
          -1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          0.75,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          -1,
          0.5,
          0.5,
          0.75,
          0.75,
          1,
          1,
          0.25,
          0.75,
          0.25,
          0.75,
          1,
          0.75,
          0.25,
          0.25,
          0.5,
          1,
          1,
          0.25,
          0.75,
          0.75,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1
         ],
         "xaxis": "x7",
         "yaxis": "y7"
        },
        {
         "name": "Quiz 8: Evaluación de Resultados",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          -1,
          -1,
          -1
         ],
         "xaxis": "x8",
         "yaxis": "y8"
        },
        {
         "name": "Quiz 9: Determinación de Asignaciones",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          0,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          -1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0,
          1,
          1,
          -1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          0,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          0,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          0,
          1,
          -1,
          1,
          -1,
          -1,
          -1
         ],
         "xaxis": "x9",
         "yaxis": "y9"
        },
        {
         "name": "Quiz 10: Desigualdad",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          0,
          1,
          -1,
          1,
          1,
          -1,
          1,
          -1,
          -1,
          -1
         ],
         "xaxis": "x10",
         "yaxis": "y10"
        },
        {
         "name": "Quiz 11: Conceptos centrales",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.33,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.33,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          0.67,
          0.67,
          1,
          1,
          -1,
          1,
          0.67,
          -1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          -1,
          1,
          0.33,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.33,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          0.67,
          1,
          0.67,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0.33,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.33,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          -1,
          1,
          1,
          0,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.33,
          0.67,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          0.67,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          -1
         ],
         "xaxis": "x11",
         "yaxis": "y11"
        },
        {
         "name": "Quiz 12: Profundizando lo aprendido",
         "type": "histogram",
         "x": [
          0.5,
          1,
          1,
          1,
          1,
          -1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0.5,
          0.5,
          1,
          1,
          1,
          1,
          0.5,
          -1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          0.5,
          0.5,
          1,
          1,
          1,
          -1,
          0.5,
          1,
          0.5,
          1,
          1,
          1,
          1,
          0.5,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          0.5,
          1,
          1,
          -1,
          1,
          0.5,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          0.5,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          -1,
          1,
          0.5,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          -1,
          1,
          0.5,
          1,
          1,
          -1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          0.5,
          1,
          1,
          0.5,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0.5,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          0.5,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          0,
          1,
          0.5,
          1,
          1,
          0.5,
          1,
          0.5,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.5,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          0.5,
          1,
          1,
          0.5,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          -1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          0.5,
          0.5,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          0.5,
          -1,
          -1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          0.5,
          -1,
          1,
          0.5,
          0.5,
          0.5,
          -1,
          -1
         ],
         "xaxis": "x12",
         "yaxis": "y12"
        },
        {
         "name": "Quiz 13: Conceptos centrales",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          0.5,
          1,
          0.5,
          0.5,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          0.5,
          -1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0.5,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          0.5,
          1,
          0.5,
          1,
          1,
          -1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          0.5,
          1,
          1,
          0.5,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          0.5,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          0.5,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          0.5,
          -1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1
         ],
         "xaxis": "x13",
         "yaxis": "y13"
        },
        {
         "name": "Quiz 14: Profundizando lo aprendido",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          0.5,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          -1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          0.5,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          0.5,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          -1,
          -1
         ],
         "xaxis": "x14",
         "yaxis": "y14"
        },
        {
         "name": "Quiz 15: Conceptos centrales",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          -1
         ],
         "xaxis": "x15",
         "yaxis": "y15"
        },
        {
         "name": "Quiz 16: Profundizando lo aprendido",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0.33,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          0.33,
          1,
          1,
          0.67,
          0.67,
          1,
          -1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          0.67,
          1,
          1,
          0.33,
          1,
          -1,
          1,
          1,
          -1,
          0.67,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          -1,
          0.33,
          1,
          0.67,
          1,
          1,
          -1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          -1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.33,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          0.67,
          0.67,
          1,
          1,
          -1,
          1,
          1,
          0.67,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          0.67,
          -1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          -1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          0.67,
          0.67,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.33,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          0.67,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          0.33,
          1,
          1,
          1,
          0.67,
          1,
          -1,
          0.67,
          1,
          0.67,
          -1,
          1,
          -1,
          1,
          1,
          1,
          0.67,
          1,
          0.33,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          0.67,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.33,
          0.67,
          -1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0.33,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          0.67,
          1,
          1,
          0.33,
          1,
          1,
          1,
          -1,
          1,
          0.67,
          1,
          -1,
          0.33,
          0.67,
          0,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          -1,
          1,
          0.67,
          0.67,
          1,
          1,
          1,
          0.67,
          -1,
          1,
          0.67,
          -1,
          -1
         ],
         "xaxis": "x16",
         "yaxis": "y16"
        },
        {
         "name": "Quiz 18: Oferta, demanda y equilibrio de mercado",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1
         ],
         "xaxis": "x17",
         "yaxis": "y17"
        },
        {
         "name": "Quiz 19: Cambios en la oferta y la demanda",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1
         ],
         "xaxis": "x18",
         "yaxis": "y18"
        },
        {
         "name": "Quiz 20: Excedentes y la mano invisible",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          -1,
          1,
          -1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          -1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          0,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          -1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0,
          1,
          1,
          -1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          -1,
          -1
         ],
         "xaxis": "x19",
         "yaxis": "y19"
        },
        {
         "name": "Quiz 21: Impuestos y Subsidios",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1
         ],
         "xaxis": "x20",
         "yaxis": "y20"
        },
        {
         "name": "Quiz 22: Eficiencia y externalidades",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          -1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          -1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          -1,
          -1,
          -1
         ],
         "xaxis": "x21",
         "yaxis": "y21"
        },
        {
         "name": "Quiz 23: Corrección de fallas",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          0.67,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          -1,
          0.67,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.33,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.33,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          0.67,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          -1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          0.33,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          0.67,
          1,
          0.67,
          1,
          0.67,
          1,
          1,
          1,
          1,
          0.33,
          1,
          1,
          1,
          0.67,
          1,
          -1,
          1,
          1,
          0.67,
          -1,
          1,
          0.67,
          1,
          1,
          1,
          0.33,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          0.67,
          -1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          0.67,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.33,
          1,
          1,
          1,
          0.67,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          0.67,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          0.67,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          0.67,
          -1,
          1,
          1,
          0.67,
          1,
          0.67,
          -1,
          1,
          1,
          1,
          -1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          0.67,
          1,
          1,
          0.67,
          1,
          1,
          1,
          -1,
          -1,
          0.67,
          -1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          0.33,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.67,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          -1
         ],
         "xaxis": "x22",
         "yaxis": "y22"
        },
        {
         "name": "Quiz 24: Otras fuentes de ineficiencia",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          -1
         ],
         "xaxis": "x23",
         "yaxis": "y23"
        },
        {
         "name": "Quiz 25: Regla de la mayoría",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          -1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          0.5,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          0.5,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          -1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          0.5,
          -1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          0.5,
          1,
          -1,
          0.5,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          0.5,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          -1,
          0.5,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.5,
          0.5,
          -1,
          0,
          1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          0.5,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          0,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          0.5,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.5,
          1,
          1,
          -1,
          1,
          1,
          1,
          0.5,
          0.5,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          -1,
          0.5,
          1,
          1,
          1,
          0.5,
          1,
          -1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          -1,
          -1
         ],
         "xaxis": "x24",
         "yaxis": "y24"
        },
        {
         "name": "Quiz 26: La paradoja de Condorcet",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          -1,
          1,
          1,
          -1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          0,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          -1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          -1,
          0,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0,
          -1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          0,
          0,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          -1,
          -1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          -1,
          -1
         ],
         "xaxis": "x25",
         "yaxis": "y25"
        },
        {
         "name": "Quiz 27: Teorema del votante mediano",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          -1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          -1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          -1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          -1,
          1,
          1,
          -1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          -1,
          1,
          0,
          0,
          -1,
          0,
          1,
          0,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          -1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          -1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          -1,
          0,
          1,
          1,
          0,
          0,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0,
          -1,
          0,
          1,
          -1,
          1,
          1,
          1,
          0,
          -1,
          0,
          0,
          1,
          1,
          -1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          -1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          0,
          1,
          1,
          1,
          1,
          -1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0,
          1,
          1,
          -1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          0,
          0,
          0,
          1,
          0,
          1,
          -1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          -1,
          -1,
          1,
          1,
          1,
          0,
          0,
          0,
          -1,
          -1,
          -1
         ],
         "xaxis": "x26",
         "yaxis": "y26"
        },
        {
         "name": "Quiz 28: Decisiones intertemporales",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          -1,
          1,
          1,
          0.5,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          -1,
          1,
          1,
          -1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.5,
          -1,
          -1,
          -1
         ],
         "xaxis": "x27",
         "yaxis": "y27"
        },
        {
         "name": "Quiz 29: Tópicos Adicionales",
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.5,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0.5,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          -1,
          0.5,
          1,
          1,
          1,
          1,
          -1,
          1,
          1,
          0,
          -1,
          -1,
          -1
         ],
         "xaxis": "x28",
         "yaxis": "y28"
        },
        {
         "name": "Quiz (Avg)",
         "type": "histogram",
         "x": [
          0.9051724137931034,
          0.9655172413793104,
          0.956896551724138,
          0.9655172413793104,
          0.4396551724137931,
          0.7586206896551724,
          0.8189655172413793,
          0.8506896551724139,
          0.7731034482758621,
          0.913793103448276,
          0.9655172413793104,
          0.9655172413793104,
          0.9224137931034484,
          0.896551724137931,
          0.9310344827586208,
          0.9051724137931034,
          0,
          0.9655172413793104,
          0.9541379310344827,
          0.956896551724138,
          0.6579310344827586,
          0.9655172413793104,
          0.956896551724138,
          0.75,
          0.9196551724137932,
          0.9310344827586208,
          0.9310344827586208,
          0.9655172413793104,
          0.8189655172413793,
          0.7586206896551724,
          0.853448275862069,
          0.7817241379310346,
          0.5662068965517242,
          0.853448275862069,
          0.9310344827586208,
          0.9655172413793104,
          0.75,
          0.9310344827586208,
          0.9224137931034484,
          0.9051724137931034,
          0.9655172413793104,
          0.9655172413793104,
          0.8824137931034484,
          0.7958620689655171,
          0.9541379310344827,
          0.9482758620689656,
          0.7931034482758621,
          0.8189655172413793,
          0.9655172413793104,
          0.9482758620689656,
          0.9224137931034484,
          0.8620689655172413,
          0.7989655172413793,
          0.896551724137931,
          0.7586206896551724,
          0.8562068965517241,
          0.8851724137931035,
          0.9655172413793104,
          0.8679310344827587,
          0.7903448275862069,
          0.7672413793103449,
          0.7586206896551724,
          0.956896551724138,
          0.9655172413793104,
          0.8420689655172414,
          0.7013793103448277,
          0.9655172413793104,
          0.8793103448275862,
          0.9310344827586208,
          0.9655172413793104,
          0.9655172413793104,
          0.8103448275862069,
          0.8275862068965517,
          0.8679310344827587,
          0.7789655172413793,
          0.8793103448275862,
          0.956896551724138,
          0.8820689655172413,
          0.8075862068965518,
          0.7155172413793104,
          0.9655172413793104,
          0.896551724137931,
          0.4051724137931034,
          0.873793103448276,
          0.7241379310344828,
          0.9224137931034484,
          0.833448275862069,
          0.8420689655172414,
          0.833448275862069,
          0.8448275862068966,
          0.9224137931034484,
          0.5172413793103449,
          0.8993103448275861,
          0.9655172413793104,
          0.8162068965517242,
          0.9396551724137931,
          0.9224137931034484,
          0.1896551724137931,
          0.9655172413793104,
          0.8679310344827587,
          0.9310344827586208,
          0.8910344827586207,
          0.7586206896551724,
          0.853448275862069,
          0.9310344827586208,
          0.8765517241379311,
          0.9655172413793104,
          0.9310344827586208,
          0.9424137931034482,
          0.7068965517241379,
          0.913793103448276,
          0.9655172413793104,
          0.9482758620689656,
          0.6927586206896552,
          0.8879310344827587,
          0.8879310344827587,
          0.9655172413793104,
          0.8706896551724138,
          0.8620689655172413,
          0.4827586206896552,
          0.9455172413793104,
          0.9655172413793104,
          0.9110344827586208,
          0.9655172413793104,
          0.9310344827586208,
          0.9655172413793104,
          0.853448275862069,
          0.9396551724137931,
          0.8448275862068966,
          0.9655172413793104,
          0.9310344827586208,
          0.9482758620689656,
          0.9655172413793104,
          0.7986206896551723,
          0.9482758620689656,
          0.7931034482758621,
          0.5575862068965518,
          0.9655172413793104,
          0.853448275862069,
          0.9024137931034484,
          0.9655172413793104,
          0.9655172413793104,
          0.9541379310344827,
          0.8706896551724138,
          0.8706896551724138,
          0.913793103448276,
          0.8620689655172413,
          0.8620689655172413,
          0.8248275862068966,
          0.8765517241379311,
          0.563103448275862,
          0.7931034482758621,
          0.956896551724138,
          0.9655172413793104,
          0.9655172413793104,
          0.9396551724137931,
          0.7875862068965518,
          0.936896551724138,
          0.7817241379310346,
          0.956896551724138,
          0.9396551724137931,
          0,
          0.8620689655172413,
          0.956896551724138,
          0.936896551724138,
          0.9196551724137932,
          0.9655172413793104,
          0.9310344827586208,
          0.9655172413793104,
          0.9051724137931034,
          0.853448275862069,
          0.8879310344827587,
          0.9655172413793104,
          0.8275862068965517,
          0.9482758620689656,
          0.7672413793103449,
          0.896551724137931,
          0.8793103448275862,
          0.9310344827586208,
          0.9455172413793104,
          0.936896551724138,
          0.9196551724137932,
          0.896551724137931,
          0.8506896551724139,
          0.7817241379310346,
          0.9482758620689656,
          0.8075862068965518,
          0.833448275862069,
          0.8620689655172413,
          0.7241379310344828,
          0.9310344827586208,
          0.8048275862068965,
          0.3103448275862069,
          0.9310344827586208,
          0.9282758620689656,
          0.9310344827586208,
          0.9541379310344827,
          0.9655172413793104,
          0.8593103448275863,
          0.7931034482758621,
          0.9051724137931034,
          0.8879310344827587,
          0.8048275862068967,
          0.7327586206896551,
          0.9541379310344827,
          0.8851724137931035,
          0.9482758620689656,
          0.913793103448276,
          0.8593103448275863,
          0.9655172413793104,
          0.9655172413793104,
          0.9110344827586208,
          0.853448275862069,
          0.9310344827586208,
          0.9655172413793104,
          0.8593103448275863,
          0.8793103448275862,
          0.9310344827586208,
          0.8679310344827587,
          0.8620689655172413,
          0.8824137931034484,
          0.8220689655172414,
          0.896551724137931,
          0.6810344827586207,
          0.896551724137931,
          0.9310344827586208,
          0,
          0.8103448275862069,
          0.8734482758620689,
          0.9655172413793104,
          0.9310344827586208,
          0.9482758620689656,
          0.5862068965517241,
          0.6955172413793104,
          0.9051724137931034,
          0.896551724137931,
          0.8620689655172413,
          0.9655172413793104,
          0.7931034482758621,
          0.9310344827586208,
          0.9655172413793104,
          0.9396551724137931,
          0.9310344827586208,
          0.8851724137931035,
          0.9310344827586208,
          0.9655172413793104,
          0.853448275862069,
          0.936896551724138,
          0.9655172413793104,
          0.9655172413793104,
          0.9541379310344827,
          0.7817241379310346,
          0.8793103448275862,
          0.8620689655172413,
          0.7586206896551724,
          0.9655172413793104,
          0.6348275862068964,
          0.8851724137931035,
          0.9655172413793104,
          0.913793103448276,
          0.9655172413793104,
          0.913793103448276,
          0.9655172413793104,
          0.9424137931034482,
          0.8793103448275862,
          0.9655172413793104,
          0.9110344827586208,
          0.9655172413793104,
          0.9310344827586208,
          0.7644827586206897,
          0.9655172413793104,
          0.896551724137931,
          0.9224137931034484,
          0.9224137931034484,
          0.8851724137931035,
          0.7931034482758621,
          0.9655172413793104,
          0.8275862068965517,
          0.8879310344827587,
          0.8448275862068966,
          0.8506896551724139,
          0.8189655172413793,
          0.9310344827586208,
          0.7127586206896552,
          0.8879310344827587,
          0.9110344827586208,
          0.9310344827586208,
          0.9655172413793104,
          0.6724137931034483,
          0.9655172413793104,
          0.9655172413793104,
          0.833448275862069,
          0.8793103448275862,
          0.7644827586206897,
          0.8879310344827587,
          0.9310344827586208,
          0.6982758620689655,
          0.9655172413793104,
          0.956896551724138,
          0.7068965517241379,
          0.8189655172413793,
          0.8275862068965517,
          0.8103448275862069,
          0.956896551724138,
          0.9655172413793104,
          0.853448275862069,
          0.896551724137931,
          0.9224137931034484,
          0.8103448275862069,
          0.9655172413793104,
          0.8275862068965517,
          0.7758620689655172,
          0.9110344827586208,
          0.9541379310344827,
          0.853448275862069,
          0.9482758620689656,
          0.9196551724137932,
          0.8275862068965517,
          0.9655172413793104,
          0.8679310344827587,
          0.9655172413793104,
          0.7444827586206898,
          0.9396551724137931,
          0.8362068965517241,
          0.9482758620689656,
          0.8162068965517242,
          0.9224137931034484,
          0.8506896551724139,
          0.913793103448276,
          0.7762068965517241,
          0.9224137931034484,
          0.9655172413793104,
          0.6551724137931034,
          0.7155172413793104,
          0.6693103448275862,
          0.9655172413793104,
          0.9655172413793104,
          0.9051724137931034,
          0.8306896551724139,
          0.9655172413793104,
          0.4482758620689655,
          0.8851724137931035,
          0.9655172413793104,
          0.8106896551724139,
          0.3103448275862069,
          0.9655172413793104,
          0.8506896551724139,
          0.9655172413793104,
          0.9541379310344827,
          0.9310344827586208,
          0.773103448275862,
          0.9482758620689656,
          0.6837931034482758,
          0.9655172413793104,
          0.9310344827586208,
          0.956896551724138,
          0.9655172413793104,
          0.8275862068965517,
          0.913793103448276,
          0.9396551724137931,
          0.9482758620689656,
          0.4627586206896552,
          0.7327586206896551,
          0.8248275862068966,
          0.956896551724138,
          0.7758620689655172,
          0.9655172413793104,
          0.9655172413793104,
          0.9255172413793104,
          0.7731034482758621,
          0.7586206896551724,
          0.8793103448275862,
          0.6810344827586207,
          0.9310344827586208,
          0.9655172413793104,
          0.7213793103448276,
          0.7472413793103448,
          0.9655172413793104,
          0.7844827586206896,
          0.9655172413793104,
          0.853448275862069,
          0.9282758620689656,
          0.9655172413793104,
          0.833448275862069,
          0.956896551724138,
          0.9655172413793104,
          0.8189655172413793,
          0.8793103448275862,
          0.8275862068965517,
          0.666896551724138,
          0.896551724137931,
          0.9482758620689656,
          0.9655172413793104,
          0.9310344827586208,
          0.6582758620689655,
          0.9655172413793104,
          0.8103448275862069,
          0.8765517241379311,
          0.7903448275862069,
          0.8275862068965517,
          0.956896551724138,
          0.1982758620689655,
          0.9655172413793104,
          0.896551724137931,
          0.956896551724138,
          0.7931034482758621,
          0.913793103448276,
          0.9310344827586208,
          0.4768965517241379,
          0.9310344827586208,
          0.956896551724138,
          0.913793103448276,
          0.9541379310344827,
          0.913793103448276,
          0.833448275862069,
          0.896551724137931,
          0.9655172413793104,
          0.8620689655172413,
          0.9110344827586208,
          0.8448275862068966,
          0.9655172413793104,
          0.9655172413793104,
          0.9655172413793104,
          0.9655172413793104,
          0.9482758620689656,
          0.9655172413793104,
          0.956896551724138,
          0.9110344827586208,
          0.8275862068965517,
          0.9310344827586208,
          0.7817241379310346,
          0.7644827586206897,
          0.9655172413793104,
          0.956896551724138,
          0.9079310344827586,
          0.8593103448275863,
          0.9310344827586208,
          0.8448275862068966,
          0.9310344827586208,
          0.896551724137931,
          0.956896551724138,
          0.5717241379310344,
          0.9196551724137932,
          0.5086206896551724,
          0.896551724137931,
          0.956896551724138,
          0.8765517241379311,
          0.8275862068965517,
          0.896551724137931,
          0.8620689655172413,
          0.6955172413793104,
          0.7386206896551725,
          0.9482758620689656,
          0.7844827586206896,
          0.9110344827586208,
          0.9655172413793104,
          0.9310344827586208,
          0.9655172413793104,
          0.896551724137931,
          0.8620689655172413,
          0.9224137931034484,
          0.7472413793103448,
          0.896551724137931,
          0.7068965517241379,
          0.9482758620689656,
          0.9655172413793104,
          0.9655172413793104,
          0.8275862068965517,
          0.7962068965517243,
          0.8765517241379311,
          0.9051724137931034,
          0.9310344827586208,
          0.8765517241379311,
          0.9310344827586208,
          0.913793103448276,
          0.8420689655172414,
          0.7586206896551724,
          0.913793103448276,
          0.7527586206896552,
          0.8275862068965517,
          0.9655172413793104,
          0.8593103448275863,
          0.9655172413793104,
          0.7817241379310346,
          0.9310344827586208,
          0.9310344827586208,
          0.9655172413793104,
          0.913793103448276,
          0.8506896551724139,
          0.7241379310344828,
          0.9655172413793104,
          0.9541379310344827,
          0.8765517241379311,
          0.2241379310344827,
          0.896551724137931,
          0.896551724137931,
          0.7041379310344829,
          0.913793103448276,
          0.9196551724137932,
          0,
          0.9310344827586208,
          0.8275862068965517,
          0.8879310344827587,
          0.6493103448275861,
          0.8793103448275862,
          0.7503448275862069,
          0.9310344827586208,
          0.8706896551724138,
          0.9310344827586208,
          0.9655172413793104,
          0.9655172413793104,
          0.7213793103448276,
          0.9655172413793104,
          0.9224137931034484,
          0.9310344827586208,
          0.9655172413793104,
          0.8048275862068967,
          0.6896551724137931,
          0.7586206896551724,
          0.9310344827586208,
          0.896551724137931,
          0.8448275862068966,
          0.8362068965517241,
          0.9310344827586208,
          0.8275862068965517,
          0.9655172413793104,
          0.75,
          0.7155172413793104,
          0.7413793103448276,
          0.9482758620689656,
          0.8620689655172413,
          0.7844827586206896,
          0.9655172413793104,
          0.7586206896551724,
          0.9655172413793104,
          0.9655172413793104,
          0.8075862068965518,
          0.9655172413793104,
          0.8103448275862069,
          0.9024137931034484,
          0.896551724137931,
          0.9655172413793104,
          0.7586206896551724,
          0.9655172413793104,
          0.9310344827586208,
          0.8620689655172413,
          0.5086206896551724,
          0.9310344827586208,
          0.5862068965517241,
          0.9196551724137932,
          0.7241379310344828,
          0.7758620689655172,
          0.9310344827586208,
          0.9310344827586208,
          0.7989655172413793,
          0.8620689655172413,
          0.896551724137931,
          0.9196551724137932,
          0.7413793103448276,
          0.1379310344827586,
          0.7931034482758621,
          0.7127586206896552,
          0.6637931034482759,
          0.9224137931034484,
          0.8793103448275862,
          0.603448275862069,
          0.146551724137931,
          0.7844827586206896,
          0.6062068965517241,
          0.8362068965517241,
          0.6841379310344827,
          0.75,
          0.7327586206896551,
          0.8017241379310345,
          0.5344827586206896,
          0.913793103448276,
          0.8162068965517242,
          0.7100000000000001,
          0.9224137931034484,
          0.6637931034482759,
          0.603448275862069,
          0.6437931034482759,
          0.5689655172413793,
          0.603448275862069,
          0.4541379310344827,
          0,
          0
         ],
         "xaxis": "x29",
         "yaxis": "y29"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 1: Uso de modelos matemáticos en la economía",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 2: Motivación y Función de Producción",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 3: Preferencias y Toma de Decisiones",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.9311111111111112,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 4: Salario y Efectos",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.9311111111111112,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 5: Explicando Diferencias y Conclusión",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.8622222222222222,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 6: Introducción y conceptos iniciales",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.8622222222222222,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 7: Prediciendo el resultado de un juego",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.7933333333333333,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 8: Evaluación de Resultados",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.7933333333333333,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 9: Determinación de Asignaciones",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.7244444444444444,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 10: Desigualdad",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.7244444444444444,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 11: Conceptos centrales",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6555555555555556,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 12: Profundizando lo aprendido",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6555555555555556,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 13: Conceptos centrales",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.5866666666666667,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 14: Profundizando lo aprendido",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.5866666666666667,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 15: Conceptos centrales",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.5177777777777778,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 16: Profundizando lo aprendido",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.5177777777777778,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 18: Oferta, demanda y equilibrio de mercado",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4488888888888889,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 19: Cambios en la oferta y la demanda",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4488888888888889,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 20: Excedentes y la mano invisible",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.38,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 21: Impuestos y Subsidios",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.38,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 22: Eficiencia y externalidades",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.3111111111111111,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 23: Corrección de fallas",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.3111111111111111,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 24: Otras fuentes de ineficiencia",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.24222222222222223,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 25: Regla de la mayoría",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.24222222222222223,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 26: La paradoja de Condorcet",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.17333333333333334,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 27: Teorema del votante mediano",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.17333333333333334,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 28: Decisiones intertemporales",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.10444444444444445,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz 29: Tópicos Adicionales",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.10444444444444445,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Quiz (Avg)",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.035555555555555556,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 4500,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribución de Puntuaciones por Cuestionario"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis10": {
         "anchor": "y10",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis11": {
         "anchor": "y11",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis12": {
         "anchor": "y12",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis13": {
         "anchor": "y13",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis14": {
         "anchor": "y14",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis15": {
         "anchor": "y15",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis16": {
         "anchor": "y16",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis17": {
         "anchor": "y17",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis18": {
         "anchor": "y18",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis19": {
         "anchor": "y19",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis20": {
         "anchor": "y20",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis21": {
         "anchor": "y21",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis22": {
         "anchor": "y22",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis23": {
         "anchor": "y23",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis24": {
         "anchor": "y24",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis25": {
         "anchor": "y25",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis26": {
         "anchor": "y26",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis27": {
         "anchor": "y27",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis28": {
         "anchor": "y28",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis29": {
         "anchor": "y29",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis30": {
         "anchor": "y30",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis7": {
         "anchor": "y7",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis8": {
         "anchor": "y8",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis9": {
         "anchor": "y9",
         "domain": [
          0,
          0.45
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.9644444444444444,
          1
         ]
        },
        "yaxis10": {
         "anchor": "x10",
         "domain": [
          0.6888888888888889,
          0.7244444444444444
         ]
        },
        "yaxis11": {
         "anchor": "x11",
         "domain": [
          0.62,
          0.6555555555555556
         ]
        },
        "yaxis12": {
         "anchor": "x12",
         "domain": [
          0.62,
          0.6555555555555556
         ]
        },
        "yaxis13": {
         "anchor": "x13",
         "domain": [
          0.5511111111111111,
          0.5866666666666667
         ]
        },
        "yaxis14": {
         "anchor": "x14",
         "domain": [
          0.5511111111111111,
          0.5866666666666667
         ]
        },
        "yaxis15": {
         "anchor": "x15",
         "domain": [
          0.4822222222222222,
          0.5177777777777778
         ]
        },
        "yaxis16": {
         "anchor": "x16",
         "domain": [
          0.4822222222222222,
          0.5177777777777778
         ]
        },
        "yaxis17": {
         "anchor": "x17",
         "domain": [
          0.41333333333333333,
          0.4488888888888889
         ]
        },
        "yaxis18": {
         "anchor": "x18",
         "domain": [
          0.41333333333333333,
          0.4488888888888889
         ]
        },
        "yaxis19": {
         "anchor": "x19",
         "domain": [
          0.34444444444444444,
          0.38
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.9644444444444444,
          1
         ]
        },
        "yaxis20": {
         "anchor": "x20",
         "domain": [
          0.34444444444444444,
          0.38
         ]
        },
        "yaxis21": {
         "anchor": "x21",
         "domain": [
          0.27555555555555555,
          0.3111111111111111
         ]
        },
        "yaxis22": {
         "anchor": "x22",
         "domain": [
          0.27555555555555555,
          0.3111111111111111
         ]
        },
        "yaxis23": {
         "anchor": "x23",
         "domain": [
          0.20666666666666667,
          0.24222222222222223
         ]
        },
        "yaxis24": {
         "anchor": "x24",
         "domain": [
          0.20666666666666667,
          0.24222222222222223
         ]
        },
        "yaxis25": {
         "anchor": "x25",
         "domain": [
          0.13777777777777778,
          0.17333333333333334
         ]
        },
        "yaxis26": {
         "anchor": "x26",
         "domain": [
          0.13777777777777778,
          0.17333333333333334
         ]
        },
        "yaxis27": {
         "anchor": "x27",
         "domain": [
          0.06888888888888889,
          0.10444444444444445
         ]
        },
        "yaxis28": {
         "anchor": "x28",
         "domain": [
          0.06888888888888889,
          0.10444444444444445
         ]
        },
        "yaxis29": {
         "anchor": "x29",
         "domain": [
          0,
          0.035555555555555556
         ]
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.8955555555555557,
          0.9311111111111112
         ]
        },
        "yaxis30": {
         "anchor": "x30",
         "domain": [
          0,
          0.035555555555555556
         ]
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0.8955555555555557,
          0.9311111111111112
         ]
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0.8266666666666667,
          0.8622222222222222
         ]
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0.8266666666666667,
          0.8622222222222222
         ]
        },
        "yaxis7": {
         "anchor": "x7",
         "domain": [
          0.7577777777777778,
          0.7933333333333333
         ]
        },
        "yaxis8": {
         "anchor": "x8",
         "domain": [
          0.7577777777777778,
          0.7933333333333333
         ]
        },
        "yaxis9": {
         "anchor": "x9",
         "domain": [
          0.6888888888888889,
          0.7244444444444444
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "notas_df = notas\n",
    "\n",
    "# Reemplaza 'Not Attempted' con -1 y convierte las cadenas a flotantes\n",
    "quiz_columns = [col for col in notas_df.columns if 'Quiz' in col]\n",
    "notas_df[quiz_columns] = notas_df[quiz_columns].replace('Not Attempted', -1).astype(float)\n",
    "\n",
    "# Determinamos el número de filas para los subplots\n",
    "n_rows = (len(quiz_columns) + 1) // 2\n",
    "\n",
    "# Crear una figura con subplots en dos columnas\n",
    "fig = make_subplots(rows=n_rows, cols=2, subplot_titles=quiz_columns)\n",
    "\n",
    "# Añadir un histograma para cada cuestionario en la posición adecuada\n",
    "for idx, col in enumerate(quiz_columns):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=notas_df[col], name=col),\n",
    "        row=(idx // 2) + 1,  # Incrementar la fila después de cada dos cuestionarios\n",
    "        col=(idx % 2) + 1    # Alternar entre columna 1 y 2\n",
    "    )\n",
    "\n",
    "# Actualizar el layout para que se ajuste bien\n",
    "fig.update_layout(\n",
    "    height=300 * n_rows,  # Ajustar la altura si es necesario para acomodar todos los subplots\n",
    "    title_text=\"Distribución de Puntuaciones por Cuestionario\",\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Mostrar la figura\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al analizar los datos se puede ver que las variables se encuentran distribuidas dentro de rangos esperados, es decir, dentro de (0,1) con valores ocasionales de -1, los cuales son los eventos en que un estudiante decidió no intentar el Quiz.\n",
    "\n",
    "En el caso excepcional del Quiz 1, se observa una alta tasa de No Atempt, esto se puede deber a que el curso está comenzando y que el primer quiz es sin nota y ademas introductorio a EOL.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.boxplot(x=notas['Grade'])\n",
    "plt.title('Box Plot de notas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que en el agregado de notas, se tiene una fuerte tendencia a centrarse entre el 0.8 y el 1.0, se decide no eliminar aquellos outliers que nunca respondieron ningún quiz, por lo que obtuvieron nota 0. Esto porque pueden contener información de si la persona pertenece a la clase a identificar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay 26 outliers, lo que representa aproximadamente el 4.43% del total de datos.\n",
    "Los límites para considerar un valor como atípico están dados por:\n",
    "Límite inferior : 0.655\n",
    "Límite superior : 1.175\n",
    "Esto significa que cualquier calificación por debajo de 0.655 se considera un outlier. Dado que la escala de calificaciones no ha sido especificada, asumimos que está entre 0 y 1, donde 1 es la calificación más alta posible.\n",
    "\n",
    "Las estadísticas descriptivas de los outliers son:\n",
    "\n",
    "Media (Mean): 0.41, lo que indica que en promedio, los outliers están por debajo del promedio general.\n",
    "Desviación estándar (Std): 0.25, lo que muestra una variabilidad considerable entre los valores atípicos.\n",
    "Mínimo (Min): 0.00, la calificación más baja posible, lo que sugiere que algunos estudiantes no obtuvieron ningún punto.\n",
    "Cuartiles (25%, 50%, 75%): Los valores de los cuartiles indican que la mitad de los outliers tiene calificaciones entre 0.2475 y 0.5975, lo que muestra que no todos los outliers están en el extremo más bajo.\n",
    "Este pequeño porcentaje de outliers podría representar casos de estudiantes que tuvieron un rendimiento significativamente por debajo del promedio.\n",
    "A partir de esto consideramos importante no eliminar estos outliers dado que representan personas con baja califacion, por lo cual puede ser importante en el modelo que estas personas sean parte de los datos, para que el modelo tambien aprenda de estos usuarios, que pueden ser parte importante de los que reprobaron el ramo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de los outliers encontrados en logs entrenamiento, los quitamos del dataframe de notas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtenemos los usuarios del df filtrados\n",
    "usernames_filtrados = set(logs_entrenamiento_filtrado['username'].unique())\n",
    "len(usernames_filtrados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtenemos los usuarios del df sin filtrar\n",
    "logs_entrenamiento = pd.read_csv('logs_entrenamiento.csv')\n",
    "usernames_sin_filtrar = set(logs_entrenamiento['username'].unique())\n",
    "len(usernames_sin_filtrar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usernames_diferencia = usernames_sin_filtrar - usernames_filtrados\n",
    "# Obtenemos los usuarios que fueron eliminados, es decir, los outliers del logs entrenamiento\n",
    "len(usernames_diferencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notas_df_filtrado = notas_df[~notas_df['Username'].isin(usernames_diferencia)]\n",
    "len(notas_df_filtrado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cruce de los datos y generación de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names of 'df': Index(['Unnamed: 0', 'Username', 'Grade',\n",
      "       'Quiz 1: Uso de modelos matemáticos en la economía',\n",
      "       'Quiz 2: Motivación y Función de Producción',\n",
      "       'Quiz 3: Preferencias y Toma de Decisiones',\n",
      "       'Quiz 4: Salario y Efectos',\n",
      "       'Quiz 5: Explicando Diferencias y Conclusión',\n",
      "       'Quiz 6: Introducción y conceptos iniciales',\n",
      "       'Quiz 7: Prediciendo el resultado de un juego',\n",
      "       'Quiz 8: Evaluación de Resultados',\n",
      "       'Quiz 9: Determinación de Asignaciones', 'Quiz 10: Desigualdad',\n",
      "       'Quiz 11: Conceptos centrales', 'Quiz 12: Profundizando lo aprendido',\n",
      "       'Quiz 13: Conceptos centrales', 'Quiz 14: Profundizando lo aprendido',\n",
      "       'Quiz 15: Conceptos centrales', 'Quiz 16: Profundizando lo aprendido',\n",
      "       'Quiz 18: Oferta, demanda y equilibrio de mercado',\n",
      "       'Quiz 19: Cambios en la oferta y la demanda',\n",
      "       'Quiz 20: Excedentes y la mano invisible',\n",
      "       'Quiz 21: Impuestos y Subsidios',\n",
      "       'Quiz 22: Eficiencia y externalidades', 'Quiz 23: Corrección de fallas',\n",
      "       'Quiz 24: Otras fuentes de ineficiencia',\n",
      "       'Quiz 25: Regla de la mayoría', 'Quiz 26: La paradoja de Condorcet',\n",
      "       'Quiz 27: Teorema del votante mediano',\n",
      "       'Quiz 28: Decisiones intertemporales', 'Quiz 29: Tópicos Adicionales',\n",
      "       'Quiz (Avg)'],\n",
      "      dtype='object')\n",
      "Column names of 'eventos': Index(['Unnamed: 0', 'username', 'time', 'event_type', 'grouped_event_type',\n",
      "       'chapter', 'sequential', 'label'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>username</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Quiz 1: Uso de modelos matemáticos en la economía</th>\n",
       "      <th>Quiz 2: Motivación y Función de Producción</th>\n",
       "      <th>Quiz 3: Preferencias y Toma de Decisiones</th>\n",
       "      <th>Quiz 4: Salario y Efectos</th>\n",
       "      <th>Quiz 5: Explicando Diferencias y Conclusión</th>\n",
       "      <th>Quiz 6: Introducción y conceptos iniciales</th>\n",
       "      <th>Quiz 7: Prediciendo el resultado de un juego</th>\n",
       "      <th>Quiz 8: Evaluación de Resultados</th>\n",
       "      <th>Quiz 9: Determinación de Asignaciones</th>\n",
       "      <th>Quiz 10: Desigualdad</th>\n",
       "      <th>Quiz 11: Conceptos centrales</th>\n",
       "      <th>Quiz 12: Profundizando lo aprendido</th>\n",
       "      <th>Quiz 13: Conceptos centrales</th>\n",
       "      <th>Quiz 14: Profundizando lo aprendido</th>\n",
       "      <th>Quiz 15: Conceptos centrales</th>\n",
       "      <th>Quiz 16: Profundizando lo aprendido</th>\n",
       "      <th>Quiz 18: Oferta, demanda y equilibrio de mercado</th>\n",
       "      <th>Quiz 19: Cambios en la oferta y la demanda</th>\n",
       "      <th>Quiz 20: Excedentes y la mano invisible</th>\n",
       "      <th>Quiz 21: Impuestos y Subsidios</th>\n",
       "      <th>Quiz 22: Eficiencia y externalidades</th>\n",
       "      <th>Quiz 23: Corrección de fallas</th>\n",
       "      <th>Quiz 24: Otras fuentes de ineficiencia</th>\n",
       "      <th>Quiz 25: Regla de la mayoría</th>\n",
       "      <th>Quiz 26: La paradoja de Condorcet</th>\n",
       "      <th>Quiz 27: Teorema del votante mediano</th>\n",
       "      <th>Quiz 28: Decisiones intertemporales</th>\n",
       "      <th>Quiz 29: Tópicos Adicionales</th>\n",
       "      <th>Quiz (Avg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>05743498d061bf472df897f1e5bdda6d62e99312c952e3...</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.905172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2fb73a5b451fa1beba6a7e6c86cf66ab3d8bfa3fc256bb...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>c5f32ddce577c3f4cce3bcdcb5c8e0e03933b5cc62fa18...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>81528304670b5be911641ecc2ba3a21195234d10c3ab43...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>4427f64ffb5a05abefc1aa6936fca72e2f8fc24ad5f11d...</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.439655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           username  Grade  \\\n",
       "0           3  05743498d061bf472df897f1e5bdda6d62e99312c952e3...   0.94   \n",
       "1           4  2fb73a5b451fa1beba6a7e6c86cf66ab3d8bfa3fc256bb...   1.00   \n",
       "2           5  c5f32ddce577c3f4cce3bcdcb5c8e0e03933b5cc62fa18...   0.99   \n",
       "3           6  81528304670b5be911641ecc2ba3a21195234d10c3ab43...   1.00   \n",
       "4           7  4427f64ffb5a05abefc1aa6936fca72e2f8fc24ad5f11d...   0.91   \n",
       "\n",
       "   Quiz 1: Uso de modelos matemáticos en la economía  \\\n",
       "0                                               0.75   \n",
       "1                                               1.00   \n",
       "2                                               1.00   \n",
       "3                                               1.00   \n",
       "4                                              -1.00   \n",
       "\n",
       "   Quiz 2: Motivación y Función de Producción  \\\n",
       "0                                         1.0   \n",
       "1                                         1.0   \n",
       "2                                         1.0   \n",
       "3                                         1.0   \n",
       "4                                         1.0   \n",
       "\n",
       "   Quiz 3: Preferencias y Toma de Decisiones  Quiz 4: Salario y Efectos  \\\n",
       "0                                        1.0                        1.0   \n",
       "1                                        1.0                        1.0   \n",
       "2                                        1.0                        1.0   \n",
       "3                                        1.0                        1.0   \n",
       "4                                        1.0                        1.0   \n",
       "\n",
       "   Quiz 5: Explicando Diferencias y Conclusión  \\\n",
       "0                                          0.0   \n",
       "1                                          1.0   \n",
       "2                                          1.0   \n",
       "3                                          1.0   \n",
       "4                                          1.0   \n",
       "\n",
       "   Quiz 6: Introducción y conceptos iniciales  \\\n",
       "0                                         1.0   \n",
       "1                                         1.0   \n",
       "2                                         1.0   \n",
       "3                                         1.0   \n",
       "4                                         1.0   \n",
       "\n",
       "   Quiz 7: Prediciendo el resultado de un juego  \\\n",
       "0                                          1.00   \n",
       "1                                          1.00   \n",
       "2                                          0.75   \n",
       "3                                          1.00   \n",
       "4                                          0.75   \n",
       "\n",
       "   Quiz 8: Evaluación de Resultados  Quiz 9: Determinación de Asignaciones  \\\n",
       "0                               1.0                                    1.0   \n",
       "1                               1.0                                    1.0   \n",
       "2                               1.0                                    1.0   \n",
       "3                               1.0                                    1.0   \n",
       "4                               1.0                                    1.0   \n",
       "\n",
       "   Quiz 10: Desigualdad  Quiz 11: Conceptos centrales  \\\n",
       "0                   1.0                           1.0   \n",
       "1                   1.0                           1.0   \n",
       "2                   1.0                           1.0   \n",
       "3                   1.0                           1.0   \n",
       "4                   1.0                           1.0   \n",
       "\n",
       "   Quiz 12: Profundizando lo aprendido  Quiz 13: Conceptos centrales  \\\n",
       "0                                  0.5                           1.0   \n",
       "1                                  1.0                           1.0   \n",
       "2                                  1.0                           1.0   \n",
       "3                                  1.0                           1.0   \n",
       "4                                  1.0                           1.0   \n",
       "\n",
       "   Quiz 14: Profundizando lo aprendido  Quiz 15: Conceptos centrales  \\\n",
       "0                                  1.0                           1.0   \n",
       "1                                  1.0                           1.0   \n",
       "2                                  1.0                           1.0   \n",
       "3                                  1.0                           1.0   \n",
       "4                                  1.0                          -1.0   \n",
       "\n",
       "   Quiz 16: Profundizando lo aprendido  \\\n",
       "0                                  1.0   \n",
       "1                                  1.0   \n",
       "2                                  1.0   \n",
       "3                                  1.0   \n",
       "4                                 -1.0   \n",
       "\n",
       "   Quiz 18: Oferta, demanda y equilibrio de mercado  \\\n",
       "0                                               1.0   \n",
       "1                                               1.0   \n",
       "2                                               1.0   \n",
       "3                                               1.0   \n",
       "4                                              -1.0   \n",
       "\n",
       "   Quiz 19: Cambios en la oferta y la demanda  \\\n",
       "0                                         1.0   \n",
       "1                                         1.0   \n",
       "2                                         1.0   \n",
       "3                                         1.0   \n",
       "4                                        -1.0   \n",
       "\n",
       "   Quiz 20: Excedentes y la mano invisible  Quiz 21: Impuestos y Subsidios  \\\n",
       "0                                      1.0                             1.0   \n",
       "1                                      1.0                             1.0   \n",
       "2                                      1.0                             1.0   \n",
       "3                                      1.0                             1.0   \n",
       "4                                     -1.0                            -1.0   \n",
       "\n",
       "   Quiz 22: Eficiencia y externalidades  Quiz 23: Corrección de fallas  \\\n",
       "0                                   1.0                            1.0   \n",
       "1                                   1.0                            1.0   \n",
       "2                                   1.0                            1.0   \n",
       "3                                   1.0                            1.0   \n",
       "4                                  -1.0                           -1.0   \n",
       "\n",
       "   Quiz 24: Otras fuentes de ineficiencia  Quiz 25: Regla de la mayoría  \\\n",
       "0                                     1.0                           1.0   \n",
       "1                                     1.0                           1.0   \n",
       "2                                     1.0                           1.0   \n",
       "3                                     1.0                           1.0   \n",
       "4                                    -1.0                          -1.0   \n",
       "\n",
       "   Quiz 26: La paradoja de Condorcet  Quiz 27: Teorema del votante mediano  \\\n",
       "0                                1.0                                   1.0   \n",
       "1                                1.0                                   1.0   \n",
       "2                                1.0                                   1.0   \n",
       "3                                1.0                                   1.0   \n",
       "4                               -1.0                                  -1.0   \n",
       "\n",
       "   Quiz 28: Decisiones intertemporales  Quiz 29: Tópicos Adicionales  \\\n",
       "0                                  1.0                           1.0   \n",
       "1                                  1.0                           1.0   \n",
       "2                                  1.0                           1.0   \n",
       "3                                  1.0                           1.0   \n",
       "4                                 -1.0                          -1.0   \n",
       "\n",
       "   Quiz (Avg)  \n",
       "0    0.905172  \n",
       "1    0.965517  \n",
       "2    0.956897  \n",
       "3    0.965517  \n",
       "4    0.439655  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventos = logs_entrenamiento_filtrado.copy()\n",
    "\n",
    "notas = notas_df_filtrado.copy()\n",
    "\n",
    "column_names_df = notas.columns\n",
    "\n",
    "\n",
    "column_names_eventos = eventos.columns\n",
    "\n",
    "# Print the column names\n",
    "print(\"Column names of 'df':\", column_names_df)\n",
    "print(\"Column names of 'eventos':\", column_names_eventos)\n",
    "\n",
    "# Rename a single column\n",
    "notas.rename(columns={'Username': 'username'}, inplace=True)\n",
    "\n",
    "notas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Group 0: ['Quiz 2: Motivación y Función de Producción'\\n 'Quiz 6: Introducción y conceptos iniciales'\\n 'Quiz 8: Evaluación de Resultados' 'Quiz 17: Introducción'\\n 'Quiz 25: Regla de la mayoría']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Group 1: ['Quiz 1: Uso de modelos matemáticos en la economía'\\n 'Quiz 3: Preferencias y Toma de Decisiones'\\n 'Quiz 7: Prediciendo el resultado de un juego'\\n 'Quiz 9: Determinación de Asignaciones' 'Quiz 11: Conceptos centrales'\\n 'Quiz 13: Conceptos centrales' 'Quiz 15: Conceptos centrales'\\n 'Quiz 18: Oferta, demanda y equilibrio de mercado'\\n 'Quiz 22: Eficiencia y externalidades'\\n 'Quiz 26: La paradoja de Condorcet' 'Quiz 28: Decisiones intertemporales']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Group 2: ['Quiz 4: Salario y Efectos' 'Quiz 10: Desigualdad'\\n 'Quiz 12: Profundizando lo aprendido'\\n 'Quiz 14: Profundizando lo aprendido'\\n 'Quiz 16: Profundizando lo aprendido'\\n 'Quiz 19: Cambios en la oferta y la demanda'\\n 'Quiz 23: Corrección de fallas' 'Quiz 27: Teorema del votante mediano'\\n 'Quiz 29: Tópicos Adicionales']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Group 3: ['Quiz 5: Explicando Diferencias y Conclusión'\\n 'Quiz 20: Excedentes y la mano invisible'\\n 'Quiz 24: Otras fuentes de ineficiencia']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Group 4: ['Quiz 21: Impuestos y Subsidios']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#RENOMBRAMOS COLUMNAS\n",
    "notas.rename(columns={'Grade': 'grade', 'Grade Scaled': 'grade_scaled', 'Quiz (Avg)': 'quiz_avg', 'Unnamed: 0': 'unnamed'}, inplace=True)\n",
    "\n",
    "\n",
    "#QUIZZES DE LAS SEQ\n",
    "# Agrupar los datos por 'chap_order' e imprimir los valores únicos de 'display_name' para cada grupo\n",
    "grouped = chapter.groupby('seq_order')['display_name'].unique()\n",
    "\n",
    "for chap_order, unique_display_names in grouped.items():\n",
    "    display(f'Group {chap_order}: {unique_display_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte se encuentran aquellos quizzes que pertenecen a un mismo valor de la columna sequential, luego de agruparlos se les toma el promedio y luego se eliminan las columnas originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unnamed</th>\n",
       "      <th>username</th>\n",
       "      <th>grade</th>\n",
       "      <th>seq_4_avg</th>\n",
       "      <th>quiz_avg</th>\n",
       "      <th>seq_0_avg</th>\n",
       "      <th>seq_1_avg</th>\n",
       "      <th>seq_2_avg</th>\n",
       "      <th>seq_3_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>05743498d061bf472df897f1e5bdda6d62e99312c952e3...</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2fb73a5b451fa1beba6a7e6c86cf66ab3d8bfa3fc256bb...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>c5f32ddce577c3f4cce3bcdcb5c8e0e03933b5cc62fa18...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>81528304670b5be911641ecc2ba3a21195234d10c3ab43...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>4427f64ffb5a05abefc1aa6936fca72e2f8fc24ad5f11d...</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.439655</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>afca888290f061f966a5f4ab433b53ac73734e00bdfce6...</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>95ee01a5a7e3c41023fc379d6acb0f47860f2149caacb1...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.818966</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>61d11a14e95e598a883d48aea410c474ca6f419ee8a5b0...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.850690</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.907778</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>4f824a96d26c45a3e047fd26f1f164371e86b4cab53895...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.773103</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.518889</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>ef14776d7e8bc0b6ad12b59d9b12e2d742e962dfc415b0...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unnamed                                           username  grade  \\\n",
       "0        3  05743498d061bf472df897f1e5bdda6d62e99312c952e3...   0.94   \n",
       "1        4  2fb73a5b451fa1beba6a7e6c86cf66ab3d8bfa3fc256bb...   1.00   \n",
       "2        5  c5f32ddce577c3f4cce3bcdcb5c8e0e03933b5cc62fa18...   0.99   \n",
       "3        6  81528304670b5be911641ecc2ba3a21195234d10c3ab43...   1.00   \n",
       "4        7  4427f64ffb5a05abefc1aa6936fca72e2f8fc24ad5f11d...   0.91   \n",
       "5        8  afca888290f061f966a5f4ab433b53ac73734e00bdfce6...   0.79   \n",
       "6        9  95ee01a5a7e3c41023fc379d6acb0f47860f2149caacb1...   0.85   \n",
       "7       10  61d11a14e95e598a883d48aea410c474ca6f419ee8a5b0...   0.88   \n",
       "8       12  4f824a96d26c45a3e047fd26f1f164371e86b4cab53895...   0.80   \n",
       "9       13  ef14776d7e8bc0b6ad12b59d9b12e2d742e962dfc415b0...   0.95   \n",
       "\n",
       "   seq_4_avg  quiz_avg  seq_0_avg  seq_1_avg  seq_2_avg  seq_3_avg  \n",
       "0        1.0  0.905172      1.000   0.977273   0.944444   0.666667  \n",
       "1        1.0  0.965517      1.000   1.000000   1.000000   1.000000  \n",
       "2        1.0  0.956897      1.000   0.977273   1.000000   1.000000  \n",
       "3        1.0  0.965517      1.000   1.000000   1.000000   1.000000  \n",
       "4       -1.0  0.439655      0.500  -0.113636  -0.111111  -0.333333  \n",
       "5        1.0  0.758621      0.500   0.636364   0.555556   0.333333  \n",
       "6       -1.0  0.818966      1.000   0.795455   0.777778   0.333333  \n",
       "7        1.0  0.850690      0.625   0.909091   0.907778   1.000000  \n",
       "8        1.0  0.773103      1.000   0.795455   0.518889   0.666667  \n",
       "9        1.0  0.913793      1.000   0.772727   1.000000   1.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se convierten las columnas a tipo numérico\n",
    "columns_to_convert_seq_0 = ['Quiz 2: Motivación y Función de Producción',\n",
    "                            'Quiz 6: Introducción y conceptos iniciales',\n",
    "                            'Quiz 8: Evaluación de Resultados', \n",
    "                            'Quiz 25: Regla de la mayoría']\n",
    "\n",
    "notas[columns_to_convert_seq_0] = notas[columns_to_convert_seq_0].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Calcular el promedio para las columnas\n",
    "notas['seq_0_avg'] = notas[columns_to_convert_seq_0].mean(axis=1)\n",
    "\n",
    "# Eliminar las columnas originales\n",
    "notas.drop(columns=columns_to_convert_seq_0, inplace=True)\n",
    "\n",
    "# Repetir los pasos anteriores para las demás columnas\n",
    "columns_to_convert_seq_1 = ['Quiz 1: Uso de modelos matemáticos en la economía',\n",
    "                            'Quiz 3: Preferencias y Toma de Decisiones',\n",
    "                            'Quiz 7: Prediciendo el resultado de un juego',\n",
    "                            'Quiz 9: Determinación de Asignaciones',\n",
    "                            'Quiz 11: Conceptos centrales',\n",
    "                            'Quiz 13: Conceptos centrales',\n",
    "                            'Quiz 15: Conceptos centrales',\n",
    "                            'Quiz 18: Oferta, demanda y equilibrio de mercado',\n",
    "                            'Quiz 22: Eficiencia y externalidades',\n",
    "                            'Quiz 26: La paradoja de Condorcet',\n",
    "                            'Quiz 28: Decisiones intertemporales']\n",
    "\n",
    "notas[columns_to_convert_seq_1] = notas[columns_to_convert_seq_1].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "notas['seq_1_avg'] = notas[columns_to_convert_seq_1].mean(axis=1)\n",
    "notas.drop(columns=columns_to_convert_seq_1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# For seq_2\n",
    "columns_to_convert_seq_2 = ['Quiz 4: Salario y Efectos', 'Quiz 10: Desigualdad',\n",
    "                            'Quiz 12: Profundizando lo aprendido',\n",
    "                            'Quiz 14: Profundizando lo aprendido',\n",
    "                            'Quiz 16: Profundizando lo aprendido',\n",
    "                            'Quiz 19: Cambios en la oferta y la demanda',\n",
    "                            'Quiz 23: Corrección de fallas',\n",
    "                            'Quiz 27: Teorema del votante mediano',\n",
    "                            'Quiz 29: Tópicos Adicionales']\n",
    "\n",
    "notas[columns_to_convert_seq_2] = notas[columns_to_convert_seq_2].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "notas['seq_2_avg'] = notas[columns_to_convert_seq_2].mean(axis=1)\n",
    "notas.drop(columns=columns_to_convert_seq_2, inplace=True)\n",
    "\n",
    "# For seq_3\n",
    "columns_to_convert_seq_3 = ['Quiz 5: Explicando Diferencias y Conclusión',\n",
    "                            'Quiz 20: Excedentes y la mano invisible',\n",
    "                            'Quiz 24: Otras fuentes de ineficiencia']\n",
    "\n",
    "notas[columns_to_convert_seq_3] = notas[columns_to_convert_seq_3].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "notas['seq_3_avg'] = notas[columns_to_convert_seq_3].mean(axis=1)\n",
    "notas.drop(columns=columns_to_convert_seq_3, inplace=True)\n",
    "\n",
    "\n",
    "notas.rename(columns={'Quiz 21: Impuestos y Subsidios': 'seq_4_avg'}, inplace=True)\n",
    "\n",
    "notas.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente chunk de código se define que una sesión corresponde a un día con registro de ingreso. Con esto se calcula el promedio de la duración de las sesiones, la desviación estándar de la duración de las sesiones y la duración en días del uso de EOL, es decir, la diferencia en días entre su último día utilizando la plataforma y el primero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unnamed', 'username', 'grade', 'seq_4_avg', 'quiz_avg', 'seq_0_avg', 'seq_1_avg', 'seq_2_avg', 'seq_3_avg', 'duracion_sesion_avg', 'duracion_sesion_std', 'duracion_EOL']\n"
     ]
    }
   ],
   "source": [
    "#ACÁ SE TOMA INFO DE LOG_TRAIN PARA SUPLIR LA DATA DE NOTAS\n",
    "\n",
    "\n",
    "# Convert the 'time_column' to a datetime object\n",
    "eventos['time'] = pd.to_datetime(eventos['time'])\n",
    "\n",
    "# Create new columns for month, day, and time\n",
    "eventos['month'] = eventos['time'].dt.month\n",
    "eventos['day'] = eventos['time'].dt.day\n",
    "eventos['hora'] = eventos['time'].dt.strftime('%H:%M:%S')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------\n",
    "\n",
    "# DURACION DE SESIONES (una sesion es un día con registro de ingreso)\n",
    "\n",
    "# Group the DataFrame by 'usuario', 'month', and 'day' and calculate the min and max time\n",
    "grouped = eventos.groupby(['username', 'month', 'day'])['time'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "#\n",
    "grouped['time_difference'] = (grouped['max'] - grouped['min']).dt.total_seconds() / 3600\n",
    "\n",
    "# Merge the 'time_difference' column from the 'grouped' DataFrame into the 'eventos' DataFrame\n",
    "eventos = eventos.merge(grouped[['username', 'month', 'day', 'time_difference']], on=['username', 'month', 'day'], how='left')\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------\n",
    "\n",
    "#ESTADISTICOS DE DUACION DE SESIONES\n",
    "\n",
    "# Group the DataFrame by 'usuarioname' and calculate the average and standard deviation of 'time_difference'\n",
    "grouped = eventos.groupby('username')['time_difference'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "grouped.columns = ['username', 'duracion_sesion_avg', 'duracion_sesion_std']\n",
    "\n",
    "#Agregarlo a la data final\n",
    "notas = notas.merge(grouped[['username', 'duracion_sesion_avg', 'duracion_sesion_std']].drop_duplicates(), on='username', how='left')\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------\n",
    "\n",
    "#DURACION EN DÍAS DE SU USO DE EOL\n",
    "\n",
    "# Extract the date part\n",
    "eventos['date'] = eventos['time'].dt.date\n",
    "\n",
    "# Group the DataFrame by 'usuario', 'month', and 'day' and calculate the min and max time\n",
    "grouped = eventos.groupby(['username'])['date'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "# Calculate the time difference in hours\n",
    "grouped['duracion_EOL'] = (grouped['max'] - grouped['min']).dt.days\n",
    "\n",
    "#Agregarlo a la data final\n",
    "notas = notas.merge(grouped[['username', 'duracion_EOL']].drop_duplicates(), on='username', how='left')\n",
    "\n",
    "\n",
    "column_names = notas.columns.tolist()\n",
    "\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente chunk de código se calculan el número de sesiones que se realizan por mes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unnamed</th>\n",
       "      <th>username</th>\n",
       "      <th>grade</th>\n",
       "      <th>seq_4_avg</th>\n",
       "      <th>quiz_avg</th>\n",
       "      <th>seq_0_avg</th>\n",
       "      <th>seq_1_avg</th>\n",
       "      <th>seq_2_avg</th>\n",
       "      <th>seq_3_avg</th>\n",
       "      <th>duracion_sesion_avg</th>\n",
       "      <th>duracion_sesion_std</th>\n",
       "      <th>duracion_EOL</th>\n",
       "      <th>num_sesiones_agosto</th>\n",
       "      <th>num_sesiones_septiembre</th>\n",
       "      <th>num_sesiones_octubre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>05743498d061bf472df897f1e5bdda6d62e99312c952e3...</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2fb73a5b451fa1beba6a7e6c86cf66ab3d8bfa3fc256bb...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.944454</td>\n",
       "      <td>5.131721</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2fb73a5b451fa1beba6a7e6c86cf66ab3d8bfa3fc256bb...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.944454</td>\n",
       "      <td>5.131721</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2fb73a5b451fa1beba6a7e6c86cf66ab3d8bfa3fc256bb...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.944454</td>\n",
       "      <td>5.131721</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2fb73a5b451fa1beba6a7e6c86cf66ab3d8bfa3fc256bb...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.944454</td>\n",
       "      <td>5.131721</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422240</th>\n",
       "      <td>610</td>\n",
       "      <td>d4e09736a16c403937d6e829e6cdae6ed0537277c2c34d...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.703825</td>\n",
       "      <td>0.753715</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422241</th>\n",
       "      <td>610</td>\n",
       "      <td>d4e09736a16c403937d6e829e6cdae6ed0537277c2c34d...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.703825</td>\n",
       "      <td>0.753715</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422242</th>\n",
       "      <td>610</td>\n",
       "      <td>d4e09736a16c403937d6e829e6cdae6ed0537277c2c34d...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.703825</td>\n",
       "      <td>0.753715</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422243</th>\n",
       "      <td>610</td>\n",
       "      <td>d4e09736a16c403937d6e829e6cdae6ed0537277c2c34d...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.703825</td>\n",
       "      <td>0.753715</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422244</th>\n",
       "      <td>613</td>\n",
       "      <td>714d13c3517b88defa5763d78fc0c840a4bc1ad6092c02...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>422245 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        unnamed                                           username  grade  \\\n",
       "0             3  05743498d061bf472df897f1e5bdda6d62e99312c952e3...   0.94   \n",
       "1             4  2fb73a5b451fa1beba6a7e6c86cf66ab3d8bfa3fc256bb...   1.00   \n",
       "2             4  2fb73a5b451fa1beba6a7e6c86cf66ab3d8bfa3fc256bb...   1.00   \n",
       "3             4  2fb73a5b451fa1beba6a7e6c86cf66ab3d8bfa3fc256bb...   1.00   \n",
       "4             4  2fb73a5b451fa1beba6a7e6c86cf66ab3d8bfa3fc256bb...   1.00   \n",
       "...         ...                                                ...    ...   \n",
       "422240      610  d4e09736a16c403937d6e829e6cdae6ed0537277c2c34d...   0.00   \n",
       "422241      610  d4e09736a16c403937d6e829e6cdae6ed0537277c2c34d...   0.00   \n",
       "422242      610  d4e09736a16c403937d6e829e6cdae6ed0537277c2c34d...   0.00   \n",
       "422243      610  d4e09736a16c403937d6e829e6cdae6ed0537277c2c34d...   0.00   \n",
       "422244      613  714d13c3517b88defa5763d78fc0c840a4bc1ad6092c02...   0.00   \n",
       "\n",
       "        seq_4_avg  quiz_avg  seq_0_avg  seq_1_avg  seq_2_avg  seq_3_avg  \\\n",
       "0             1.0  0.905172        1.0   0.977273   0.944444   0.666667   \n",
       "1             1.0  0.965517        1.0   1.000000   1.000000   1.000000   \n",
       "2             1.0  0.965517        1.0   1.000000   1.000000   1.000000   \n",
       "3             1.0  0.965517        1.0   1.000000   1.000000   1.000000   \n",
       "4             1.0  0.965517        1.0   1.000000   1.000000   1.000000   \n",
       "...           ...       ...        ...        ...        ...        ...   \n",
       "422240       -1.0  0.000000       -1.0  -1.000000  -1.000000  -1.000000   \n",
       "422241       -1.0  0.000000       -1.0  -1.000000  -1.000000  -1.000000   \n",
       "422242       -1.0  0.000000       -1.0  -1.000000  -1.000000  -1.000000   \n",
       "422243       -1.0  0.000000       -1.0  -1.000000  -1.000000  -1.000000   \n",
       "422244       -1.0  0.000000       -1.0  -1.000000  -1.000000  -1.000000   \n",
       "\n",
       "        duracion_sesion_avg  duracion_sesion_std  duracion_EOL  \\\n",
       "0                       NaN                  NaN           NaN   \n",
       "1                  4.944454             5.131721          64.0   \n",
       "2                  4.944454             5.131721          64.0   \n",
       "3                  4.944454             5.131721          64.0   \n",
       "4                  4.944454             5.131721          64.0   \n",
       "...                     ...                  ...           ...   \n",
       "422240             1.703825             0.753715          24.0   \n",
       "422241             1.703825             0.753715          24.0   \n",
       "422242             1.703825             0.753715          24.0   \n",
       "422243             1.703825             0.753715          24.0   \n",
       "422244                  NaN                  NaN           NaN   \n",
       "\n",
       "        num_sesiones_agosto  num_sesiones_septiembre  num_sesiones_octubre  \n",
       "0                       NaN                      NaN                   NaN  \n",
       "1                       5.0                      3.0                   2.0  \n",
       "2                       5.0                      3.0                   2.0  \n",
       "3                       5.0                      3.0                   2.0  \n",
       "4                       5.0                      3.0                   2.0  \n",
       "...                     ...                      ...                   ...  \n",
       "422240                  1.0                      1.0                   0.0  \n",
       "422241                  1.0                      1.0                   0.0  \n",
       "422242                  1.0                      1.0                   0.0  \n",
       "422243                  1.0                      1.0                   0.0  \n",
       "422244                  NaN                      NaN                   NaN  \n",
       "\n",
       "[422245 rows x 15 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#----------------------------------\n",
    "\n",
    "#FRECUENCIA DE SESIONES POR MES\n",
    "\n",
    "\n",
    "distinct_months = eventos['month'].unique()\n",
    "\n",
    "# Create a new dataframe to store the results\n",
    "result_data = {'username': eventos['username']}\n",
    "for month in distinct_months:\n",
    "    result_data[month] = eventos['username'].map(\n",
    "        eventos[eventos['month'] == month].groupby('username')['day'].nunique()\n",
    "    )\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "result_df = pd.DataFrame(result_data)\n",
    "\n",
    "# Rename multiple columns\n",
    "result_df.rename(columns={8: 'num_sesiones_agosto', 9: 'num_sesiones_septiembre', 10: 'num_sesiones_octubre'}, inplace=True)\n",
    "\n",
    "\n",
    "result_df.fillna(0, inplace=True)\n",
    "\n",
    "# Merge the 'result_df' with the 'df_notas' dataframe based on the 'username' column\n",
    "notas = notas.merge(result_df, on='username', how='left')\n",
    "\n",
    "notas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/courses/(course-code)/course/'\n",
      " 'edx.bi.course.upgrade.sidebarupsell.displayed'\n",
      " '/courses/(course-code)/progress' 'edx.ui.lms.link_clicked'\n",
      " '/courses/(course-code)/(uuid-course)/'\n",
      " '/courses/(course-code)/course_wiki'\n",
      " '/courses/(course-code)/wiki/(course-code)/'\n",
      " '/courses/(course-code)/discussion/(discussion-id)/'\n",
      " '/courses/(course-code)/jump_to/(block-code)@vertical@(uuid)'\n",
      " '/courses/(course-code)/courseware/(uuid1)/(uuid2)/(tab-n)'\n",
      " '/courses/(course-code)/xblock/block-v1:(block-code)@html+block@(uuid)/handler/publish_completion'\n",
      " 'edx.ui.lms.sequence.next_selected'\n",
      " '/courses/(course-code)/courseware/(uuid-code1)/(uuid-code2)/(some-path)'\n",
      " 'load_video'\n",
      " '/courses/(course-code)/xblock/block-v1:(block-code)@sequential+block@(uuid)/handler/xmodule_handler/get_completion'\n",
      " '/courses/(course-code)/xblock/block-v1:(block-code)@sequential+block@(uuid)/handler/xmodule_handler/goto_position'\n",
      " 'seq_goto' 'play_video' 'pause_video' 'seek_video' 'page_close'\n",
      " '/courses/(course-code)/xblock/block-v1:(block-code)@problem+block@(uuid)/handler/xmodule_handler/problem_check'\n",
      " 'problem_check' 'problem_graded' 'seq_next'\n",
      " 'edx.ui.lms.sequence.previous_selected' 'seq_prev' 'stop_video'\n",
      " '/courses/(course-code)/jump_to/(block-code)@course+block'\n",
      " 'edx.course.home.resume_course.clicked'\n",
      " '/courses/(course-code)/courseware'\n",
      " '/courses/(course-code)/discussion/(discussion-id)//(inline-id)/inline'\n",
      " '/courses/(course-code)/discussion/(discussion-id)/(thread-id)/threads/(thread-id)'\n",
      " 'speed_change_video'\n",
      " '/courses/(course-code)/discussion/(discussion-id)/(1 * hash-id)/(inline-id)/inline'\n",
      " '/courses/(course-code)/bookmarks/' 'edx.course.tool.accessed'\n",
      " '/courses/(course-code)/xblock/block-v1:(block-code)@problem+block@(uuid)/handler/xmodule_handler/problem_show'\n",
      " 'problem_show' '/courses/(course-code)/jump_to/(block-code)@html@(uuid)'\n",
      " '/courses/(course-code)/discussion/(discussion-id)/threads/(thread-id)'\n",
      " '/courses/(course-code)/discussion/(discussion-id)/(thread-id)/update'\n",
      " '/courses/(course-code)/discussion/(discussion-id)/(thread-id)/reply'\n",
      " '/courses/(course-code)/discussion/(discussion-id)/users/(user-id)'\n",
      " '/courses/(course-code)/jump_to/(block-code)@sequential@(uuid)'\n",
      " '/courses/(course-code)/discussion/(discussion-id)/course/inline'\n",
      " '/courses/(course-code)/discussion/(discussion-id)/(thread-id)/upvote'\n",
      " '/courses/(course-code)/discussion/(discussion-id)/users/(user-id)/followed'\n",
      " '/courses/(course-code)/xblock/block-v1:(block-code)@problem+block@(uuid)/handler/xmodule_handler/problem_save'\n",
      " 'problem_save'\n",
      " '/courses/(course-code)/discussion/(discussion-id)/(thread-id)/unfollow'\n",
      " '/courses/(course-code)/discussion/(discussion-id)/(thread-id)/follow'\n",
      " '/courses/(course-code)/jump_to/(block-code)@problem@(uuid)'\n",
      " '/courses/(course-code)/discussion/(discussion-id)/search'\n",
      " '/courses/(course-code)/discussion/(discussion-id)'\n",
      " '/courses/(course-code)/wiki/']\n"
     ]
    }
   ],
   "source": [
    "# Entrega los valores únicos de la columna grouped_event_type\n",
    "unique_values = eventos['grouped_event_type'].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, con respecto a los tipos de eventos, se busca encontrar la cantidad de veces que se realiza cada uno junto con su desviación estándar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\AppData\\Local\\Temp\\ipykernel_10508\\276831140.py:30: FutureWarning:\n",
      "\n",
      "merging between different levels is deprecated and will be removed in a future version. (1 levels on the left, 2 on the right)\n",
      "\n",
      "C:\\Users\\tomas\\AppData\\Local\\Temp\\ipykernel_10508\\276831140.py:30: PerformanceWarning:\n",
      "\n",
      "dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unnamed', 'username', 'grade', 'seq_4_avg', 'quiz_avg', 'seq_0_avg', 'seq_1_avg', 'seq_2_avg', 'seq_3_avg', 'duracion_sesion_avg', 'duracion_sesion_std', 'duracion_EOL', 'num_sesiones_agosto', 'num_sesiones_septiembre', 'num_sesiones_octubre', 'page_close_mean', 'page_close_std', 'problem_graded_mean', 'problem_graded_std', 'problem_check_mean', 'problem_check_std', 'problem_show_mean', 'problem_show_std', 'seg_prev_mean', 'seg_prev_std', 'seg_next_mean', 'seg_next_std', 'seg_goto_mean', 'seg_goto_std', 'load_video_mean', 'load_video_std', 'play_video_mean', 'play_video_std', 'pause_video_mean', 'pause_video_std', 'speed_change_video_mean', 'speed_change_video_std']\n"
     ]
    }
   ],
   "source": [
    "# SE ENCUENTRAN LOS ESTADISTICOS DE LAS ACTIVIDADES QUE REALIZA EN CADA SESION\n",
    "# IE CANTIDAD DE VECES QUE REALIZA ALGUNA ACTIVIDAD EN UNA SESION (MONTH, DAY)\n",
    "# Lista de eventos para los que se crearán columnas\n",
    "event_types = ['page_close', 'problem_graded', 'problem_check', 'problem_show', 'seg_prev',\n",
    "               'seg_next', 'seg_goto', 'load_video', 'play_video', 'pause_video', 'speed_change_video']\n",
    "\n",
    "# Iterate through the event types and create columns with boolean values\n",
    "for event_type in event_types:\n",
    "    eventos[event_type] = (eventos['grouped_event_type'] == event_type).astype(int)\n",
    "\n",
    "grouped_eventos = eventos.groupby(['username', 'month', 'day'])[event_types].sum().reset_index()\n",
    "\n",
    "\n",
    "\n",
    "# Group the sub_df DataFrame by 'username' and calculate the mean and standard deviation for each event type\n",
    "agg_df = grouped_eventos.groupby('username').agg({\n",
    "    'page_close': ['mean', 'std'],\n",
    "    'problem_graded': ['mean', 'std'],\n",
    "    'problem_check': ['mean', 'std'],\n",
    "    'problem_show': ['mean', 'std'],\n",
    "    'seg_prev': ['mean', 'std'],\n",
    "    'seg_next': ['mean', 'std'],\n",
    "    'seg_goto': ['mean', 'std'],\n",
    "    'load_video': ['mean', 'std'],\n",
    "    'play_video': ['mean', 'std'],\n",
    "    'pause_video': ['mean', 'std'],\n",
    "    'speed_change_video': ['mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "notas = notas.merge(agg_df, on='username', how='left')\n",
    "\n",
    "\n",
    "# Specify the mapping of old column names to new column names\n",
    "column_mapping = {\n",
    "    ('page_close', 'mean'): 'page_close_mean',\n",
    "    ('page_close', 'std'): 'page_close_std',\n",
    "    ('problem_graded', 'mean'): 'problem_graded_mean',\n",
    "    ('problem_graded', 'std'): 'problem_graded_std',\n",
    "    ('problem_check', 'mean'): 'problem_check_mean',\n",
    "    ('problem_check', 'std'): 'problem_check_std',\n",
    "    ('problem_show', 'mean'): 'problem_show_mean',\n",
    "    ('problem_show', 'std'): 'problem_show_std',\n",
    "    ('seg_prev', 'mean'): 'seg_prev_mean',\n",
    "    ('seg_prev', 'std'): 'seg_prev_std',\n",
    "    ('seg_next', 'mean'): 'seg_next_mean',\n",
    "    ('seg_next', 'std'): 'seg_next_std',\n",
    "    ('seg_goto', 'mean'): 'seg_goto_mean',\n",
    "    ('seg_goto', 'std'): 'seg_goto_std',\n",
    "    ('load_video', 'mean'): 'load_video_mean',\n",
    "    ('load_video', 'std'): 'load_video_std',\n",
    "    ('play_video', 'mean'): 'play_video_mean',\n",
    "    ('play_video', 'std'): 'play_video_std',\n",
    "    ('pause_video', 'mean'): 'pause_video_mean',\n",
    "    ('pause_video', 'std'): 'pause_video_std',\n",
    "    ('speed_change_video', 'mean'): 'speed_change_video_mean',\n",
    "    ('speed_change_video', 'std'): 'speed_change_video_std'\n",
    "}\n",
    "\n",
    "# Rename the columns in the 'notas' DataFrame based on the mapping\n",
    "notas.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Display the resulting 'notas' DataFrame\n",
    "column_names = notas.columns.tolist()\n",
    "\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se busca encontrar aquellos chapters en los que el estudiante haya estudiado más o menos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unnamed', 'username', 'grade', 'seq_4_avg', 'quiz_avg', 'seq_0_avg', 'seq_1_avg', 'seq_2_avg', 'seq_3_avg', 'duracion_sesion_avg', 'duracion_sesion_std', 'duracion_EOL', 'num_sesiones_agosto', 'num_sesiones_septiembre', 'num_sesiones_octubre', 'page_close_mean', 'page_close_std', 'problem_graded_mean', 'problem_graded_std', 'problem_check_mean', 'problem_check_std', 'problem_show_mean', 'problem_show_std', 'seg_prev_mean', 'seg_prev_std', 'seg_next_mean', 'seg_next_std', 'seg_goto_mean', 'seg_goto_std', 'load_video_mean', 'load_video_std', 'play_video_mean', 'play_video_std', 'pause_video_mean', 'pause_video_std', 'speed_change_video_mean', 'speed_change_video_std', 'num_eventos_seq_0', 'num_eventos_seq_1', 'num_eventos_seq_2', 'num_eventos_seq_3', 'num_eventos_seq_4']\n"
     ]
    }
   ],
   "source": [
    "#COUNT ACTIVIDADES PER CHAPTER (encontrar chapters que haya estudioado mas/menos)\n",
    "\n",
    "grouped = eventos.groupby(['username', 'sequential'])['grouped_event_type'].count().reset_index()\n",
    "\n",
    "pivoted_df = grouped.pivot(index='username', columns='sequential', values='grouped_event_type').fillna(0)\n",
    "\n",
    "# Reset the index to make 'column1' a regular column\n",
    "pivoted_df.reset_index(inplace=True)\n",
    "\n",
    "# Rename columns for clarity\n",
    "pivoted_df.columns.name = None\n",
    "\n",
    "# Assuming 'notas' is the DataFrame where you want to add the columns\n",
    "notas = notas.merge(pivoted_df, on='username', how='left')\n",
    "\n",
    "# Rename multiple columns\n",
    "notas.rename(columns={'0': 'num_eventos_seq_0', '1': 'num_eventos_seq_1', '2': 'num_eventos_seq_2', '3': 'num_eventos_seq_3', '4': 'num_eventos_seq_4'}, inplace=True)\n",
    "\n",
    "notas = notas.drop(columns=['none_page'])\n",
    "\n",
    "# Display the resulting 'notas' DataFrame\n",
    "column_names = notas.columns.tolist()\n",
    "\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se unen los datos generados con los labels\n",
    "\n",
    "label_df = eventos[['username', 'label']].drop_duplicates()\n",
    "\n",
    "\n",
    "merged_df = pd.merge(notas, label_df, on='username', how='inner')\n",
    "\n",
    "notas = merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "notas.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan las siguientes columnas debido a que resultaron ser columnas vacías (solo eran 0)\n",
    "notas.drop(['unnamed', 'seg_prev_mean', 'seg_prev_std', 'seg_next_mean', 'seg_next_std',\n",
    "       'seg_goto_mean', 'seg_goto_std'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se calcula el tiempo promedio y desviación estandar que transcurre entre sesiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               username  month  day       date\n",
      "1537  454895bd2443967377ab017ec8ee1ae9137ec4720ad234...      9    4 2022-09-04\n",
      "1702  4edb701e0fbc912eea4574816ec14fb24ae8c3d0b16f5b...      9    5 2022-09-05\n",
      "828   28d2574d7d15160f5c28719b17ebc2dab707befa2f18cb...      8   23 2022-08-23\n",
      "1320  3dc3fc1020a048d54e8c2011a962e340aba1f4dc83a5ab...      9   20 2022-09-20\n",
      "2803  7612c1630582eadef65f1d1ba65e7d296cf04d76817d0e...      9   13 2022-09-13\n",
      "2103  57096c7dc738ad617a4db1ab64f1e7d7bce81d881700ff...      8   27 2022-08-27\n",
      "4276  bb6bd7a9ccd841dc446fac6d055f46917497317a056577...      8   21 2022-08-21\n",
      "4618  d051f6f2ba3853576d0319545145b2efaf00210888822e...      8   15 2022-08-15\n",
      "3959  aa7d35fd27bc1d9ff0e3f2f85b5e44036cd31769873f78...      8   24 2022-08-24\n",
      "3688  9a43f83865191c10e8bc3993b98e74a9456b41c391a6c1...      8   19 2022-08-19\n",
      "1401  40d44dd79a8528b3cd4798f5c08288aca7f540c6b4d5f8...      9   19 2022-09-19\n",
      "2407  62a4e71a9f08c417a7c93acf31b7d09d179ea699fad86d...      8   21 2022-08-21\n",
      "613   1f2871ebb4ee23bffd8ba3abf91392c585ba6662924629...      9    5 2022-09-05\n",
      "2052  56b37c4198fdee6aaae46c09bfcbb028bdb7b0dd572cc3...     10    1 2022-10-01\n",
      "1709  4ee71504c0797bbe8401a988969d9cb65122fb86e4fd7d...      8   29 2022-08-29\n",
      "1828  52a1db4e2025b9de64963780bab0461853c7c863958b81...      8   17 2022-08-17\n",
      "3864  a5686a515f2447acd4540fd826d5ba11fb7aff26766a6e...      9   25 2022-09-25\n",
      "1528  454895bd2443967377ab017ec8ee1ae9137ec4720ad234...      8   16 2022-08-16\n",
      "4813  d42f54a88ce5170c31a2838db0e2d767a8e3de9f1a7111...     10    7 2022-10-07\n",
      "3056  801195d79376a4859b8c351ab4c6dcfa70f94a9c42059f...      8   12 2022-08-12\n",
      "2404  62a4e71a9f08c417a7c93acf31b7d09d179ea699fad86d...      8   17 2022-08-17\n",
      "1592  47f2774dfe8d71961dd9abe8e467205009ac8313486ea7...     10    3 2022-10-03\n",
      "3785  9d823901218f3edbe2d34edc9818a0eb4d1237b9773173...      9   11 2022-09-11\n",
      "2658  6f96005f4b8eabe6ce305afecd656c92579eea2068f1bb...      8   23 2022-08-23\n",
      "1862  53e50534636a37fa605451b081aa9d17217492b303b0c8...      8   29 2022-08-29\n",
      "4109  b0173c576b043bc37eb5e5a501838adb37f37b6d2aa4d8...     10    1 2022-10-01\n",
      "4732  d2a219fcbb9b9c215e223d0d9cb87d1fe21cbdc9d3a403...      8   11 2022-08-11\n",
      "4371  befb083a644c7c0287eb39322c24beebf17efa5230ad68...     10    2 2022-10-02\n",
      "1028  32ac67fe18683b6d415afcd30d2cb37dac6ca1e88d5347...      8   24 2022-08-24\n",
      "3935  a9c25680f61f807b3c0a56db4479e9b134f24b021a036c...      8   10 2022-08-10\n",
      "3687  9a43f83865191c10e8bc3993b98e74a9456b41c391a6c1...      8   17 2022-08-17\n",
      "554   1ca122e1eefe2b1eb16167409e13bf501dfccbe4571b2c...      9   22 2022-09-22\n",
      "3928  a96e2804d141154ffa31781c26a65edf3522be2c3ca2ce...      9    4 2022-09-04\n",
      "321   12698cd78d23da60017639955fb369f14369b19cc65733...      8   24 2022-08-24\n",
      "3226  841cb67ca782f4e8d4e6a27164a5216f3ca2cb042593b1...      8   16 2022-08-16\n",
      "3541  91783373b6042bf8b6208e4b0fa8929b357aed05d666e1...      9   28 2022-09-28\n",
      "5426  ec968c304eab2ac46e1cc3fd62b0049baecb8aa35979b1...      8    9 2022-08-09\n",
      "1064  33503c0904195fd168429c0bd9d1823f4f832b1878f6f6...      8   31 2022-08-31\n",
      "5584  f3142143752a23bf86400bb56c5f22cd73a99bfcbb2df6...      8   22 2022-08-22\n",
      "412   1a06fbdc136167319baf48efbd0078264089815143a5f2...      9   24 2022-09-24\n",
      "3409  8c1c0b48244bfd0191327d71f733557149c9327701fcd8...      8   18 2022-08-18\n",
      "5641  f53b402e3bf653f45274b193eb4bc083bafe7080de89ac...      8   25 2022-08-25\n",
      "5701  f75f90897fb682993eaeefc7adaa02e255166d9ef5c816...      8   12 2022-08-12\n",
      "1517  4509d74eef384d467a6e7d40f586e8a6568d5be97b4da1...      8   14 2022-08-14\n",
      "3985  ab0003d7c01ccfababe725776d36658b9a08c9db4d2682...      8   19 2022-08-19\n",
      "494   1b745a5df80285859409711947deab4c0540ff763bd4bc...      9   26 2022-09-26\n",
      "122   06afdbc80205de7e89cc7d6989f64a16f0bfbbdba312de...      9   30 2022-09-30\n",
      "722   25888bec9dca4095d9612a71d2def6b09d1c120fc08333...      9   24 2022-09-24\n",
      "4123  b15e36f4ccff22a0572c37eaca65695b92089c9209d384...     10    2 2022-10-02\n",
      "3546  91b100bff66ba80bc0679cb6f63d873e49765bbb7becba...      8   22 2022-08-22\n"
     ]
    }
   ],
   "source": [
    "eventos['date'] = eventos['time'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "eventos['date'] = pd.to_datetime(eventos['date'])\n",
    "\n",
    "g_eventos = eventos.groupby(['username', 'month', 'day', 'date']).size().reset_index(name='count')\n",
    "\n",
    "sample_g_eventos = g_eventos[['username', 'month','day', 'date']].sample(50)\n",
    "print(sample_g_eventos)\n",
    "\n",
    "g_eventos['day_diff'] = g_eventos.groupby('username')['date'].diff().dt.days\n",
    "\n",
    "# Calculate the average time between sessions per user, excluding the first '0' gap\n",
    "avg_time_between_sessions = g_eventos.groupby('username')['day_diff'].agg(lambda x: x[x != 0].mean() if len(x[x != 0]) > 0 else 0)\n",
    "\n",
    "# Calculate the standard deviation of time between sessions per user, excluding the first '0' gap\n",
    "std_time_between_sessions = g_eventos.groupby('username')['day_diff'].agg(lambda x: x[x != 0].std() if len(x[x != 0]) > 0 else 0)\n",
    "\n",
    "# Merge average and standard deviation of time between sessions into 'notas' DataFrame based on 'username'\n",
    "notas = notas.merge(avg_time_between_sessions.rename('avg_time_between_sessions'), on='username')\n",
    "notas = notas.merge(std_time_between_sessions.rename('std_time_between_sessions'), on='username')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora también se calculan el núemero de sesiones realizadas entre las 12 de la noche y las 2 de la mañana, y también el número de sesiones entre 2 de la mañana y 5 de la mañana.\n",
    "\n",
    "Junto con esto también se calcula la cantidad de actividad que se realiza en estos horarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventos['time'] = pd.to_datetime(eventos['time'])\n",
    "\n",
    "# Filtrar las sesiones que ocurren entre las 2 y las 5 de la madrugada\n",
    "sessions_between_2_and_5 = eventos[(eventos['time'].dt.hour >= 2) & (eventos['time'].dt.hour <= 5)]\n",
    "\n",
    "# Obtener el número de sesiones distintas por usuario, mes y día entre las 2 y las 5 de la madrugada\n",
    "num_sessions_2_to_5 = sessions_between_2_and_5.groupby(['username', 'month', 'day']).size().reset_index(name='sessions_2_to_5')\n",
    "\n",
    "# Contar el número total de sesiones entre las 2 y las 5 de la madrugada por usuario\n",
    "total_sessions_2_to_5 = num_sessions_2_to_5.groupby('username')['sessions_2_to_5'].sum().reset_index()\n",
    "\n",
    "# Merge de la columna 'sessions_2_to_5' al DataFrame 'notas' basado en 'username'\n",
    "notas = notas.merge(total_sessions_2_to_5[['username', 'sessions_2_to_5']], on='username', how='left')\n",
    "\n",
    "# Renombrar la columna 'sessions_2_to_5' a 'nightsession_2_to_5'\n",
    "notas = notas.rename(columns={'sessions_2_to_5': 'nightactivity_2_to_5'})\n",
    "\n",
    "# Reemplazar valores NaN en 'nightsession_2_to_5' por 0\n",
    "notas['nightactivity_2_to_5'] = notas['nightactivity_2_to_5'].fillna(0).astype(int)\n",
    "\n",
    "sessions_between_0_and_2 = eventos[(eventos['time'].dt.hour >= 0) & (eventos['time'].dt.hour < 2)]\n",
    "\n",
    "# Obtener el número de sesiones distintas por usuario, mes y día entre las 0 y las 2 de la madrugada\n",
    "num_sessions_0_to_2 = sessions_between_0_and_2.groupby(['username', 'month', 'day']).size().reset_index(name='sessions_0_to_2')\n",
    "\n",
    "# Contar el número total de sesiones entre las 0 y las 2 de la madrugada por usuario\n",
    "total_sessions_0_to_2 = num_sessions_0_to_2.groupby('username')['sessions_0_to_2'].sum().reset_index()\n",
    "\n",
    "# Merge de la columna 'sessions_0_to_2' al DataFrame 'notas' basado en 'username'\n",
    "notas = notas.merge(total_sessions_0_to_2[['username', 'sessions_0_to_2']], on='username', how='left')\n",
    "\n",
    "# Renombrar la columna 'sessions_0_to_2' a 'nightsession_0_to_2'\n",
    "notas = notas.rename(columns={'sessions_0_to_2': 'nightactivity_0_to_2'})\n",
    "\n",
    "# Reemplazar valores NaN en 'nightsession_0_to_2' por 0\n",
    "notas['nightactivity_0_to_2'] = notas['nightactivity_0_to_2'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna 'time' a formato datetime\n",
    "eventos['time'] = pd.to_datetime(eventos['time'])\n",
    "\n",
    "# Crear un nuevo DataFrame con la agrupación y reemplazo de 'time' por el máximo tiempo registrado\n",
    "nuevo_eventos = eventos.copy()  # Crear una copia del DataFrame original\n",
    "\n",
    "# Agrupar por 'username', 'month', 'day' y obtener el máximo tiempo registrado en cada grupo\n",
    "nuevo_eventos['time'] = nuevo_eventos.groupby(['username', 'month', 'day'])['time'].transform('max')\n",
    "\n",
    "# Eliminar duplicados para tener un conjunto único por 'username', 'month', 'day'\n",
    "nuevo_eventos = nuevo_eventos.drop_duplicates(subset=['username', 'month', 'day'])\n",
    "\n",
    "# Filtrar las sesiones que ocurren entre las 2 y las 5 de la madrugada\n",
    "sesiones_nocturnas = nuevo_eventos[(nuevo_eventos['time'].dt.hour >= 2) & (nuevo_eventos['time'].dt.hour < 5)]\n",
    "\n",
    "num_sesiones_nocturnas = sesiones_nocturnas.groupby('username').agg({'month': pd.Series.nunique, 'day': pd.Series.nunique}).reset_index()\n",
    "\n",
    "# Calcular el número total de sesiones únicas (month, day) nocturnas\n",
    "num_sesiones_nocturnas['sesionesde_2_5'] = num_sesiones_nocturnas['month'] * num_sesiones_nocturnas['day']\n",
    "\n",
    "# Seleccionar únicamente las columnas necesarias\n",
    "num_sesiones_nocturnas = num_sesiones_nocturnas[['username', 'sesionesde_2_5']]\n",
    "\n",
    "num_sesiones_nocturnas\n",
    "\n",
    "# Fusionar la columna 'sesionesde_2_5' en el DataFrame 'eventos' basado en 'username'\n",
    "notas = notas.merge(num_sesiones_nocturnas, on='username', how='left')\n",
    "# Reemplazar valores NaN en 'nightsession_0_to_2' por 0\n",
    "notas['sesionesde_2_5'] = notas['sesionesde_2_5'].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "#entre las 0 y 2 hrs\n",
    "\n",
    "# Filtrar las sesiones que ocurren entre la medianoche y las 2 AM (sin incluir las 2 AM)\n",
    "sesiones_nocturnas = nuevo_eventos[(nuevo_eventos['time'].dt.hour >= 0) & (nuevo_eventos['time'].dt.hour < 2)]\n",
    "\n",
    "# Agrupar por 'username' y contar la cantidad de sesiones únicas (month, day) nocturnas para cada usuario\n",
    "num_sesiones_nocturnas = sesiones_nocturnas.groupby('username').agg({'month': pd.Series.nunique, 'day': pd.Series.nunique}).reset_index()\n",
    "\n",
    "# Calcular el número total de sesiones únicas (month, day) nocturnas\n",
    "num_sesiones_nocturnas['sesionesde_0_2'] = num_sesiones_nocturnas['month'] * num_sesiones_nocturnas['day']\n",
    "\n",
    "# Seleccionar únicamente las columnas necesarias\n",
    "num_sesiones_nocturnas = num_sesiones_nocturnas[['username', 'sesionesde_0_2']]\n",
    "\n",
    "# Fusionar la columna 'sesionesde_0_2' en el DataFrame 'notas' basado en 'username'\n",
    "notas = notas.merge(num_sesiones_nocturnas, on='username', how='left')\n",
    "\n",
    "# Reemplazar valores NaN en 'nightsession_0_to_2' por 0\n",
    "notas['sesionesde_0_2'] = notas['sesionesde_0_2'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza un boxplot de las variables para tener una mejor idea de cómo se comportan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configurar el estilo de seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Crear boxplots para cada variable\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=notas, palette=\"Set3\")\n",
    "plt.xticks(rotation=90)  \n",
    "plt.title('Boxplots de las Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "df_entrenamiento = notas.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    304\n",
       "0     81\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entrenamiento['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entrenamiento.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_entrenamiento.drop(columns=['label', 'username'])\n",
    "y = df_entrenamiento['label']\n",
    "\n",
    "# Crear una instancia de SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=314159)\n",
    "\n",
    "# Aplicar SMOTE a tus datos\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# X_resampled y y_resampled contienen los datos con SMOTE aplicado\n",
    "\n",
    "# Puedes convertirlos de nuevo a DataFrames si lo necesitas\n",
    "X_resampled_df = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "y_resampled_df = pd.Series(y_resampled, name='label')\n",
    "\n",
    "# Ahora X_resampled_df y y_resampled_df contienen los datos con SMOTE aplicado en formato DataFrame\n",
    "df_sobremuestreados = pd.concat([X_resampled_df, y_resampled_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    304\n",
       "0    304\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sobremuestreados['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entrenamiento = df_sobremuestreados.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomas\\anaconda3\\envs\\Lab_6\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning:\n",
      "\n",
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "seed = 314159\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['grade', 'seq_4_avg', 'quiz_avg', 'seq_0_avg', 'seq_1_avg', 'seq_2_avg',\n",
       "       'seq_3_avg', 'duracion_sesion_avg', 'duracion_sesion_std',\n",
       "       'duracion_EOL', 'num_sesiones_agosto', 'num_sesiones_septiembre',\n",
       "       'num_sesiones_octubre', 'page_close_mean', 'page_close_std',\n",
       "       'problem_graded_mean', 'problem_graded_std', 'problem_check_mean',\n",
       "       'problem_check_std', 'problem_show_mean', 'problem_show_std',\n",
       "       'load_video_mean', 'load_video_std', 'play_video_mean',\n",
       "       'play_video_std', 'pause_video_mean', 'pause_video_std',\n",
       "       'speed_change_video_mean', 'speed_change_video_std',\n",
       "       'num_eventos_seq_0', 'num_eventos_seq_1', 'num_eventos_seq_2',\n",
       "       'num_eventos_seq_3', 'num_eventos_seq_4', 'avg_time_between_sessions',\n",
       "       'std_time_between_sessions', 'nightactivity_2_to_5',\n",
       "       'nightactivity_0_to_2', 'sesionesde_2_5', 'sesionesde_0_2', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entrenamiento.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte del código se seleccionan aquellas columnas que tienen una correlación con label mayor a 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la correlación entre todas las características y la etiqueta\n",
    "correlation_matrix = df_entrenamiento.corr()\n",
    "correlation_with_label = correlation_matrix['label'].abs()\n",
    "\n",
    "# Seleccionar las características con mayor correlación\n",
    "selected_features = correlation_with_label[correlation_with_label > 0.05].index.tolist()\n",
    "\n",
    "# Crear un nuevo DataFrame con solo las características seleccionadas y la etiqueta\n",
    "selected_data = df_entrenamiento[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = selected_data.drop(columns=['label'])  # Características\n",
    "\n",
    "\n",
    "y = selected_data['label']  # Etiquetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se separan los datos en entrenamiento y testeo. Cabe recalcar que se toma stratify = y. Esto ayuda a que se mantengan balanceadas las clases en ambos datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=314159, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se escalan todos aquellos datos que no se encuentren entre 0 y 1 con MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Selecciona las columnas que deben ser escaladas\n",
    "cols_to_scale = X_train.select_dtypes(include=['float64', 'int64', 'int32']).columns\n",
    "\n",
    "# Ajusta el scaler con los datos de entrenamiento solo para aquellas columnas que no están en el rango [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "for col in cols_to_scale:\n",
    "    if X_train[col].min() < 0 or X_train[col].max() > 1:\n",
    "        X_train[col] = scaler.fit_transform(X_train[[col]])\n",
    "        # Transforma también los datos de prueba usando el mismo scaler\n",
    "        X_test[col] = scaler.transform(X_test[[col]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede al entrenamiento de la red neuronal utilizando tensorflow y optuna. En este sentido, optuna buscará los mejores hiperparámetros para la tasa de aprendizaje, el número de capas, el número de neuronas, el dropout rate, el optimizador, la función de activación y el batch size. Esto se realiza en 200 trials con 50 épocas por red neuronal entrenada.\n",
    "Posteriormente se toman los parámetros del mejor modelo y se reentrena pero con 200 épocas en vez de 50.\n",
    "\n",
    "Este código se demora aproximadamente una hora en correr, por lo que se adjunta el modelo en la carpeta.\n",
    "\n",
    "Se puede cargar ese modelo con el codigo del siguiente chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomas\\anaconda3\\envs\\Lab_6\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning:\n",
      "\n",
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n",
      "[I 2023-12-03 10:29:12,303] A new study created in memory with name: no-name-c9918d84-db75-4896-be51-18700dce0f75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:29:36,853] Trial 0 finished with value: 0.7692307692307693 and parameters: {'learning_rate': 0.006017707488824367, 'num_hidden_layers': 2, 'num_hidden_units': 329, 'dropout_rate': 0.21056273996850217, 'optimizer': 'sgd', 'activation': 'relu', 'batch_size': 9}. Best is trial 0 with value: 0.7692307692307693.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:30:00,209] Trial 1 finished with value: 0.6986301369863014 and parameters: {'learning_rate': 0.006994460242314335, 'num_hidden_layers': 2, 'num_hidden_units': 307, 'dropout_rate': 0.007947683545153406, 'optimizer': 'rmsprop', 'activation': 'elu', 'batch_size': 9}. Best is trial 0 with value: 0.7692307692307693.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:30:31,189] Trial 2 finished with value: 0.6799999999999999 and parameters: {'learning_rate': 0.008128162590868477, 'num_hidden_layers': 8, 'num_hidden_units': 154, 'dropout_rate': 0.29946119870233456, 'optimizer': 'adam', 'activation': 'elu', 'batch_size': 19}. Best is trial 0 with value: 0.7692307692307693.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:30:51,608] Trial 3 finished with value: 0.6629213483146068 and parameters: {'learning_rate': 0.009316904697130994, 'num_hidden_layers': 2, 'num_hidden_units': 70, 'dropout_rate': 0.461259390725649, 'optimizer': 'adam', 'activation': 'relu', 'batch_size': 9}. Best is trial 0 with value: 0.7692307692307693.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:31:31,590] Trial 4 finished with value: 0.7218045112781954 and parameters: {'learning_rate': 0.007215148285610208, 'num_hidden_layers': 7, 'num_hidden_units': 465, 'dropout_rate': 0.21275018439087484, 'optimizer': 'sgd', 'activation': 'sigmoid', 'batch_size': 19}. Best is trial 0 with value: 0.7692307692307693.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:31:58,446] Trial 5 finished with value: 0.7692307692307692 and parameters: {'learning_rate': 0.0033550945582446973, 'num_hidden_layers': 5, 'num_hidden_units': 485, 'dropout_rate': 0.19658359541128706, 'optimizer': 'adam', 'activation': 'relu', 'batch_size': 19}. Best is trial 0 with value: 0.7692307692307693.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:32:21,008] Trial 6 finished with value: 0.2702702702702703 and parameters: {'learning_rate': 0.004482303691749502, 'num_hidden_layers': 8, 'num_hidden_units': 71, 'dropout_rate': 0.44082712075771074, 'optimizer': 'sgd', 'activation': 'elu', 'batch_size': 19}. Best is trial 0 with value: 0.7692307692307693.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:32:33,765] Trial 7 finished with value: 0.7716535433070867 and parameters: {'learning_rate': 0.009694661719069077, 'num_hidden_layers': 2, 'num_hidden_units': 31, 'dropout_rate': 0.49195881157949856, 'optimizer': 'rmsprop', 'activation': 'sigmoid', 'batch_size': 19}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:32:48,983] Trial 8 finished with value: 0.7413793103448276 and parameters: {'learning_rate': 0.0063783620514608124, 'num_hidden_layers': 3, 'num_hidden_units': 306, 'dropout_rate': 0.0481638673939736, 'optimizer': 'sgd', 'activation': 'sigmoid', 'batch_size': 38}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:33:12,293] Trial 9 finished with value: 0.7272727272727273 and parameters: {'learning_rate': 0.008929265626769206, 'num_hidden_layers': 4, 'num_hidden_units': 111, 'dropout_rate': 0.39493600728057815, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:33:23,263] Trial 10 finished with value: 0.7008547008547008 and parameters: {'learning_rate': 0.001500161316551285, 'num_hidden_layers': 1, 'num_hidden_units': 210, 'dropout_rate': 0.3622234606324287, 'optimizer': 'rmsprop', 'activation': 'sigmoid', 'batch_size': 38}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:33:41,296] Trial 11 finished with value: 0.6986301369863014 and parameters: {'learning_rate': 0.009746799067929133, 'num_hidden_layers': 1, 'num_hidden_units': 371, 'dropout_rate': 0.49890332020772504, 'optimizer': 'rmsprop', 'activation': 'relu', 'batch_size': 9}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:34:07,762] Trial 12 finished with value: 0.7702702702702702 and parameters: {'learning_rate': 0.005416837125508627, 'num_hidden_layers': 5, 'num_hidden_units': 246, 'dropout_rate': 0.28813440777914523, 'optimizer': 'rmsprop', 'activation': 'tanh', 'batch_size': 19}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:34:25,495] Trial 13 finished with value: 0.631578947368421 and parameters: {'learning_rate': 0.004953579975737702, 'num_hidden_layers': 5, 'num_hidden_units': 17, 'dropout_rate': 0.3251833872385691, 'optimizer': 'rmsprop', 'activation': 'tanh', 'batch_size': 19}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:34:50,182] Trial 14 finished with value: 0.6341463414634146 and parameters: {'learning_rate': 0.007995440888098747, 'num_hidden_layers': 6, 'num_hidden_units': 173, 'dropout_rate': 0.41252357984475757, 'optimizer': 'rmsprop', 'activation': 'tanh', 'batch_size': 19}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:35:13,011] Trial 15 finished with value: 0.7500000000000001 and parameters: {'learning_rate': 0.0034045022449572457, 'num_hidden_layers': 4, 'num_hidden_units': 234, 'dropout_rate': 0.29773071014798075, 'optimizer': 'rmsprop', 'activation': 'tanh', 'batch_size': 19}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:35:26,899] Trial 16 finished with value: 0.6086956521739131 and parameters: {'learning_rate': 0.008348662862355442, 'num_hidden_layers': 6, 'num_hidden_units': 433, 'dropout_rate': 0.3684636517398581, 'optimizer': 'rmsprop', 'activation': 'sigmoid', 'batch_size': 38}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:35:50,052] Trial 17 finished with value: 0.7289719626168225 and parameters: {'learning_rate': 0.009707137440705022, 'num_hidden_layers': 3, 'num_hidden_units': 391, 'dropout_rate': 0.4714422401718964, 'optimizer': 'rmsprop', 'activation': 'tanh', 'batch_size': 19}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:36:19,001] Trial 18 finished with value: 0.6917293233082706 and parameters: {'learning_rate': 0.005972471070929275, 'num_hidden_layers': 6, 'num_hidden_units': 265, 'dropout_rate': 0.4226588975292356, 'optimizer': 'rmsprop', 'activation': 'sigmoid', 'batch_size': 19}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:36:41,301] Trial 19 finished with value: 0.672566371681416 and parameters: {'learning_rate': 0.007332303522780076, 'num_hidden_layers': 3, 'num_hidden_units': 22, 'dropout_rate': 0.4849082514685849, 'optimizer': 'rmsprop', 'activation': 'tanh', 'batch_size': 19}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:37:03,845] Trial 20 finished with value: 0.6470588235294118 and parameters: {'learning_rate': 0.0002839221755725572, 'num_hidden_layers': 4, 'num_hidden_units': 143, 'dropout_rate': 0.2599334734152501, 'optimizer': 'adam', 'activation': 'sigmoid', 'batch_size': 38}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:37:27,836] Trial 21 finished with value: 0.7540983606557377 and parameters: {'learning_rate': 0.006112442586535197, 'num_hidden_layers': 2, 'num_hidden_units': 341, 'dropout_rate': 0.17792088254241453, 'optimizer': 'sgd', 'activation': 'relu', 'batch_size': 9}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:37:50,961] Trial 22 finished with value: 0.7152317880794702 and parameters: {'learning_rate': 0.00874059082587816, 'num_hidden_layers': 1, 'num_hidden_units': 418, 'dropout_rate': 0.12978450723241675, 'optimizer': 'sgd', 'activation': 'relu', 'batch_size': 9}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:38:28,278] Trial 23 finished with value: 0.6799999999999999 and parameters: {'learning_rate': 0.009991709957415587, 'num_hidden_layers': 3, 'num_hidden_units': 273, 'dropout_rate': 0.2549923770351841, 'optimizer': 'sgd', 'activation': 'relu', 'batch_size': 9}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:38:51,137] Trial 24 finished with value: 0.6811594202898551 and parameters: {'learning_rate': 0.005886631361571085, 'num_hidden_layers': 2, 'num_hidden_units': 223, 'dropout_rate': 0.36426414947061525, 'optimizer': 'rmsprop', 'activation': 'relu', 'batch_size': 19}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:39:41,406] Trial 25 finished with value: 0.7272727272727273 and parameters: {'learning_rate': 0.005228560730305301, 'num_hidden_layers': 5, 'num_hidden_units': 330, 'dropout_rate': 0.32079152166974423, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:40:11,182] Trial 26 finished with value: 0.7368421052631579 and parameters: {'learning_rate': 0.007443995705326402, 'num_hidden_layers': 4, 'num_hidden_units': 184, 'dropout_rate': 0.14540952849736422, 'optimizer': 'rmsprop', 'activation': 'sigmoid', 'batch_size': 19}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:40:31,413] Trial 27 finished with value: 0.7261146496815287 and parameters: {'learning_rate': 0.0067184319367543125, 'num_hidden_layers': 2, 'num_hidden_units': 67, 'dropout_rate': 0.24677360033699122, 'optimizer': 'rmsprop', 'activation': 'elu', 'batch_size': 19}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:41:13,080] Trial 28 finished with value: 0.6495726495726496 and parameters: {'learning_rate': 0.007879410627908465, 'num_hidden_layers': 7, 'num_hidden_units': 366, 'dropout_rate': 0.44561108726400106, 'optimizer': 'adam', 'activation': 'sigmoid', 'batch_size': 38}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:41:38,294] Trial 29 finished with value: 0.7205882352941175 and parameters: {'learning_rate': 0.008978103298084406, 'num_hidden_layers': 1, 'num_hidden_units': 299, 'dropout_rate': 0.40126699469661925, 'optimizer': 'sgd', 'activation': 'elu', 'batch_size': 9}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:42:13,896] Trial 30 finished with value: 0.743801652892562 and parameters: {'learning_rate': 0.00681299242822469, 'num_hidden_layers': 2, 'num_hidden_units': 511, 'dropout_rate': 0.49223507559040863, 'optimizer': 'rmsprop', 'activation': 'relu', 'batch_size': 9}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:42:44,861] Trial 31 finished with value: 0.6950354609929078 and parameters: {'learning_rate': 0.0038078454231727232, 'num_hidden_layers': 5, 'num_hidden_units': 497, 'dropout_rate': 0.2092654872828531, 'optimizer': 'adam', 'activation': 'relu', 'batch_size': 19}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:43:16,352] Trial 32 finished with value: 0.7341772151898734 and parameters: {'learning_rate': 0.0032704694734477986, 'num_hidden_layers': 5, 'num_hidden_units': 438, 'dropout_rate': 0.293827293409038, 'optimizer': 'adam', 'activation': 'relu', 'batch_size': 19}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:43:45,914] Trial 33 finished with value: 0.7519999999999999 and parameters: {'learning_rate': 0.005273132752504006, 'num_hidden_layers': 6, 'num_hidden_units': 396, 'dropout_rate': 0.2192524000301046, 'optimizer': 'adam', 'activation': 'relu', 'batch_size': 19}. Best is trial 7 with value: 0.7716535433070867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:43:58,997] Trial 34 finished with value: 0.8034188034188035 and parameters: {'learning_rate': 0.0027621464996600838, 'num_hidden_layers': 3, 'num_hidden_units': 460, 'dropout_rate': 0.17052691797776098, 'optimizer': 'adam', 'activation': 'relu', 'batch_size': 19}. Best is trial 34 with value: 0.8034188034188035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:44:09,568] Trial 35 finished with value: 0.7413793103448276 and parameters: {'learning_rate': 0.007737310308521734, 'num_hidden_layers': 3, 'num_hidden_units': 460, 'dropout_rate': 0.15165285812708335, 'optimizer': 'adam', 'activation': 'relu', 'batch_size': 19}. Best is trial 34 with value: 0.8034188034188035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:44:15,310] Trial 36 finished with value: 0.7164179104477612 and parameters: {'learning_rate': 0.008435880771415279, 'num_hidden_layers': 2, 'num_hidden_units': 124, 'dropout_rate': 0.11339117372169971, 'optimizer': 'adam', 'activation': 'elu', 'batch_size': 19}. Best is trial 34 with value: 0.8034188034188035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:44:22,797] Trial 37 finished with value: 0.782608695652174 and parameters: {'learning_rate': 0.007056515068138088, 'num_hidden_layers': 3, 'num_hidden_units': 244, 'dropout_rate': 0.17221549049020474, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 34 with value: 0.8034188034188035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:44:30,171] Trial 38 finished with value: 0.8070175438596491 and parameters: {'learning_rate': 0.00919593864620116, 'num_hidden_layers': 3, 'num_hidden_units': 236, 'dropout_rate': 0.17865331122539485, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 38 with value: 0.8070175438596491.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:44:44,304] Trial 39 finished with value: 0.8205128205128205 and parameters: {'learning_rate': 0.009283029944959297, 'num_hidden_layers': 3, 'num_hidden_units': 196, 'dropout_rate': 0.1777723785100351, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 39 with value: 0.8205128205128205.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:44:57,687] Trial 40 finished with value: 0.8108108108108109 and parameters: {'learning_rate': 0.009216012487349021, 'num_hidden_layers': 3, 'num_hidden_units': 190, 'dropout_rate': 0.17862570174331913, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 39 with value: 0.8205128205128205.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:45:11,422] Trial 41 finished with value: 0.7962962962962963 and parameters: {'learning_rate': 0.009090715265332639, 'num_hidden_layers': 3, 'num_hidden_units': 197, 'dropout_rate': 0.10237765310338526, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 39 with value: 0.8205128205128205.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:45:25,820] Trial 42 finished with value: 0.8403361344537814 and parameters: {'learning_rate': 0.00916851126800178, 'num_hidden_layers': 3, 'num_hidden_units': 198, 'dropout_rate': 0.10136510180541769, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 42 with value: 0.8403361344537814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:45:35,070] Trial 43 finished with value: 0.7927927927927928 and parameters: {'learning_rate': 0.009315170387249402, 'num_hidden_layers': 4, 'num_hidden_units': 148, 'dropout_rate': 0.08451554090992845, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 42 with value: 0.8403361344537814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:45:42,685] Trial 44 finished with value: 0.8245614035087719 and parameters: {'learning_rate': 0.008497025521019408, 'num_hidden_layers': 3, 'num_hidden_units': 174, 'dropout_rate': 0.18058555202205434, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 42 with value: 0.8403361344537814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:45:51,041] Trial 45 finished with value: 0.7586206896551724 and parameters: {'learning_rate': 0.008600073726407911, 'num_hidden_layers': 4, 'num_hidden_units': 177, 'dropout_rate': 0.19262365871019957, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 42 with value: 0.8403361344537814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:45:57,668] Trial 46 finished with value: 0.7796610169491526 and parameters: {'learning_rate': 0.009418234008293055, 'num_hidden_layers': 3, 'num_hidden_units': 114, 'dropout_rate': 0.14533707914990812, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 42 with value: 0.8403361344537814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:46:05,950] Trial 47 finished with value: 0.8264462809917356 and parameters: {'learning_rate': 0.008210738868832638, 'num_hidden_layers': 4, 'num_hidden_units': 211, 'dropout_rate': 0.04807427802173369, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 42 with value: 0.8403361344537814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:46:14,239] Trial 48 finished with value: 0.823529411764706 and parameters: {'learning_rate': 0.008171695114116074, 'num_hidden_layers': 4, 'num_hidden_units': 207, 'dropout_rate': 0.013110145782434274, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 42 with value: 0.8403361344537814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:46:19,952] Trial 49 finished with value: 0.7850467289719626 and parameters: {'learning_rate': 0.008185007997336085, 'num_hidden_layers': 4, 'num_hidden_units': 89, 'dropout_rate': 0.027805020488732738, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 38}. Best is trial 42 with value: 0.8403361344537814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:46:27,741] Trial 50 finished with value: 0.7850467289719626 and parameters: {'learning_rate': 0.00858007302708551, 'num_hidden_layers': 4, 'num_hidden_units': 163, 'dropout_rate': 0.0628037398236252, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 42 with value: 0.8403361344537814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:46:35,928] Trial 51 finished with value: 0.8448275862068965 and parameters: {'learning_rate': 0.008768364507890992, 'num_hidden_layers': 4, 'num_hidden_units': 203, 'dropout_rate': 0.011864117080785063, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 51 with value: 0.8448275862068965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:46:44,475] Trial 52 finished with value: 0.8 and parameters: {'learning_rate': 0.008124449135006453, 'num_hidden_layers': 4, 'num_hidden_units': 202, 'dropout_rate': 0.02188243127719878, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 51 with value: 0.8448275862068965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:46:54,686] Trial 53 finished with value: 0.8245614035087719 and parameters: {'learning_rate': 0.008750138402505511, 'num_hidden_layers': 4, 'num_hidden_units': 287, 'dropout_rate': 0.00046079263551820904, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 51 with value: 0.8448275862068965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:47:07,536] Trial 54 finished with value: 0.864406779661017 and parameters: {'learning_rate': 0.007687154181699977, 'num_hidden_layers': 4, 'num_hidden_units': 276, 'dropout_rate': 0.004023668416640002, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 54 with value: 0.864406779661017.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:47:19,351] Trial 55 finished with value: 0.7663551401869158 and parameters: {'learning_rate': 0.008772191945749557, 'num_hidden_layers': 5, 'num_hidden_units': 283, 'dropout_rate': 0.043132777263515505, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 54 with value: 0.864406779661017.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:47:29,301] Trial 56 finished with value: 0.8727272727272727 and parameters: {'learning_rate': 0.007598738012519626, 'num_hidden_layers': 4, 'num_hidden_units': 298, 'dropout_rate': 0.00672747947547965, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 56 with value: 0.8727272727272727.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:47:40,183] Trial 57 finished with value: 0.864406779661017 and parameters: {'learning_rate': 0.007727869161271066, 'num_hidden_layers': 5, 'num_hidden_units': 255, 'dropout_rate': 0.0005896088006173902, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 56 with value: 0.8727272727272727.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:47:48,346] Trial 58 finished with value: 0.822429906542056 and parameters: {'learning_rate': 0.007580249887083142, 'num_hidden_layers': 5, 'num_hidden_units': 247, 'dropout_rate': 0.004817618329532307, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 38}. Best is trial 56 with value: 0.8727272727272727.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:47:58,673] Trial 59 finished with value: 0.8771929824561403 and parameters: {'learning_rate': 0.007295813334415077, 'num_hidden_layers': 5, 'num_hidden_units': 312, 'dropout_rate': 0.03246054212912508, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 59 with value: 0.8771929824561403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:48:10,889] Trial 60 finished with value: 0.8688524590163934 and parameters: {'learning_rate': 0.007132079546662979, 'num_hidden_layers': 6, 'num_hidden_units': 316, 'dropout_rate': 0.033721001710787436, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 59 with value: 0.8771929824561403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:48:27,531] Trial 61 finished with value: 0.8245614035087719 and parameters: {'learning_rate': 0.00739739723705608, 'num_hidden_layers': 6, 'num_hidden_units': 318, 'dropout_rate': 0.03333369542881746, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 59 with value: 0.8771929824561403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:48:54,672] Trial 62 finished with value: 0.7961165048543689 and parameters: {'learning_rate': 0.007751674405788374, 'num_hidden_layers': 7, 'num_hidden_units': 348, 'dropout_rate': 0.0649522004762056, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 59 with value: 0.8771929824561403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:49:16,083] Trial 63 finished with value: 0.8288288288288288 and parameters: {'learning_rate': 0.007096543065275659, 'num_hidden_layers': 5, 'num_hidden_units': 260, 'dropout_rate': 0.020563458300743027, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 59 with value: 0.8771929824561403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:49:37,855] Trial 64 finished with value: 0.8318584070796459 and parameters: {'learning_rate': 0.00665130294450332, 'num_hidden_layers': 6, 'num_hidden_units': 310, 'dropout_rate': 0.0003692793051901216, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 59 with value: 0.8771929824561403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:49:49,378] Trial 65 finished with value: 0.8376068376068376 and parameters: {'learning_rate': 0.00788899840493295, 'num_hidden_layers': 5, 'num_hidden_units': 259, 'dropout_rate': 0.03499182248960072, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 59 with value: 0.8771929824561403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:49:58,276] Trial 66 finished with value: 0.6571428571428571 and parameters: {'learning_rate': 0.007232653005131283, 'num_hidden_layers': 6, 'num_hidden_units': 285, 'dropout_rate': 0.015624037781169872, 'optimizer': 'sgd', 'activation': 'elu', 'batch_size': 19}. Best is trial 59 with value: 0.8771929824561403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:50:09,318] Trial 67 finished with value: 0.8245614035087719 and parameters: {'learning_rate': 0.007620042530726945, 'num_hidden_layers': 5, 'num_hidden_units': 224, 'dropout_rate': 0.05926994518322447, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 59 with value: 0.8771929824561403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:50:20,921] Trial 68 finished with value: 0.7962962962962963 and parameters: {'learning_rate': 0.006531209138324239, 'num_hidden_layers': 5, 'num_hidden_units': 331, 'dropout_rate': 0.027673536366139184, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 38}. Best is trial 59 with value: 0.8771929824561403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:50:37,820] Trial 69 finished with value: 0.8947368421052632 and parameters: {'learning_rate': 0.006307081982596653, 'num_hidden_layers': 8, 'num_hidden_units': 346, 'dropout_rate': 0.04986643115094616, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:50:53,103] Trial 70 finished with value: 0.7889908256880733 and parameters: {'learning_rate': 0.006303540584447883, 'num_hidden_layers': 8, 'num_hidden_units': 356, 'dropout_rate': 0.04503164010155221, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:51:06,804] Trial 71 finished with value: 0.8571428571428572 and parameters: {'learning_rate': 0.0069542218643464, 'num_hidden_layers': 8, 'num_hidden_units': 303, 'dropout_rate': 0.014462517216036992, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:51:23,198] Trial 72 finished with value: 0.8717948717948717 and parameters: {'learning_rate': 0.006923940344550155, 'num_hidden_layers': 8, 'num_hidden_units': 383, 'dropout_rate': 0.016789103109383953, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:51:39,528] Trial 73 finished with value: 0.8620689655172413 and parameters: {'learning_rate': 0.006915160727107122, 'num_hidden_layers': 8, 'num_hidden_units': 383, 'dropout_rate': 0.03430512503329418, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:51:54,059] Trial 74 finished with value: 0.8073394495412843 and parameters: {'learning_rate': 0.006875088703977817, 'num_hidden_layers': 7, 'num_hidden_units': 378, 'dropout_rate': 0.07204954390650059, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:52:16,673] Trial 75 finished with value: 0.8288288288288288 and parameters: {'learning_rate': 0.007292300752918538, 'num_hidden_layers': 8, 'num_hidden_units': 404, 'dropout_rate': 0.03803367004612962, 'optimizer': 'sgd', 'activation': 'sigmoid', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:52:26,319] Trial 76 finished with value: 0.6493506493506493 and parameters: {'learning_rate': 0.0063657321892834455, 'num_hidden_layers': 8, 'num_hidden_units': 380, 'dropout_rate': 0.04994609674607199, 'optimizer': 'sgd', 'activation': 'elu', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:52:39,115] Trial 77 finished with value: 0.8468468468468469 and parameters: {'learning_rate': 0.005790990757633459, 'num_hidden_layers': 7, 'num_hidden_units': 338, 'dropout_rate': 0.0006749374397484673, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:52:57,051] Trial 78 finished with value: 0.8672566371681416 and parameters: {'learning_rate': 0.007489094139992666, 'num_hidden_layers': 8, 'num_hidden_units': 359, 'dropout_rate': 0.0765097593852073, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:53:12,819] Trial 79 finished with value: 0.8448275862068965 and parameters: {'learning_rate': 0.007710485717719971, 'num_hidden_layers': 7, 'num_hidden_units': 356, 'dropout_rate': 0.08286523499170144, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:53:26,096] Trial 80 finished with value: 0.8596491228070176 and parameters: {'learning_rate': 0.007200885694221919, 'num_hidden_layers': 8, 'num_hidden_units': 318, 'dropout_rate': 0.05439282285300613, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:53:43,164] Trial 81 finished with value: 0.8547008547008548 and parameters: {'learning_rate': 0.006733994220423504, 'num_hidden_layers': 8, 'num_hidden_units': 368, 'dropout_rate': 0.028792790517274593, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:54:01,296] Trial 82 finished with value: 0.7818181818181819 and parameters: {'learning_rate': 0.007447691221636081, 'num_hidden_layers': 8, 'num_hidden_units': 414, 'dropout_rate': 0.038486804446941955, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:54:14,967] Trial 83 finished with value: 0.8392857142857142 and parameters: {'learning_rate': 0.007869311043690267, 'num_hidden_layers': 7, 'num_hidden_units': 294, 'dropout_rate': 0.02026907569444173, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:54:28,396] Trial 84 finished with value: 0.8275862068965518 and parameters: {'learning_rate': 0.006967650274119508, 'num_hidden_layers': 8, 'num_hidden_units': 272, 'dropout_rate': 0.05224581787848145, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:54:44,116] Trial 85 finished with value: 0.7256637168141593 and parameters: {'learning_rate': 0.00657335559140597, 'num_hidden_layers': 8, 'num_hidden_units': 322, 'dropout_rate': 0.07083203198368693, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:55:03,732] Trial 86 finished with value: 0.8595041322314049 and parameters: {'learning_rate': 0.007445607077957843, 'num_hidden_layers': 8, 'num_hidden_units': 391, 'dropout_rate': 0.027888488964193204, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:55:19,918] Trial 87 finished with value: 0.8073394495412843 and parameters: {'learning_rate': 0.007026102060443658, 'num_hidden_layers': 7, 'num_hidden_units': 430, 'dropout_rate': 0.012585142279510058, 'optimizer': 'sgd', 'activation': 'sigmoid', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:55:31,807] Trial 88 finished with value: 0.8363636363636363 and parameters: {'learning_rate': 0.006126727322262799, 'num_hidden_layers': 7, 'num_hidden_units': 352, 'dropout_rate': 0.04071633865329799, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 38}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:55:44,872] Trial 89 finished with value: 0.8037383177570093 and parameters: {'learning_rate': 0.008008584280369881, 'num_hidden_layers': 8, 'num_hidden_units': 331, 'dropout_rate': 0.05538778780483712, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:55:57,793] Trial 90 finished with value: 0.7894736842105263 and parameters: {'learning_rate': 0.0067167600694476295, 'num_hidden_layers': 6, 'num_hidden_units': 310, 'dropout_rate': 0.011397191805291602, 'optimizer': 'sgd', 'activation': 'elu', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:56:13,364] Trial 91 finished with value: 0.7999999999999999 and parameters: {'learning_rate': 0.0072068393912768135, 'num_hidden_layers': 8, 'num_hidden_units': 316, 'dropout_rate': 0.05501197731661227, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:56:29,084] Trial 92 finished with value: 0.8288288288288288 and parameters: {'learning_rate': 0.007169083361016515, 'num_hidden_layers': 8, 'num_hidden_units': 382, 'dropout_rate': 0.025823702103524585, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:56:45,129] Trial 93 finished with value: 0.7522935779816513 and parameters: {'learning_rate': 0.007560710171046952, 'num_hidden_layers': 8, 'num_hidden_units': 340, 'dropout_rate': 0.07610402448236606, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:57:00,211] Trial 94 finished with value: 0.8392857142857142 and parameters: {'learning_rate': 0.007313379784351833, 'num_hidden_layers': 8, 'num_hidden_units': 364, 'dropout_rate': 0.06182582480763047, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:57:13,748] Trial 95 finished with value: 0.6956521739130433 and parameters: {'learning_rate': 0.00831925413141925, 'num_hidden_layers': 8, 'num_hidden_units': 269, 'dropout_rate': 0.04139595246045348, 'optimizer': 'adam', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:57:28,539] Trial 96 finished with value: 0.6211180124223602 and parameters: {'learning_rate': 0.006917044205165747, 'num_hidden_layers': 7, 'num_hidden_units': 302, 'dropout_rate': 0.008507576574274135, 'optimizer': 'rmsprop', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:57:39,077] Trial 97 finished with value: 0.8073394495412843 and parameters: {'learning_rate': 0.00785887231729661, 'num_hidden_layers': 5, 'num_hidden_units': 279, 'dropout_rate': 0.08678708572891455, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:57:52,954] Trial 98 finished with value: 0.8318584070796459 and parameters: {'learning_rate': 0.007655344845957889, 'num_hidden_layers': 7, 'num_hidden_units': 321, 'dropout_rate': 0.021456327153986245, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:58:06,131] Trial 99 finished with value: 0.8474576271186439 and parameters: {'learning_rate': 0.006425449286995026, 'num_hidden_layers': 8, 'num_hidden_units': 294, 'dropout_rate': 0.03302240354397723, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:58:15,281] Trial 100 finished with value: 0.7692307692307692 and parameters: {'learning_rate': 0.008038351301338563, 'num_hidden_layers': 4, 'num_hidden_units': 255, 'dropout_rate': 0.00021674448323459605, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:58:37,985] Trial 101 finished with value: 0.8739495798319327 and parameters: {'learning_rate': 0.007520451329651969, 'num_hidden_layers': 8, 'num_hidden_units': 395, 'dropout_rate': 0.02435333950395524, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:59:02,427] Trial 102 finished with value: 0.7962962962962963 and parameters: {'learning_rate': 0.007510727307619283, 'num_hidden_layers': 8, 'num_hidden_units': 397, 'dropout_rate': 0.048636066499324386, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:59:25,926] Trial 103 finished with value: 0.8141592920353982 and parameters: {'learning_rate': 0.007155066643735604, 'num_hidden_layers': 8, 'num_hidden_units': 410, 'dropout_rate': 0.034033641047239584, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 10:59:43,580] Trial 104 finished with value: 0.8448275862068965 and parameters: {'learning_rate': 0.006824694158261416, 'num_hidden_layers': 8, 'num_hidden_units': 346, 'dropout_rate': 0.015932207514259646, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:00:06,125] Trial 105 finished with value: 0.8448275862068965 and parameters: {'learning_rate': 0.007732606022583047, 'num_hidden_layers': 8, 'num_hidden_units': 424, 'dropout_rate': 0.06155487061826172, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:00:23,114] Trial 106 finished with value: 0.8275862068965518 and parameters: {'learning_rate': 0.007380870636560268, 'num_hidden_layers': 6, 'num_hidden_units': 360, 'dropout_rate': 0.0221042541727856, 'optimizer': 'sgd', 'activation': 'sigmoid', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:00:32,845] Trial 107 finished with value: 0.8108108108108109 and parameters: {'learning_rate': 0.008314462812498133, 'num_hidden_layers': 5, 'num_hidden_units': 374, 'dropout_rate': 0.008021668274315268, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 38}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:00:49,127] Trial 108 finished with value: 0.6222222222222222 and parameters: {'learning_rate': 0.007122676086673691, 'num_hidden_layers': 7, 'num_hidden_units': 325, 'dropout_rate': 0.04627827192439995, 'optimizer': 'adam', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:00:59,158] Trial 109 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.007978390629974286, 'num_hidden_layers': 4, 'num_hidden_units': 392, 'dropout_rate': 0.03235163844888093, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:01:10,241] Trial 110 finished with value: 0.7796610169491526 and parameters: {'learning_rate': 0.008024890418858177, 'num_hidden_layers': 4, 'num_hidden_units': 395, 'dropout_rate': 0.033589452029912335, 'optimizer': 'rmsprop', 'activation': 'elu', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:01:23,191] Trial 111 finished with value: 0.8672566371681416 and parameters: {'learning_rate': 0.007529622259494436, 'num_hidden_layers': 4, 'num_hidden_units': 443, 'dropout_rate': 0.02121175046899816, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:01:34,902] Trial 112 finished with value: 0.8547008547008548 and parameters: {'learning_rate': 0.007503072470505834, 'num_hidden_layers': 4, 'num_hidden_units': 449, 'dropout_rate': 0.009996574395872638, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:01:46,691] Trial 113 finished with value: 0.8256880733944955 and parameters: {'learning_rate': 0.007857851565271497, 'num_hidden_layers': 4, 'num_hidden_units': 474, 'dropout_rate': 0.023073933852799967, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:01:57,967] Trial 114 finished with value: 0.7962962962962963 and parameters: {'learning_rate': 0.006874397792408826, 'num_hidden_layers': 4, 'num_hidden_units': 385, 'dropout_rate': 0.040878546857098116, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:02:10,163] Trial 115 finished with value: 0.8495575221238939 and parameters: {'learning_rate': 0.007668345734365875, 'num_hidden_layers': 4, 'num_hidden_units': 445, 'dropout_rate': 0.01644976943559396, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:02:21,435] Trial 116 finished with value: 0.8467153284671532 and parameters: {'learning_rate': 0.00837712806406251, 'num_hidden_layers': 4, 'num_hidden_units': 408, 'dropout_rate': 0.029365491276122452, 'optimizer': 'sgd', 'activation': 'relu', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:02:33,805] Trial 117 finished with value: 0.8347826086956522 and parameters: {'learning_rate': 0.008106784270907243, 'num_hidden_layers': 5, 'num_hidden_units': 366, 'dropout_rate': 0.0007525237053658288, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:02:43,970] Trial 118 finished with value: 0.8073394495412843 and parameters: {'learning_rate': 0.006552084885220336, 'num_hidden_layers': 4, 'num_hidden_units': 334, 'dropout_rate': 0.06548978607488133, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 19}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:03:01,184] Trial 119 finished with value: 0.864406779661017 and parameters: {'learning_rate': 0.007271707319027716, 'num_hidden_layers': 5, 'num_hidden_units': 423, 'dropout_rate': 0.047372746108332746, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:03:19,253] Trial 120 finished with value: 0.8869565217391304 and parameters: {'learning_rate': 0.007344635891143432, 'num_hidden_layers': 5, 'num_hidden_units': 423, 'dropout_rate': 0.04666846334014383, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:03:35,783] Trial 121 finished with value: 0.864406779661017 and parameters: {'learning_rate': 0.0073574559667909855, 'num_hidden_layers': 5, 'num_hidden_units': 419, 'dropout_rate': 0.045237079315730636, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:03:53,202] Trial 122 finished with value: 0.8717948717948717 and parameters: {'learning_rate': 0.007744815136037916, 'num_hidden_layers': 5, 'num_hidden_units': 431, 'dropout_rate': 0.021681250623411672, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:04:11,435] Trial 123 finished with value: 0.8214285714285715 and parameters: {'learning_rate': 0.007859529410740348, 'num_hidden_layers': 5, 'num_hidden_units': 435, 'dropout_rate': 0.017876767371333282, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:04:29,093] Trial 124 finished with value: 0.8288288288288288 and parameters: {'learning_rate': 0.007598540734114232, 'num_hidden_layers': 5, 'num_hidden_units': 452, 'dropout_rate': 0.0070947880798686086, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:04:57,789] Trial 125 finished with value: 0.8363636363636363 and parameters: {'learning_rate': 0.00815759331340525, 'num_hidden_layers': 6, 'num_hidden_units': 400, 'dropout_rate': 0.026188751871008192, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:05:36,419] Trial 126 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.007039299530265103, 'num_hidden_layers': 5, 'num_hidden_units': 479, 'dropout_rate': 0.056246002760250484, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:06:10,017] Trial 127 finished with value: 0.8518518518518519 and parameters: {'learning_rate': 0.00703260648958964, 'num_hidden_layers': 4, 'num_hidden_units': 490, 'dropout_rate': 0.07061417898037162, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:06:50,603] Trial 128 finished with value: 0.8521739130434782 and parameters: {'learning_rate': 0.006752239531508858, 'num_hidden_layers': 5, 'num_hidden_units': 471, 'dropout_rate': 0.055766302281813306, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:07:25,017] Trial 129 finished with value: 0.8214285714285715 and parameters: {'learning_rate': 0.007455538430781668, 'num_hidden_layers': 4, 'num_hidden_units': 460, 'dropout_rate': 0.03806477574731311, 'optimizer': 'sgd', 'activation': 'sigmoid', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:08:08,919] Trial 130 finished with value: 0.8288288288288288 and parameters: {'learning_rate': 0.008522302452144534, 'num_hidden_layers': 6, 'num_hidden_units': 505, 'dropout_rate': 0.0774997725217994, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:08:47,718] Trial 131 finished with value: 0.8571428571428572 and parameters: {'learning_rate': 0.007895274078523556, 'num_hidden_layers': 5, 'num_hidden_units': 442, 'dropout_rate': 0.01633406562703579, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:09:09,085] Trial 132 finished with value: 0.8849557522123893 and parameters: {'learning_rate': 0.007718512293435558, 'num_hidden_layers': 5, 'num_hidden_units': 469, 'dropout_rate': 0.028150576274596446, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:09:30,504] Trial 133 finished with value: 0.8073394495412843 and parameters: {'learning_rate': 0.007081111529152365, 'num_hidden_layers': 5, 'num_hidden_units': 466, 'dropout_rate': 0.09277597695799356, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:09:48,504] Trial 134 finished with value: 0.8666666666666666 and parameters: {'learning_rate': 0.00732462725946733, 'num_hidden_layers': 5, 'num_hidden_units': 480, 'dropout_rate': 0.05624882138482164, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:10:07,678] Trial 135 finished with value: 0.7884615384615384 and parameters: {'learning_rate': 0.007318524710144565, 'num_hidden_layers': 5, 'num_hidden_units': 479, 'dropout_rate': 0.0658847876314744, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:10:32,748] Trial 136 finished with value: 0.12307692307692307 and parameters: {'learning_rate': 0.006642497412463652, 'num_hidden_layers': 5, 'num_hidden_units': 455, 'dropout_rate': 0.056483176429831805, 'optimizer': 'adam', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:10:49,981] Trial 137 finished with value: 0.7692307692307692 and parameters: {'learning_rate': 0.007493604874676159, 'num_hidden_layers': 5, 'num_hidden_units': 431, 'dropout_rate': 0.07839128977917417, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:11:15,915] Trial 138 finished with value: 0.7499999999999999 and parameters: {'learning_rate': 0.006274702909061925, 'num_hidden_layers': 6, 'num_hidden_units': 476, 'dropout_rate': 0.04932132653031821, 'optimizer': 'rmsprop', 'activation': 'relu', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:11:43,779] Trial 139 finished with value: 0.8727272727272727 and parameters: {'learning_rate': 0.007026320083022164, 'num_hidden_layers': 5, 'num_hidden_units': 500, 'dropout_rate': 0.028707649079744345, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:12:01,465] Trial 140 finished with value: 0.8 and parameters: {'learning_rate': 0.006939448715514379, 'num_hidden_layers': 5, 'num_hidden_units': 488, 'dropout_rate': 0.02909459828726458, 'optimizer': 'sgd', 'activation': 'elu', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:12:24,221] Trial 141 finished with value: 0.8672566371681416 and parameters: {'learning_rate': 0.007227984178274443, 'num_hidden_layers': 5, 'num_hidden_units': 506, 'dropout_rate': 0.03984561084121682, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:12:49,234] Trial 142 finished with value: 0.8288288288288288 and parameters: {'learning_rate': 0.007174998041830564, 'num_hidden_layers': 5, 'num_hidden_units': 500, 'dropout_rate': 0.035551774151892764, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:13:12,825] Trial 143 finished with value: 0.8928571428571428 and parameters: {'learning_rate': 0.007615029621257584, 'num_hidden_layers': 5, 'num_hidden_units': 494, 'dropout_rate': 0.02247172794804353, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:13:32,997] Trial 144 finished with value: 0.8495575221238939 and parameters: {'learning_rate': 0.007664802405051223, 'num_hidden_layers': 5, 'num_hidden_units': 491, 'dropout_rate': 0.023553235245873952, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:13:55,980] Trial 145 finished with value: 0.8392857142857142 and parameters: {'learning_rate': 0.00784799094180418, 'num_hidden_layers': 5, 'num_hidden_units': 510, 'dropout_rate': 0.016312487217778372, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:14:13,578] Trial 146 finished with value: 0.8547008547008548 and parameters: {'learning_rate': 0.007503531600704452, 'num_hidden_layers': 4, 'num_hidden_units': 464, 'dropout_rate': 0.02917539321429469, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:14:33,179] Trial 147 finished with value: 0.8141592920353982 and parameters: {'learning_rate': 0.007993880955520328, 'num_hidden_layers': 5, 'num_hidden_units': 410, 'dropout_rate': 0.04411112223090387, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:14:52,715] Trial 148 finished with value: 0.8598130841121495 and parameters: {'learning_rate': 0.006780009043872297, 'num_hidden_layers': 6, 'num_hidden_units': 347, 'dropout_rate': 0.01087748268662872, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:15:10,045] Trial 149 finished with value: 0.8545454545454545 and parameters: {'learning_rate': 0.008221964791268077, 'num_hidden_layers': 4, 'num_hidden_units': 493, 'dropout_rate': 0.06759220496423053, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:15:19,541] Trial 150 finished with value: 0.8468468468468469 and parameters: {'learning_rate': 0.006470535218446792, 'num_hidden_layers': 5, 'num_hidden_units': 442, 'dropout_rate': 0.035027244723314206, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 38}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:15:38,979] Trial 151 finished with value: 0.8421052631578947 and parameters: {'learning_rate': 0.007083882823194625, 'num_hidden_layers': 5, 'num_hidden_units': 508, 'dropout_rate': 0.04157671608535107, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:15:59,059] Trial 152 finished with value: 0.8521739130434782 and parameters: {'learning_rate': 0.007711777901594712, 'num_hidden_layers': 5, 'num_hidden_units': 512, 'dropout_rate': 0.025351071801812022, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:16:18,189] Trial 153 finished with value: 0.8495575221238939 and parameters: {'learning_rate': 0.00724087299925691, 'num_hidden_layers': 5, 'num_hidden_units': 486, 'dropout_rate': 0.051742173491510654, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:16:41,607] Trial 154 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.0075279253671474665, 'num_hidden_layers': 5, 'num_hidden_units': 374, 'dropout_rate': 0.04110269568828957, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:17:03,394] Trial 155 finished with value: 0.8108108108108109 and parameters: {'learning_rate': 0.007625690813531959, 'num_hidden_layers': 5, 'num_hidden_units': 386, 'dropout_rate': 0.1109029601943892, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:17:24,763] Trial 156 finished with value: 0.8771929824561403 and parameters: {'learning_rate': 0.008046105651966767, 'num_hidden_layers': 6, 'num_hidden_units': 373, 'dropout_rate': 0.015428818486239919, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:17:46,592] Trial 157 finished with value: 0.8750000000000001 and parameters: {'learning_rate': 0.007992978710139877, 'num_hidden_layers': 6, 'num_hidden_units': 375, 'dropout_rate': 0.010573582502544475, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:18:11,153] Trial 158 finished with value: 0.8392857142857142 and parameters: {'learning_rate': 0.007972639004607611, 'num_hidden_layers': 6, 'num_hidden_units': 371, 'dropout_rate': 0.009547110273871721, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 69 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:18:30,897] Trial 159 finished with value: 0.9090909090909091 and parameters: {'learning_rate': 0.00838577805415959, 'num_hidden_layers': 6, 'num_hidden_units': 375, 'dropout_rate': 0.007392878523957584, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:18:55,059] Trial 160 finished with value: 0.6229508196721312 and parameters: {'learning_rate': 0.00829266872320905, 'num_hidden_layers': 6, 'num_hidden_units': 375, 'dropout_rate': 0.0008804363362514712, 'optimizer': 'adam', 'activation': 'sigmoid', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:19:16,220] Trial 161 finished with value: 0.8448275862068965 and parameters: {'learning_rate': 0.00800484138694732, 'num_hidden_layers': 6, 'num_hidden_units': 393, 'dropout_rate': 0.01856215732186385, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:19:33,692] Trial 162 finished with value: 0.8695652173913043 and parameters: {'learning_rate': 0.00841955560924824, 'num_hidden_layers': 6, 'num_hidden_units': 356, 'dropout_rate': 0.010629147394949412, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:19:55,072] Trial 163 finished with value: 0.817391304347826 and parameters: {'learning_rate': 0.008377677457755172, 'num_hidden_layers': 6, 'num_hidden_units': 355, 'dropout_rate': 0.0075610765663215495, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:20:13,828] Trial 164 finished with value: 0.8376068376068376 and parameters: {'learning_rate': 0.008529793938262356, 'num_hidden_layers': 6, 'num_hidden_units': 377, 'dropout_rate': 0.024237539418600608, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:20:33,328] Trial 165 finished with value: 0.8076923076923077 and parameters: {'learning_rate': 0.00885729446755632, 'num_hidden_layers': 6, 'num_hidden_units': 403, 'dropout_rate': 0.00857623831463385, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:20:51,353] Trial 166 finished with value: 0.8245614035087719 and parameters: {'learning_rate': 0.008608452174180888, 'num_hidden_layers': 6, 'num_hidden_units': 389, 'dropout_rate': 8.103319153809907e-05, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:21:16,301] Trial 167 finished with value: 0.6614173228346456 and parameters: {'learning_rate': 0.00815451699685761, 'num_hidden_layers': 6, 'num_hidden_units': 366, 'dropout_rate': 0.017154988727800198, 'optimizer': 'rmsprop', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:21:33,666] Trial 168 finished with value: 0.7850467289719626 and parameters: {'learning_rate': 0.007784421933437056, 'num_hidden_layers': 5, 'num_hidden_units': 339, 'dropout_rate': 0.03031213942572219, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:21:53,158] Trial 169 finished with value: 0.8852459016393442 and parameters: {'learning_rate': 0.008146829287817023, 'num_hidden_layers': 5, 'num_hidden_units': 415, 'dropout_rate': 0.03700728358690011, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:22:34,586] Trial 170 finished with value: 0.7652173913043478 and parameters: {'learning_rate': 0.008074350684773404, 'num_hidden_layers': 5, 'num_hidden_units': 422, 'dropout_rate': 0.041603763255491616, 'optimizer': 'sgd', 'activation': 'relu', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:22:58,513] Trial 171 finished with value: 0.7663551401869158 and parameters: {'learning_rate': 0.008426652149151413, 'num_hidden_layers': 5, 'num_hidden_units': 400, 'dropout_rate': 0.015189311915552695, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:23:21,057] Trial 172 finished with value: 0.7735849056603773 and parameters: {'learning_rate': 0.007816850039330737, 'num_hidden_layers': 5, 'num_hidden_units': 381, 'dropout_rate': 0.032518071401647364, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:23:44,408] Trial 173 finished with value: 0.8648648648648649 and parameters: {'learning_rate': 0.008161334680345429, 'num_hidden_layers': 5, 'num_hidden_units': 413, 'dropout_rate': 0.023249699674798518, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:24:06,883] Trial 174 finished with value: 0.8403361344537814 and parameters: {'learning_rate': 0.00890371880602459, 'num_hidden_layers': 5, 'num_hidden_units': 361, 'dropout_rate': 0.04592407666343112, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:24:29,648] Trial 175 finished with value: 0.8376068376068376 and parameters: {'learning_rate': 0.007951241899521864, 'num_hidden_layers': 5, 'num_hidden_units': 390, 'dropout_rate': 0.010661217016945314, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:24:54,776] Trial 176 finished with value: 0.7592592592592592 and parameters: {'learning_rate': 0.00858476147473553, 'num_hidden_layers': 6, 'num_hidden_units': 352, 'dropout_rate': 0.033649350074586866, 'optimizer': 'sgd', 'activation': 'elu', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:25:18,638] Trial 177 finished with value: 0.8256880733944955 and parameters: {'learning_rate': 0.008290690793608791, 'num_hidden_layers': 5, 'num_hidden_units': 368, 'dropout_rate': 0.02318344429042844, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:25:41,024] Trial 178 finished with value: 0.8771929824561403 and parameters: {'learning_rate': 0.007670327251387168, 'num_hidden_layers': 6, 'num_hidden_units': 406, 'dropout_rate': 0.06114996792699716, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:26:03,867] Trial 179 finished with value: 0.8547008547008548 and parameters: {'learning_rate': 0.007471572787254036, 'num_hidden_layers': 5, 'num_hidden_units': 428, 'dropout_rate': 0.05500181895945168, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:26:27,832] Trial 180 finished with value: 0.8545454545454545 and parameters: {'learning_rate': 0.007680175037820714, 'num_hidden_layers': 5, 'num_hidden_units': 401, 'dropout_rate': 0.06603949133265603, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:26:54,214] Trial 181 finished with value: 0.8521739130434782 and parameters: {'learning_rate': 0.007365273533687898, 'num_hidden_layers': 6, 'num_hidden_units': 416, 'dropout_rate': 0.041398227413217185, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:27:17,762] Trial 182 finished with value: 0.7889908256880733 and parameters: {'learning_rate': 0.007795181085249318, 'num_hidden_layers': 6, 'num_hidden_units': 378, 'dropout_rate': 0.15683969197899406, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:27:39,702] Trial 183 finished with value: 0.8392857142857142 and parameters: {'learning_rate': 0.008074458089312087, 'num_hidden_layers': 6, 'num_hidden_units': 389, 'dropout_rate': 0.015150210958897601, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:28:10,677] Trial 184 finished with value: 0.75 and parameters: {'learning_rate': 0.005568257111241146, 'num_hidden_layers': 7, 'num_hidden_units': 403, 'dropout_rate': 0.13414910701687704, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:28:38,348] Trial 185 finished with value: 0.8760330578512396 and parameters: {'learning_rate': 0.007613884018025792, 'num_hidden_layers': 6, 'num_hidden_units': 498, 'dropout_rate': 0.03270076634553313, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:29:19,532] Trial 186 finished with value: 0.8495575221238939 and parameters: {'learning_rate': 0.007414658390457504, 'num_hidden_layers': 6, 'num_hidden_units': 483, 'dropout_rate': 0.05084532552313044, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:29:41,530] Trial 187 finished with value: 0.8596491228070176 and parameters: {'learning_rate': 0.007648558051793971, 'num_hidden_layers': 5, 'num_hidden_units': 498, 'dropout_rate': 0.03282445434948578, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:29:52,508] Trial 188 finished with value: 0.7884615384615384 and parameters: {'learning_rate': 0.006944597586294222, 'num_hidden_layers': 5, 'num_hidden_units': 466, 'dropout_rate': 0.05975148464096948, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 38}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:30:20,166] Trial 189 finished with value: 0.8181818181818182 and parameters: {'learning_rate': 0.007575952164884823, 'num_hidden_layers': 6, 'num_hidden_units': 499, 'dropout_rate': 0.08801691347983509, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:30:40,734] Trial 190 finished with value: 0.7999999999999999 and parameters: {'learning_rate': 0.007357759041980759, 'num_hidden_layers': 5, 'num_hidden_units': 411, 'dropout_rate': 0.026980942466892144, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:31:05,614] Trial 191 finished with value: 0.8256880733944955 and parameters: {'learning_rate': 0.007921760999544546, 'num_hidden_layers': 6, 'num_hidden_units': 374, 'dropout_rate': 0.007643389766172718, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:31:28,816] Trial 192 finished with value: 0.8032786885245902 and parameters: {'learning_rate': 0.008259187495665064, 'num_hidden_layers': 6, 'num_hidden_units': 392, 'dropout_rate': 0.03659454186967076, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:31:42,212] Trial 193 finished with value: 0.7555555555555555 and parameters: {'learning_rate': 0.007799834091048912, 'num_hidden_layers': 6, 'num_hidden_units': 41, 'dropout_rate': 0.018150395433512826, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:32:05,248] Trial 194 finished with value: 0.7272727272727273 and parameters: {'learning_rate': 0.007136099178998031, 'num_hidden_layers': 6, 'num_hidden_units': 353, 'dropout_rate': 0.22515132580778643, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:32:27,491] Trial 195 finished with value: 0.8869565217391304 and parameters: {'learning_rate': 0.008709137327579058, 'num_hidden_layers': 5, 'num_hidden_units': 381, 'dropout_rate': 0.0005121305987773155, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:32:50,461] Trial 196 finished with value: 0.8620689655172413 and parameters: {'learning_rate': 0.006091787784578423, 'num_hidden_layers': 5, 'num_hidden_units': 384, 'dropout_rate': 0.04374822984965334, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:33:11,791] Trial 197 finished with value: 0.6194690265486725 and parameters: {'learning_rate': 0.0066805280133746285, 'num_hidden_layers': 5, 'num_hidden_units': 401, 'dropout_rate': 0.0017220292846743639, 'optimizer': 'adam', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:33:36,699] Trial 198 finished with value: 0.8288288288288288 and parameters: {'learning_rate': 0.007560570321684414, 'num_hidden_layers': 5, 'num_hidden_units': 436, 'dropout_rate': 0.02513056453707138, 'optimizer': 'sgd', 'activation': 'sigmoid', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 11:34:00,877] Trial 199 finished with value: 0.8347826086956522 and parameters: {'learning_rate': 0.004818832659925317, 'num_hidden_layers': 5, 'num_hidden_units': 420, 'dropout_rate': 0.04925155461911075, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}. Best is trial 159 with value: 0.9090909090909091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor conjunto de hiperparámetros: {'learning_rate': 0.00838577805415959, 'num_hidden_layers': 6, 'num_hidden_units': 375, 'dropout_rate': 0.007392878523957584, 'optimizer': 'sgd', 'activation': 'tanh', 'batch_size': 9}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "def objective(trial):\n",
    "    # Definir espacio de búsqueda de hiperparámetros\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2)\n",
    "    num_hidden_layers = trial.suggest_int(\"num_hidden_layers\", 1, 8)\n",
    "    num_hidden_units = trial.suggest_int(\"num_hidden_units\", 16, 512)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 0.5)\n",
    "    optimizer = trial.suggest_categorical(\"optimizer\", [\"adam\", \"sgd\", \"rmsprop\"])\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\", \"sigmoid\", \"elu\"])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [608//16, 608//32, 608//64])\n",
    "    \n",
    "    # Construir el modelo de red neuronal con los hiperparámetros\n",
    "    model = keras.Sequential()\n",
    "    for _ in range(num_hidden_layers):\n",
    "        model.add(keras.layers.Dense(num_hidden_units, activation=activation))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.Dropout(dropout_rate))\n",
    "        \n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compilar y entrenar el modelo\n",
    "    if optimizer == \"adam\":\n",
    "        optimizer_obj = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == \"sgd\":\n",
    "        optimizer_obj = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == \"rmsprop\":\n",
    "        optimizer_obj = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(\"Optimizador no soportado\")\n",
    "\n",
    "    model.compile(optimizer=optimizer_obj,\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        patience=20,\n",
    "        min_delta=0.001,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=batch_size, verbose=0, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "    \n",
    "    # Calcular el puntaje F1\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    # Almacenar los pesos del modelo como un atributo del ensayo de Optuna\n",
    "    trial.set_user_attr(\"model_weights\", model.get_weights())\n",
    "    \n",
    "    # Guardar el modelo en los atributos de usuario del mejor intento\n",
    "    trial.set_user_attr('model', model)\n",
    "\n",
    "    return f1\n",
    "\n",
    "# Crear un estudio Optuna\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "# Obtener el mejor conjunto de hiperparámetros\n",
    "best_params = study.best_params\n",
    "print(\"Mejor conjunto de hiperparámetros:\", best_params)\n",
    "\n",
    "# Después de la optimización, antes de guardar el objeto Study\n",
    "best_model = study.best_trial.user_attrs.get('model')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.8762 - accuracy: 0.5514WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 8s 12ms/step - loss: 0.8791 - accuracy: 0.5453\n",
      "Epoch 2/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.6549 - accuracy: 0.6481WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6549 - accuracy: 0.6481\n",
      "Epoch 3/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.6018 - accuracy: 0.7037WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6129 - accuracy: 0.7016\n",
      "Epoch 4/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.5889 - accuracy: 0.6855WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5821 - accuracy: 0.6914\n",
      "Epoch 5/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.5607 - accuracy: 0.7078WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5607 - accuracy: 0.7078\n",
      "Epoch 6/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.5062 - accuracy: 0.7505WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.5043 - accuracy: 0.7510\n",
      "Epoch 7/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.4837 - accuracy: 0.7631WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4846 - accuracy: 0.7634\n",
      "Epoch 8/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.4895 - accuracy: 0.7735WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4969 - accuracy: 0.7695\n",
      "Epoch 9/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.4196 - accuracy: 0.8197WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4186 - accuracy: 0.8189\n",
      "Epoch 10/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.4562 - accuracy: 0.7644WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4558 - accuracy: 0.7654\n",
      "Epoch 11/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.4622 - accuracy: 0.8039WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4607 - accuracy: 0.8025\n",
      "Epoch 12/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.4635 - accuracy: 0.7757WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4635 - accuracy: 0.7757\n",
      "Epoch 13/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.4207 - accuracy: 0.8222WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.4255 - accuracy: 0.8148\n",
      "Epoch 14/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.4194 - accuracy: 0.8226WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4113 - accuracy: 0.8272\n",
      "Epoch 15/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.3657 - accuracy: 0.8462WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3653 - accuracy: 0.8477\n",
      "Epoch 16/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.4050 - accuracy: 0.8251WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.4050 - accuracy: 0.8251\n",
      "Epoch 17/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.3551 - accuracy: 0.8519WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3566 - accuracy: 0.8519\n",
      "Epoch 18/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.3550 - accuracy: 0.8600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.3568 - accuracy: 0.8601\n",
      "Epoch 19/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.3544 - accuracy: 0.8453WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3515 - accuracy: 0.8477\n",
      "Epoch 20/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.3108 - accuracy: 0.8733WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.3197 - accuracy: 0.8663\n",
      "Epoch 21/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.3387 - accuracy: 0.8600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3362 - accuracy: 0.8642\n",
      "Epoch 22/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.8560WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.3496 - accuracy: 0.8560\n",
      "Epoch 23/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.3386 - accuracy: 0.8756WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3475 - accuracy: 0.8724\n",
      "Epoch 24/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.3592 - accuracy: 0.8512WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.3570 - accuracy: 0.8519\n",
      "Epoch 25/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.3271 - accuracy: 0.8568WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.3226 - accuracy: 0.8601\n",
      "Epoch 26/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.3407 - accuracy: 0.8622WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3537 - accuracy: 0.8560\n",
      "Epoch 27/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.2856 - accuracy: 0.8689WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2937 - accuracy: 0.8663\n",
      "Epoch 28/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3183 - accuracy: 0.8765WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.3183 - accuracy: 0.8765\n",
      "Epoch 29/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.3225 - accuracy: 0.8644WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.3344 - accuracy: 0.8580\n",
      "Epoch 30/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.3098 - accuracy: 0.8715WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2990 - accuracy: 0.8765\n",
      "Epoch 31/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.2646 - accuracy: 0.8911WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2670 - accuracy: 0.8889\n",
      "Epoch 32/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.3516 - accuracy: 0.8519WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3356 - accuracy: 0.8601\n",
      "Epoch 33/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.2477 - accuracy: 0.9085WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2485 - accuracy: 0.9074\n",
      "Epoch 34/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.2428 - accuracy: 0.9107WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2419 - accuracy: 0.9095\n",
      "Epoch 35/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3349 - accuracy: 0.8477WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.3349 - accuracy: 0.8477\n",
      "Epoch 36/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.2597 - accuracy: 0.8976WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2786 - accuracy: 0.8868\n",
      "Epoch 37/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2597 - accuracy: 0.8868WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.2597 - accuracy: 0.8868\n",
      "Epoch 38/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.2327 - accuracy: 0.8844WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2297 - accuracy: 0.8848\n",
      "Epoch 39/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.3130 - accuracy: 0.8733WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3155 - accuracy: 0.8683\n",
      "Epoch 40/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.2716 - accuracy: 0.8847WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.2678 - accuracy: 0.8868\n",
      "Epoch 41/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.9198WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2043 - accuracy: 0.9198\n",
      "Epoch 42/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2799 - accuracy: 0.8807WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2799 - accuracy: 0.8807\n",
      "Epoch 43/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.2249 - accuracy: 0.9017WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2272 - accuracy: 0.8992\n",
      "Epoch 44/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2260 - accuracy: 0.9033WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.2260 - accuracy: 0.9033\n",
      "Epoch 45/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.3124 - accuracy: 0.8711WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3082 - accuracy: 0.8704\n",
      "Epoch 46/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.2521 - accuracy: 0.8845WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2450 - accuracy: 0.8889\n",
      "Epoch 47/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2035 - accuracy: 0.9095WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.2035 - accuracy: 0.9095\n",
      "Epoch 48/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.2876 - accuracy: 0.8761WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2831 - accuracy: 0.8786\n",
      "Epoch 49/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.2389 - accuracy: 0.9015WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2513 - accuracy: 0.8971\n",
      "Epoch 50/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1742 - accuracy: 0.9465WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1742 - accuracy: 0.9465\n",
      "Epoch 51/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.2510 - accuracy: 0.8910WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.2497 - accuracy: 0.8909\n",
      "Epoch 52/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.2257 - accuracy: 0.9216WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2209 - accuracy: 0.9259\n",
      "Epoch 53/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2933 - accuracy: 0.8539WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2933 - accuracy: 0.8539\n",
      "Epoch 54/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.2502 - accuracy: 0.9041WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2505 - accuracy: 0.9033\n",
      "Epoch 55/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.2099 - accuracy: 0.9200WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2157 - accuracy: 0.9156\n",
      "Epoch 56/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.2257 - accuracy: 0.9041WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2229 - accuracy: 0.9033\n",
      "Epoch 57/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.2911 - accuracy: 0.8761WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.2858 - accuracy: 0.8765\n",
      "Epoch 58/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.2365 - accuracy: 0.9038WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.2347 - accuracy: 0.9053\n",
      "Epoch 59/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1915 - accuracy: 0.9259WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1904 - accuracy: 0.9239\n",
      "Epoch 60/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.2088 - accuracy: 0.9119WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.2075 - accuracy: 0.9115\n",
      "Epoch 61/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.1813 - accuracy: 0.9333WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1850 - accuracy: 0.9321\n",
      "Epoch 62/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.2447 - accuracy: 0.9044WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2425 - accuracy: 0.9053\n",
      "Epoch 63/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.2194 - accuracy: 0.9020WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.2164 - accuracy: 0.9012\n",
      "Epoch 64/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.2474 - accuracy: 0.8994WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2483 - accuracy: 0.8992\n",
      "Epoch 65/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.2029 - accuracy: 0.9252WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2099 - accuracy: 0.9198\n",
      "Epoch 66/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1518 - accuracy: 0.9477WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1474 - accuracy: 0.9506\n",
      "Epoch 67/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1936 - accuracy: 0.9287WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1945 - accuracy: 0.9259\n",
      "Epoch 68/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.2265 - accuracy: 0.9089WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2192 - accuracy: 0.9115\n",
      "Epoch 69/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2060 - accuracy: 0.9095WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.2060 - accuracy: 0.9095\n",
      "Epoch 70/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.1891 - accuracy: 0.9295WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.1878 - accuracy: 0.9300\n",
      "Epoch 71/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.1389 - accuracy: 0.9489WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.1414 - accuracy: 0.9465\n",
      "Epoch 72/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.2119 - accuracy: 0.9259WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2089 - accuracy: 0.9280\n",
      "Epoch 73/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1221 - accuracy: 0.9542WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1216 - accuracy: 0.9547\n",
      "Epoch 74/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.2227 - accuracy: 0.9022WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.2378 - accuracy: 0.9053\n",
      "Epoch 75/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.2199 - accuracy: 0.8998WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2181 - accuracy: 0.8992\n",
      "Epoch 76/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1717 - accuracy: 0.9287WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.1716 - accuracy: 0.9300\n",
      "Epoch 77/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1780 - accuracy: 0.9182WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1760 - accuracy: 0.9198\n",
      "Epoch 78/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.1810 - accuracy: 0.9231WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1828 - accuracy: 0.9218\n",
      "Epoch 79/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1631 - accuracy: 0.9321WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1631 - accuracy: 0.9321\n",
      "Epoch 80/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1800 - accuracy: 0.9342WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1800 - accuracy: 0.9342\n",
      "Epoch 81/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.9300WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1885 - accuracy: 0.9300\n",
      "Epoch 82/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1877 - accuracy: 0.9194WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1811 - accuracy: 0.9239\n",
      "Epoch 83/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.1582 - accuracy: 0.9333WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1728 - accuracy: 0.9259\n",
      "Epoch 84/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.1331 - accuracy: 0.9422WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1362 - accuracy: 0.9403\n",
      "Epoch 85/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1704 - accuracy: 0.9455WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1624 - accuracy: 0.9486\n",
      "Epoch 86/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1701 - accuracy: 0.9342WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1701 - accuracy: 0.9342\n",
      "Epoch 87/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1956 - accuracy: 0.9216WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2030 - accuracy: 0.9198\n",
      "Epoch 88/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.2081 - accuracy: 0.9129WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1979 - accuracy: 0.9177\n",
      "Epoch 89/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.9568WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1327 - accuracy: 0.9568\n",
      "Epoch 90/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.9156WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1864 - accuracy: 0.9156\n",
      "Epoch 91/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1767 - accuracy: 0.9371WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1736 - accuracy: 0.9383\n",
      "Epoch 92/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1710 - accuracy: 0.9281WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1637 - accuracy: 0.9321\n",
      "Epoch 93/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.1811 - accuracy: 0.9295WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1816 - accuracy: 0.9280\n",
      "Epoch 94/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1468 - accuracy: 0.9346WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1501 - accuracy: 0.9321\n",
      "Epoch 95/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1817 - accuracy: 0.9280WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.1817 - accuracy: 0.9280\n",
      "Epoch 96/200\n",
      "49/54 [==========================>...] - ETA: 0s - loss: 0.1489 - accuracy: 0.9569WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1497 - accuracy: 0.9527\n",
      "Epoch 97/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.1008 - accuracy: 0.9644WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1060 - accuracy: 0.9609\n",
      "Epoch 98/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1363 - accuracy: 0.9477WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1452 - accuracy: 0.9424\n",
      "Epoch 99/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1615 - accuracy: 0.9424WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1615 - accuracy: 0.9424\n",
      "Epoch 100/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1948 - accuracy: 0.9308WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1919 - accuracy: 0.9321\n",
      "Epoch 101/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.2274 - accuracy: 0.9081WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2284 - accuracy: 0.9095\n",
      "Epoch 102/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.2207 - accuracy: 0.9081WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2189 - accuracy: 0.9074\n",
      "Epoch 103/200\n",
      "49/54 [==========================>...] - ETA: 0s - loss: 0.1644 - accuracy: 0.9297WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1609 - accuracy: 0.9321\n",
      "Epoch 104/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1337 - accuracy: 0.9542WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.1358 - accuracy: 0.9527\n",
      "Epoch 105/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.1232 - accuracy: 0.9556WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.1198 - accuracy: 0.9568\n",
      "Epoch 106/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1416 - accuracy: 0.9455WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1422 - accuracy: 0.9444\n",
      "Epoch 107/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1661 - accuracy: 0.9390WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1611 - accuracy: 0.9403\n",
      "Epoch 108/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1442 - accuracy: 0.9455WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1465 - accuracy: 0.9465\n",
      "Epoch 109/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1217 - accuracy: 0.9486WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1217 - accuracy: 0.9486\n",
      "Epoch 110/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1641 - accuracy: 0.9465WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1641 - accuracy: 0.9465\n",
      "Epoch 111/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.2230 - accuracy: 0.9119WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2199 - accuracy: 0.9136\n",
      "Epoch 112/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.1989 - accuracy: 0.9267WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1951 - accuracy: 0.9259\n",
      "Epoch 113/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1284 - accuracy: 0.9542WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1314 - accuracy: 0.9527\n",
      "Epoch 114/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1981 - accuracy: 0.9281WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1882 - accuracy: 0.9321\n",
      "Epoch 115/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1790 - accuracy: 0.9350WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1768 - accuracy: 0.9362\n",
      "Epoch 116/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1577 - accuracy: 0.9368WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1513 - accuracy: 0.9403\n",
      "Epoch 117/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.1367 - accuracy: 0.9509WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1365 - accuracy: 0.9506\n",
      "Epoch 118/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1148 - accuracy: 0.9499WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1125 - accuracy: 0.9506\n",
      "Epoch 119/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1185 - accuracy: 0.9521WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.1182 - accuracy: 0.9527\n",
      "Epoch 120/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9609WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1080 - accuracy: 0.9609\n",
      "Epoch 121/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1774 - accuracy: 0.9321WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1774 - accuracy: 0.9321\n",
      "Epoch 122/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.1223 - accuracy: 0.9467WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.1159 - accuracy: 0.9506\n",
      "Epoch 123/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1750 - accuracy: 0.9259WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.1750 - accuracy: 0.9259\n",
      "Epoch 124/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.1539 - accuracy: 0.9274WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1509 - accuracy: 0.9300\n",
      "Epoch 125/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1570 - accuracy: 0.9303WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1495 - accuracy: 0.9342\n",
      "Epoch 126/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.2067 - accuracy: 0.9178WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.2036 - accuracy: 0.9198\n",
      "Epoch 127/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.1762 - accuracy: 0.9289WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1707 - accuracy: 0.9321\n",
      "Epoch 128/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.1126 - accuracy: 0.9600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1224 - accuracy: 0.9568\n",
      "Epoch 129/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1463 - accuracy: 0.9477WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1485 - accuracy: 0.9444\n",
      "Epoch 130/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.1385 - accuracy: 0.9359WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1360 - accuracy: 0.9362\n",
      "Epoch 131/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1533 - accuracy: 0.9444WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1533 - accuracy: 0.9444\n",
      "Epoch 132/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1271 - accuracy: 0.9527WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1271 - accuracy: 0.9527\n",
      "Epoch 133/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1333 - accuracy: 0.9564WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1296 - accuracy: 0.9588\n",
      "Epoch 134/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.0873 - accuracy: 0.9701WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1068 - accuracy: 0.9588\n",
      "Epoch 135/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1448 - accuracy: 0.9434WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1459 - accuracy: 0.9424\n",
      "Epoch 136/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.1714 - accuracy: 0.9316WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1705 - accuracy: 0.9321\n",
      "Epoch 137/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.1542 - accuracy: 0.9467WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1577 - accuracy: 0.9465\n",
      "Epoch 138/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1253 - accuracy: 0.9586WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1232 - accuracy: 0.9588\n",
      "Epoch 139/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1318 - accuracy: 0.9486WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.1318 - accuracy: 0.9486\n",
      "Epoch 140/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1074 - accuracy: 0.9623WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1061 - accuracy: 0.9630\n",
      "Epoch 141/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1520 - accuracy: 0.9434WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1557 - accuracy: 0.9424\n",
      "Epoch 142/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1697 - accuracy: 0.9434WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1725 - accuracy: 0.9403\n",
      "Epoch 143/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1294 - accuracy: 0.9497WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.1274 - accuracy: 0.9506\n",
      "Epoch 144/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1420 - accuracy: 0.9465WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1420 - accuracy: 0.9465\n",
      "Epoch 145/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1811 - accuracy: 0.9281WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1858 - accuracy: 0.9300\n",
      "Epoch 146/200\n",
      "49/54 [==========================>...] - ETA: 0s - loss: 0.1277 - accuracy: 0.9433WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1230 - accuracy: 0.9465\n",
      "Epoch 147/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.1126 - accuracy: 0.9530WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1093 - accuracy: 0.9547\n",
      "Epoch 148/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.1456 - accuracy: 0.9338WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1417 - accuracy: 0.9362\n",
      "Epoch 149/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1322 - accuracy: 0.9568WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.1322 - accuracy: 0.9568\n",
      "Epoch 150/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.0764 - accuracy: 0.9679WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.0749 - accuracy: 0.9691\n",
      "Epoch 151/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.1402 - accuracy: 0.9378WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1350 - accuracy: 0.9424\n",
      "Epoch 152/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.1282 - accuracy: 0.9533WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.1217 - accuracy: 0.9568\n",
      "Epoch 153/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.0714 - accuracy: 0.9739WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0894 - accuracy: 0.9691\n",
      "Epoch 154/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.9465WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.1329 - accuracy: 0.9465\n",
      "Epoch 155/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1167 - accuracy: 0.9539WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1149 - accuracy: 0.9547\n",
      "Epoch 156/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.1119 - accuracy: 0.9551WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1147 - accuracy: 0.9527\n",
      "Epoch 157/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1893 - accuracy: 0.9239WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1893 - accuracy: 0.9239\n",
      "Epoch 158/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1340 - accuracy: 0.9477WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1393 - accuracy: 0.9444\n",
      "Epoch 159/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.1645 - accuracy: 0.9466WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1621 - accuracy: 0.9465\n",
      "Epoch 160/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.0679 - accuracy: 0.9769WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.0697 - accuracy: 0.9753\n",
      "Epoch 161/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.0982 - accuracy: 0.9600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.0939 - accuracy: 0.9630\n",
      "Epoch 162/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1247 - accuracy: 0.9560WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1240 - accuracy: 0.9547\n",
      "Epoch 163/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1174 - accuracy: 0.9560WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1161 - accuracy: 0.9568\n",
      "Epoch 164/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1924 - accuracy: 0.9383WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1924 - accuracy: 0.9383\n",
      "Epoch 165/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.9581WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1134 - accuracy: 0.9588\n",
      "Epoch 166/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1587 - accuracy: 0.9303WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1570 - accuracy: 0.9321\n",
      "Epoch 167/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.9712WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.0856 - accuracy: 0.9712\n",
      "Epoch 168/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1405 - accuracy: 0.9412WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1347 - accuracy: 0.9444\n",
      "Epoch 169/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2001 - accuracy: 0.9198WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.2001 - accuracy: 0.9198\n",
      "Epoch 170/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1250 - accuracy: 0.9521WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1212 - accuracy: 0.9527\n",
      "Epoch 171/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1409 - accuracy: 0.9434WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1365 - accuracy: 0.9465\n",
      "Epoch 172/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1366 - accuracy: 0.9455WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1490 - accuracy: 0.9403\n",
      "Epoch 173/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.0691 - accuracy: 0.9808WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0851 - accuracy: 0.9712\n",
      "Epoch 174/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1470 - accuracy: 0.9413WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1467 - accuracy: 0.9403\n",
      "Epoch 175/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9753WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.0890 - accuracy: 0.9753\n",
      "Epoch 176/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.0820 - accuracy: 0.9644WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0805 - accuracy: 0.9650\n",
      "Epoch 177/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.0755 - accuracy: 0.9722WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0769 - accuracy: 0.9712\n",
      "Epoch 178/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.0875 - accuracy: 0.9733WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0825 - accuracy: 0.9753\n",
      "Epoch 179/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1763 - accuracy: 0.9350WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1736 - accuracy: 0.9362\n",
      "Epoch 180/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1156 - accuracy: 0.9706WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1137 - accuracy: 0.9712\n",
      "Epoch 181/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.1209 - accuracy: 0.9477WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1204 - accuracy: 0.9486\n",
      "Epoch 182/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1716 - accuracy: 0.9266WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1684 - accuracy: 0.9280\n",
      "Epoch 183/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.1329 - accuracy: 0.9511WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1276 - accuracy: 0.9527\n",
      "Epoch 184/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.0895 - accuracy: 0.9665WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0893 - accuracy: 0.9671\n",
      "Epoch 185/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.1242 - accuracy: 0.9467WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1228 - accuracy: 0.9465\n",
      "Epoch 186/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.1767 - accuracy: 0.9422WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1692 - accuracy: 0.9465\n",
      "Epoch 187/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.0894 - accuracy: 0.9706WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0880 - accuracy: 0.9712\n",
      "Epoch 188/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.0693 - accuracy: 0.9706WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.0681 - accuracy: 0.9712\n",
      "Epoch 189/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.1815 - accuracy: 0.9231WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1782 - accuracy: 0.9259\n",
      "Epoch 190/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.0934 - accuracy: 0.9651WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.0917 - accuracy: 0.9671\n",
      "Epoch 191/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1274 - accuracy: 0.9539WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1256 - accuracy: 0.9547\n",
      "Epoch 192/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.1240 - accuracy: 0.9509WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1296 - accuracy: 0.9486\n",
      "Epoch 193/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1297 - accuracy: 0.9560WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1329 - accuracy: 0.9547\n",
      "Epoch 194/200\n",
      "49/54 [==========================>...] - ETA: 0s - loss: 0.1442 - accuracy: 0.9433WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1367 - accuracy: 0.9444\n",
      "Epoch 195/200\n",
      "52/54 [===========================>..] - ETA: 0s - loss: 0.1132 - accuracy: 0.9509WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1099 - accuracy: 0.9527\n",
      "Epoch 196/200\n",
      "49/54 [==========================>...] - ETA: 0s - loss: 0.0814 - accuracy: 0.9683WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.0896 - accuracy: 0.9630\n",
      "Epoch 197/200\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.9630WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.1027 - accuracy: 0.9630\n",
      "Epoch 198/200\n",
      "50/54 [==========================>...] - ETA: 0s - loss: 0.0817 - accuracy: 0.9689WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.0814 - accuracy: 0.9691\n",
      "Epoch 199/200\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.0922 - accuracy: 0.9695WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.0996 - accuracy: 0.9650\n",
      "Epoch 200/200\n",
      "53/54 [============================>.] - ETA: 0s - loss: 0.1174 - accuracy: 0.9560WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.1164 - accuracy: 0.9568\n",
      "4/4 [==============================] - 1s 9ms/step\n",
      "F1 Score on Test Set: 0.8073394495412843\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Build the model with the best hyperparameters\n",
    "best_model1 = keras.Sequential()\n",
    "for _ in range(best_params[\"num_hidden_layers\"]):\n",
    "    best_model1.add(keras.layers.Dense(best_params[\"num_hidden_units\"], activation=best_params[\"activation\"]))\n",
    "    best_model1.add(keras.layers.BatchNormalization())\n",
    "    best_model1.add(keras.layers.Dropout(best_params[\"dropout_rate\"]))\n",
    "\n",
    "best_model1.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model with the best optimizer and learning rate\n",
    "if best_params[\"optimizer\"] == \"adam\":\n",
    "    optimizer_obj = keras.optimizers.Adam(learning_rate=best_params[\"learning_rate\"])\n",
    "elif best_params[\"optimizer\"] == \"sgd\":\n",
    "    optimizer_obj = keras.optimizers.SGD(learning_rate=best_params[\"learning_rate\"])\n",
    "elif best_params[\"optimizer\"] == \"rmsprop\":\n",
    "    optimizer_obj = keras.optimizers.RMSprop(learning_rate=best_params[\"learning_rate\"])\n",
    "else:\n",
    "    raise ValueError(\"Optimizador no soportado\")\n",
    "\n",
    "best_model1.compile(optimizer=optimizer_obj, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model on the entire training dataset\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=30,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "best_model1.fit(X_train, y_train, epochs=200, batch_size=best_params[\"batch_size\"], verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the retrained model\n",
    "y_pred = (best_model1.predict(X_test) > 0.5).astype(int)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"F1 Score on Test Set:\", f1)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Guardar el modelo\\nwith open('NN_best_model.pkl', 'wb') as model_file:\\n    pickle.dump(best_model1, model_file)\\n\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "'''\n",
    "# Guardar el modelo\n",
    "with open('NN_best_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(best_model1, model_file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo\n",
    "with open('NN_best_model.pkl', 'rb') as model_file:\n",
    "    loaded_model = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n",
      "Informe de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.84        61\n",
      "           1       0.92      0.72      0.81        61\n",
      "\n",
      "    accuracy                           0.83       122\n",
      "   macro avg       0.84      0.83      0.83       122\n",
      "weighted avg       0.84      0.83      0.83       122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Se hacen la predicciones sobre los datos de test\n",
    "predictions = (loaded_model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Generar un informe de clasificación\n",
    "report = classification_report(y_test, predictions)\n",
    "print(\"Informe de clasificación:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se procede a entrenar el modelo con KNN, Decision Tree, y Stacking.\n",
    "\n",
    "Del mismo modo que en el modelo anterior, primero se entrenan modelos con optuna, para luego reentrenarlo en función de los mejores hiperparámetros encontrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-03 17:13:46,982] A new study created in memory with name: no-name-f232f36f-dcfa-4d92-9686-030df5605306\n",
      "[I 2023-12-03 17:13:47,177] Trial 0 finished with value: 0.7540983606557377 and parameters: {'knn_n_neighbors': 35, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'entropy', 'final_dt_max_depth': 4, 'final_dt_criterion': 'gini'}. Best is trial 0 with value: 0.7540983606557377.\n",
      "[I 2023-12-03 17:13:47,301] Trial 1 finished with value: 0.639344262295082 and parameters: {'knn_n_neighbors': 38, 'knn_weights': 'uniform', 'dt_max_depth': 4, 'dt_criterion': 'entropy', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 0 with value: 0.7540983606557377.\n",
      "[I 2023-12-03 17:13:47,395] Trial 2 finished with value: 0.5573770491803278 and parameters: {'knn_n_neighbors': 22, 'knn_weights': 'uniform', 'dt_max_depth': 2, 'dt_criterion': 'entropy', 'final_dt_max_depth': 10, 'final_dt_criterion': 'entropy'}. Best is trial 0 with value: 0.7540983606557377.\n",
      "[I 2023-12-03 17:13:47,529] Trial 3 finished with value: 0.5491803278688525 and parameters: {'knn_n_neighbors': 40, 'knn_weights': 'uniform', 'dt_max_depth': 7, 'dt_criterion': 'entropy', 'final_dt_max_depth': 5, 'final_dt_criterion': 'gini'}. Best is trial 0 with value: 0.7540983606557377.\n",
      "[I 2023-12-03 17:13:47,666] Trial 4 finished with value: 0.7213114754098361 and parameters: {'knn_n_neighbors': 41, 'knn_weights': 'distance', 'dt_max_depth': 4, 'dt_criterion': 'entropy', 'final_dt_max_depth': 5, 'final_dt_criterion': 'entropy'}. Best is trial 0 with value: 0.7540983606557377.\n",
      "[I 2023-12-03 17:13:47,792] Trial 5 finished with value: 0.7131147540983607 and parameters: {'knn_n_neighbors': 14, 'knn_weights': 'distance', 'dt_max_depth': 5, 'dt_criterion': 'entropy', 'final_dt_max_depth': 10, 'final_dt_criterion': 'entropy'}. Best is trial 0 with value: 0.7540983606557377.\n",
      "[I 2023-12-03 17:13:47,961] Trial 6 finished with value: 0.6967213114754098 and parameters: {'knn_n_neighbors': 39, 'knn_weights': 'uniform', 'dt_max_depth': 6, 'dt_criterion': 'entropy', 'final_dt_max_depth': 1, 'final_dt_criterion': 'entropy'}. Best is trial 0 with value: 0.7540983606557377.\n",
      "[I 2023-12-03 17:13:48,056] Trial 7 finished with value: 0.7213114754098361 and parameters: {'knn_n_neighbors': 26, 'knn_weights': 'distance', 'dt_max_depth': 1, 'dt_criterion': 'entropy', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 0 with value: 0.7540983606557377.\n",
      "[I 2023-12-03 17:13:48,206] Trial 8 finished with value: 0.7704918032786885 and parameters: {'knn_n_neighbors': 27, 'knn_weights': 'distance', 'dt_max_depth': 7, 'dt_criterion': 'entropy', 'final_dt_max_depth': 3, 'final_dt_criterion': 'entropy'}. Best is trial 8 with value: 0.7704918032786885.\n",
      "[I 2023-12-03 17:13:48,330] Trial 9 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 5, 'dt_criterion': 'gini', 'final_dt_max_depth': 4, 'final_dt_criterion': 'gini'}. Best is trial 9 with value: 0.8442622950819673.\n",
      "[I 2023-12-03 17:13:48,492] Trial 10 finished with value: 0.8114754098360656 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 1, 'final_dt_criterion': 'gini'}. Best is trial 9 with value: 0.8442622950819673.\n",
      "[I 2023-12-03 17:13:48,651] Trial 11 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 1, 'final_dt_criterion': 'gini'}. Best is trial 9 with value: 0.8442622950819673.\n",
      "[I 2023-12-03 17:13:48,806] Trial 12 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 3, 'final_dt_criterion': 'gini'}. Best is trial 9 with value: 0.8442622950819673.\n",
      "[I 2023-12-03 17:13:48,956] Trial 13 finished with value: 0.7459016393442623 and parameters: {'knn_n_neighbors': 11, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 2, 'final_dt_criterion': 'gini'}. Best is trial 9 with value: 0.8442622950819673.\n",
      "[I 2023-12-03 17:13:49,066] Trial 14 finished with value: 0.7622950819672131 and parameters: {'knn_n_neighbors': 9, 'knn_weights': 'distance', 'dt_max_depth': 3, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 9 with value: 0.8442622950819673.\n",
      "[I 2023-12-03 17:13:49,201] Trial 15 finished with value: 0.7131147540983607 and parameters: {'knn_n_neighbors': 50, 'knn_weights': 'distance', 'dt_max_depth': 6, 'dt_criterion': 'gini', 'final_dt_max_depth': 3, 'final_dt_criterion': 'gini'}. Best is trial 9 with value: 0.8442622950819673.\n",
      "[I 2023-12-03 17:13:49,339] Trial 16 finished with value: 0.7295081967213115 and parameters: {'knn_n_neighbors': 17, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 9 with value: 0.8442622950819673.\n",
      "[I 2023-12-03 17:13:49,472] Trial 17 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 5, 'dt_criterion': 'gini', 'final_dt_max_depth': 2, 'final_dt_criterion': 'gini'}. Best is trial 9 with value: 0.8442622950819673.\n",
      "[I 2023-12-03 17:13:49,589] Trial 18 finished with value: 0.7131147540983607 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'uniform', 'dt_max_depth': 4, 'dt_criterion': 'gini', 'final_dt_max_depth': 4, 'final_dt_criterion': 'gini'}. Best is trial 9 with value: 0.8442622950819673.\n",
      "[I 2023-12-03 17:13:49,756] Trial 19 finished with value: 0.8032786885245902 and parameters: {'knn_n_neighbors': 18, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 1, 'final_dt_criterion': 'gini'}. Best is trial 9 with value: 0.8442622950819673.\n",
      "[I 2023-12-03 17:13:49,907] Trial 20 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 3, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 9 with value: 0.8442622950819673.\n",
      "[I 2023-12-03 17:13:50,066] Trial 21 finished with value: 0.8032786885245902 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 2, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 9 with value: 0.8442622950819673.\n",
      "[I 2023-12-03 17:13:50,176] Trial 22 finished with value: 0.7131147540983607 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 3, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 9 with value: 0.8442622950819673.\n",
      "[I 2023-12-03 17:13:50,286] Trial 23 finished with value: 0.7213114754098361 and parameters: {'knn_n_neighbors': 11, 'knn_weights': 'distance', 'dt_max_depth': 3, 'dt_criterion': 'gini', 'final_dt_max_depth': 4, 'final_dt_criterion': 'gini'}. Best is trial 9 with value: 0.8442622950819673.\n",
      "[I 2023-12-03 17:13:50,418] Trial 24 finished with value: 0.8524590163934426 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 5, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:50,555] Trial 25 finished with value: 0.7704918032786885 and parameters: {'knn_n_neighbors': 15, 'knn_weights': 'distance', 'dt_max_depth': 5, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:50,671] Trial 26 finished with value: 0.5819672131147541 and parameters: {'knn_n_neighbors': 9, 'knn_weights': 'uniform', 'dt_max_depth': 4, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'entropy'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:50,813] Trial 27 finished with value: 0.6557377049180327 and parameters: {'knn_n_neighbors': 20, 'knn_weights': 'distance', 'dt_max_depth': 6, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:50,918] Trial 28 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 2, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:51,066] Trial 29 finished with value: 0.7540983606557377 and parameters: {'knn_n_neighbors': 23, 'knn_weights': 'distance', 'dt_max_depth': 7, 'dt_criterion': 'gini', 'final_dt_max_depth': 5, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:51,170] Trial 30 finished with value: 0.8114754098360656 and parameters: {'knn_n_neighbors': 12, 'knn_weights': 'distance', 'dt_max_depth': 1, 'dt_criterion': 'gini', 'final_dt_max_depth': 4, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:51,272] Trial 31 finished with value: 0.8032786885245902 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 2, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:51,384] Trial 32 finished with value: 0.8032786885245902 and parameters: {'knn_n_neighbors': 8, 'knn_weights': 'distance', 'dt_max_depth': 3, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:51,484] Trial 33 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 2, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:51,607] Trial 34 finished with value: 0.6885245901639344 and parameters: {'knn_n_neighbors': 32, 'knn_weights': 'uniform', 'dt_max_depth': 5, 'dt_criterion': 'gini', 'final_dt_max_depth': 5, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:51,762] Trial 35 finished with value: 0.8524590163934426 and parameters: {'knn_n_neighbors': 8, 'knn_weights': 'distance', 'dt_max_depth': 4, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:51,883] Trial 36 finished with value: 0.6065573770491803 and parameters: {'knn_n_neighbors': 15, 'knn_weights': 'uniform', 'dt_max_depth': 4, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'entropy'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:52,016] Trial 37 finished with value: 0.7377049180327869 and parameters: {'knn_n_neighbors': 12, 'knn_weights': 'distance', 'dt_max_depth': 4, 'dt_criterion': 'entropy', 'final_dt_max_depth': 10, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:52,138] Trial 38 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 8, 'knn_weights': 'distance', 'dt_max_depth': 5, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'entropy'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:52,277] Trial 39 finished with value: 0.6885245901639344 and parameters: {'knn_n_neighbors': 30, 'knn_weights': 'uniform', 'dt_max_depth': 6, 'dt_criterion': 'entropy', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:52,404] Trial 40 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 4, 'dt_criterion': 'entropy', 'final_dt_max_depth': 5, 'final_dt_criterion': 'entropy'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:52,518] Trial 41 finished with value: 0.7622950819672131 and parameters: {'knn_n_neighbors': 9, 'knn_weights': 'distance', 'dt_max_depth': 3, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:52,623] Trial 42 finished with value: 0.8524590163934426 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 2, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:52,720] Trial 43 finished with value: 0.8114754098360656 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 1, 'dt_criterion': 'gini', 'final_dt_max_depth': 4, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:52,834] Trial 44 finished with value: 0.7868852459016393 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 3, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:52,970] Trial 45 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 7, 'knn_weights': 'distance', 'dt_max_depth': 5, 'dt_criterion': 'gini', 'final_dt_max_depth': 5, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:53,157] Trial 46 finished with value: 0.7295081967213115 and parameters: {'knn_n_neighbors': 13, 'knn_weights': 'distance', 'dt_max_depth': 7, 'dt_criterion': 'gini', 'final_dt_max_depth': 10, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:53,282] Trial 47 finished with value: 0.680327868852459 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 4, 'dt_criterion': 'entropy', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:53,391] Trial 48 finished with value: 0.7540983606557377 and parameters: {'knn_n_neighbors': 10, 'knn_weights': 'distance', 'dt_max_depth': 2, 'dt_criterion': 'gini', 'final_dt_max_depth': 3, 'final_dt_criterion': 'entropy'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:53,511] Trial 49 finished with value: 0.7459016393442623 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'uniform', 'dt_max_depth': 5, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:53,619] Trial 50 finished with value: 0.6721311475409836 and parameters: {'knn_n_neighbors': 44, 'knn_weights': 'distance', 'dt_max_depth': 1, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:53,722] Trial 51 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 7, 'knn_weights': 'distance', 'dt_max_depth': 2, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:53,841] Trial 52 finished with value: 0.8524590163934426 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 3, 'dt_criterion': 'gini', 'final_dt_max_depth': 5, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:53,951] Trial 53 finished with value: 0.8114754098360656 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 3, 'dt_criterion': 'gini', 'final_dt_max_depth': 5, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:54,077] Trial 54 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 4, 'dt_criterion': 'gini', 'final_dt_max_depth': 4, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:54,218] Trial 55 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 6, 'dt_criterion': 'gini', 'final_dt_max_depth': 5, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:54,335] Trial 56 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 17, 'knn_weights': 'distance', 'dt_max_depth': 3, 'dt_criterion': 'gini', 'final_dt_max_depth': 4, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:54,453] Trial 57 finished with value: 0.7459016393442623 and parameters: {'knn_n_neighbors': 10, 'knn_weights': 'distance', 'dt_max_depth': 3, 'dt_criterion': 'gini', 'final_dt_max_depth': 3, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:54,583] Trial 58 finished with value: 0.7459016393442623 and parameters: {'knn_n_neighbors': 7, 'knn_weights': 'distance', 'dt_max_depth': 4, 'dt_criterion': 'entropy', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:54,720] Trial 59 finished with value: 0.7868852459016393 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 5, 'dt_criterion': 'gini', 'final_dt_max_depth': 2, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:54,867] Trial 60 finished with value: 0.6885245901639344 and parameters: {'knn_n_neighbors': 13, 'knn_weights': 'distance', 'dt_max_depth': 6, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'entropy'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:55,004] Trial 61 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 6, 'dt_criterion': 'gini', 'final_dt_max_depth': 5, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:55,150] Trial 62 finished with value: 0.8032786885245902 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 6, 'dt_criterion': 'gini', 'final_dt_max_depth': 5, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:55,299] Trial 63 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 8, 'knn_weights': 'distance', 'dt_max_depth': 7, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:55,437] Trial 64 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 5, 'dt_criterion': 'gini', 'final_dt_max_depth': 5, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:55,562] Trial 65 finished with value: 0.8114754098360656 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 5, 'dt_criterion': 'gini', 'final_dt_max_depth': 5, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:55,697] Trial 66 finished with value: 0.7459016393442623 and parameters: {'knn_n_neighbors': 10, 'knn_weights': 'distance', 'dt_max_depth': 5, 'dt_criterion': 'gini', 'final_dt_max_depth': 4, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:55,830] Trial 67 finished with value: 0.7377049180327869 and parameters: {'knn_n_neighbors': 37, 'knn_weights': 'uniform', 'dt_max_depth': 6, 'dt_criterion': 'gini', 'final_dt_max_depth': 4, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:55,950] Trial 68 finished with value: 0.7868852459016393 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 4, 'dt_criterion': 'gini', 'final_dt_max_depth': 5, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:56,083] Trial 69 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 5, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:56,225] Trial 70 finished with value: 0.7295081967213115 and parameters: {'knn_n_neighbors': 22, 'knn_weights': 'distance', 'dt_max_depth': 7, 'dt_criterion': 'gini', 'final_dt_max_depth': 5, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:56,353] Trial 71 finished with value: 0.7868852459016393 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 4, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:56,465] Trial 72 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 7, 'knn_weights': 'distance', 'dt_max_depth': 2, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:56,589] Trial 73 finished with value: 0.8032786885245902 and parameters: {'knn_n_neighbors': 9, 'knn_weights': 'distance', 'dt_max_depth': 4, 'dt_criterion': 'gini', 'final_dt_max_depth': 5, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:56,718] Trial 74 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 3, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:56,866] Trial 75 finished with value: 0.7459016393442623 and parameters: {'knn_n_neighbors': 11, 'knn_weights': 'distance', 'dt_max_depth': 6, 'dt_criterion': 'gini', 'final_dt_max_depth': 4, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:57,012] Trial 76 finished with value: 0.5409836065573771 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 5, 'dt_criterion': 'entropy', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:57,119] Trial 77 finished with value: 0.7295081967213115 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'uniform', 'dt_max_depth': 3, 'dt_criterion': 'gini', 'final_dt_max_depth': 5, 'final_dt_criterion': 'entropy'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:57,249] Trial 78 finished with value: 0.7540983606557377 and parameters: {'knn_n_neighbors': 8, 'knn_weights': 'distance', 'dt_max_depth': 5, 'dt_criterion': 'gini', 'final_dt_max_depth': 4, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:57,379] Trial 79 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 4, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:57,537] Trial 80 finished with value: 0.8524590163934426 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 24 with value: 0.8524590163934426.\n",
      "[I 2023-12-03 17:13:57,689] Trial 81 finished with value: 0.8852459016393442 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:13:57,836] Trial 82 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:13:57,990] Trial 83 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:13:58,151] Trial 84 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:13:58,306] Trial 85 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:13:58,470] Trial 86 finished with value: 0.7786885245901639 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:13:58,619] Trial 87 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:13:58,775] Trial 88 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'entropy', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:13:58,933] Trial 89 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 7, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:13:59,079] Trial 90 finished with value: 0.7540983606557377 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'uniform', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'entropy'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:13:59,254] Trial 91 finished with value: 0.860655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:13:59,415] Trial 92 finished with value: 0.8114754098360656 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:13:59,583] Trial 93 finished with value: 0.7540983606557377 and parameters: {'knn_n_neighbors': 28, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:13:59,731] Trial 94 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:13:59,892] Trial 95 finished with value: 0.7786885245901639 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:00,056] Trial 96 finished with value: 0.7622950819672131 and parameters: {'knn_n_neighbors': 8, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:00,215] Trial 97 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:00,371] Trial 98 finished with value: 0.7213114754098361 and parameters: {'knn_n_neighbors': 49, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 10, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:00,523] Trial 99 finished with value: 0.8524590163934426 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:00,698] Trial 100 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:00,853] Trial 101 finished with value: 0.860655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:01,012] Trial 102 finished with value: 0.860655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:01,155] Trial 103 finished with value: 0.860655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:01,307] Trial 104 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:01,461] Trial 105 finished with value: 0.8852459016393442 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:01,612] Trial 106 finished with value: 0.860655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:01,785] Trial 107 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:01,952] Trial 108 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'entropy', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:02,110] Trial 109 finished with value: 0.6967213114754098 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:02,257] Trial 110 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:02,399] Trial 111 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:02,554] Trial 112 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:02,716] Trial 113 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:02,856] Trial 114 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 10, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:03,006] Trial 115 finished with value: 0.7622950819672131 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:03,164] Trial 116 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'entropy'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:03,311] Trial 117 finished with value: 0.8114754098360656 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'uniform', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:03,464] Trial 118 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:03,629] Trial 119 finished with value: 0.7295081967213115 and parameters: {'knn_n_neighbors': 33, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:03,773] Trial 120 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:03,932] Trial 121 finished with value: 0.8524590163934426 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:04,091] Trial 122 finished with value: 0.7868852459016393 and parameters: {'knn_n_neighbors': 24, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:04,256] Trial 123 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 7, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 10, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:04,407] Trial 124 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:04,564] Trial 125 finished with value: 0.860655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:04,715] Trial 126 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:04,872] Trial 127 finished with value: 0.8032786885245902 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:05,024] Trial 128 finished with value: 0.7868852459016393 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:05,189] Trial 129 finished with value: 0.7295081967213115 and parameters: {'knn_n_neighbors': 19, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:05,352] Trial 130 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'entropy', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:05,499] Trial 131 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:05,649] Trial 132 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:05,808] Trial 133 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:05,963] Trial 134 finished with value: 0.7295081967213115 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:06,111] Trial 135 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 10, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:06,268] Trial 136 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:06,426] Trial 137 finished with value: 0.860655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'entropy'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:06,599] Trial 138 finished with value: 0.7786885245901639 and parameters: {'knn_n_neighbors': 7, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:06,742] Trial 139 finished with value: 0.7459016393442623 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'uniform', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:06,905] Trial 140 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:07,053] Trial 141 finished with value: 0.860655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:07,208] Trial 142 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:07,364] Trial 143 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:07,517] Trial 144 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:07,689] Trial 145 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:07,855] Trial 146 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:08,016] Trial 147 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:08,167] Trial 148 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:08,322] Trial 149 finished with value: 0.8524590163934426 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:08,483] Trial 150 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:08,640] Trial 151 finished with value: 0.8852459016393442 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:08,785] Trial 152 finished with value: 0.8524590163934426 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:08,938] Trial 153 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:09,101] Trial 154 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:09,254] Trial 155 finished with value: 0.7704918032786885 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:09,406] Trial 156 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:09,564] Trial 157 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'entropy', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:09,716] Trial 158 finished with value: 0.7868852459016393 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:09,872] Trial 159 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'entropy'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:10,020] Trial 160 finished with value: 0.8114754098360656 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'uniform', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:10,188] Trial 161 finished with value: 0.8524590163934426 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:10,345] Trial 162 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:10,503] Trial 163 finished with value: 0.860655737704918 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:10,653] Trial 164 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:10,813] Trial 165 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:10,972] Trial 166 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:11,134] Trial 167 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:11,286] Trial 168 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 7, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:11,452] Trial 169 finished with value: 0.8524590163934426 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:11,650] Trial 170 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:11,814] Trial 171 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:11,980] Trial 172 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:12,135] Trial 173 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:12,336] Trial 174 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:12,587] Trial 175 finished with value: 0.7213114754098361 and parameters: {'knn_n_neighbors': 42, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:12,767] Trial 176 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:12,951] Trial 177 finished with value: 0.7868852459016393 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:13,131] Trial 178 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:13,298] Trial 179 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:13,466] Trial 180 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 10, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:13,636] Trial 181 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:13,802] Trial 182 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:13,953] Trial 183 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:14,120] Trial 184 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:14,289] Trial 185 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:14,470] Trial 186 finished with value: 0.7704918032786885 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'entropy', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:14,646] Trial 187 finished with value: 0.8852459016393442 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:14,809] Trial 188 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:14,964] Trial 189 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'entropy'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:15,121] Trial 190 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'uniform', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:15,305] Trial 191 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:15,479] Trial 192 finished with value: 0.860655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:15,649] Trial 193 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:15,814] Trial 194 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:15,967] Trial 195 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:16,134] Trial 196 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:16,301] Trial 197 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:16,462] Trial 198 finished with value: 0.7540983606557377 and parameters: {'knn_n_neighbors': 16, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:16,637] Trial 199 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:16,804] Trial 200 finished with value: 0.8524590163934426 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:16,968] Trial 201 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:17,133] Trial 202 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:17,302] Trial 203 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:17,481] Trial 204 finished with value: 0.7704918032786885 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:17,666] Trial 205 finished with value: 0.8032786885245902 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:17,824] Trial 206 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:17,987] Trial 207 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:18,152] Trial 208 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:18,334] Trial 209 finished with value: 0.7868852459016393 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:18,513] Trial 210 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:18,670] Trial 211 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:18,838] Trial 212 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:19,002] Trial 213 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:19,168] Trial 214 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:19,334] Trial 215 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:19,495] Trial 216 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:19,653] Trial 217 finished with value: 0.8852459016393442 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:19,836] Trial 218 finished with value: 0.6967213114754098 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'entropy', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:20,011] Trial 219 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:20,167] Trial 220 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:20,323] Trial 221 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:20,504] Trial 222 finished with value: 0.8852459016393442 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:20,669] Trial 223 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:20,833] Trial 224 finished with value: 0.8032786885245902 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:20,996] Trial 225 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:21,149] Trial 226 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:21,308] Trial 227 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:21,466] Trial 228 finished with value: 0.860655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:21,618] Trial 229 finished with value: 0.7868852459016393 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'uniform', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'entropy'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:21,797] Trial 230 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:21,955] Trial 231 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:22,135] Trial 232 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:22,301] Trial 233 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:22,469] Trial 234 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:22,646] Trial 235 finished with value: 0.7131147540983607 and parameters: {'knn_n_neighbors': 21, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:22,804] Trial 236 finished with value: 0.8852459016393442 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:22,978] Trial 237 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:23,141] Trial 238 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:23,300] Trial 239 finished with value: 0.860655737704918 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:23,460] Trial 240 finished with value: 0.860655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:23,614] Trial 241 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:23,764] Trial 242 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:23,922] Trial 243 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:24,084] Trial 244 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:24,239] Trial 245 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:24,389] Trial 246 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:24,552] Trial 247 finished with value: 0.8032786885245902 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:24,729] Trial 248 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:24,905] Trial 249 finished with value: 0.8852459016393442 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:25,063] Trial 250 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:25,217] Trial 251 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:25,388] Trial 252 finished with value: 0.6885245901639344 and parameters: {'knn_n_neighbors': 37, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:25,553] Trial 253 finished with value: 0.7131147540983607 and parameters: {'knn_n_neighbors': 28, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:25,749] Trial 254 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'entropy', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:25,917] Trial 255 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:26,091] Trial 256 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:26,255] Trial 257 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:26,419] Trial 258 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'entropy'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:26,577] Trial 259 finished with value: 0.7868852459016393 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'uniform', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:26,751] Trial 260 finished with value: 0.8852459016393442 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:26,905] Trial 261 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:27,057] Trial 262 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:27,214] Trial 263 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:27,375] Trial 264 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:27,529] Trial 265 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:27,681] Trial 266 finished with value: 0.8114754098360656 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 2, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:27,847] Trial 267 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:28,001] Trial 268 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:28,164] Trial 269 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:28,322] Trial 270 finished with value: 0.8032786885245902 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:28,485] Trial 271 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:28,653] Trial 272 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:28,823] Trial 273 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:28,995] Trial 274 finished with value: 0.8114754098360656 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 7, 'dt_criterion': 'entropy', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:29,157] Trial 275 finished with value: 0.7131147540983607 and parameters: {'knn_n_neighbors': 48, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:29,333] Trial 276 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:29,479] Trial 277 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'entropy'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:29,646] Trial 278 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:29,805] Trial 279 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'uniform', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:29,971] Trial 280 finished with value: 0.8524590163934426 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:30,132] Trial 281 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:30,290] Trial 282 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:30,454] Trial 283 finished with value: 0.8852459016393442 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:30,618] Trial 284 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:30,786] Trial 285 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:30,954] Trial 286 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:31,122] Trial 287 finished with value: 0.7622950819672131 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:31,293] Trial 288 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:31,464] Trial 289 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:31,624] Trial 290 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:31,796] Trial 291 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:31,970] Trial 292 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:32,143] Trial 293 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:32,311] Trial 294 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'entropy', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:32,488] Trial 295 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:32,666] Trial 296 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'entropy'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:32,816] Trial 297 finished with value: 0.7295081967213115 and parameters: {'knn_n_neighbors': 26, 'knn_weights': 'uniform', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:32,991] Trial 298 finished with value: 0.7786885245901639 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 10, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:33,160] Trial 299 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:33,337] Trial 300 finished with value: 0.8852459016393442 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:33,505] Trial 301 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:33,678] Trial 302 finished with value: 0.8032786885245902 and parameters: {'knn_n_neighbors': 24, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:33,836] Trial 303 finished with value: 0.6967213114754098 and parameters: {'knn_n_neighbors': 30, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:34,003] Trial 304 finished with value: 0.7704918032786885 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:34,160] Trial 305 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:34,338] Trial 306 finished with value: 0.8114754098360656 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:34,498] Trial 307 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:34,662] Trial 308 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 5, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:34,817] Trial 309 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:35,018] Trial 310 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:35,186] Trial 311 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:35,344] Trial 312 finished with value: 0.8114754098360656 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'entropy', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:35,511] Trial 313 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 7, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:35,689] Trial 314 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:35,878] Trial 315 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:36,069] Trial 316 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'entropy'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:36,229] Trial 317 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'uniform', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:36,395] Trial 318 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 1, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:36,554] Trial 319 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:36,725] Trial 320 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:36,886] Trial 321 finished with value: 0.6967213114754098 and parameters: {'knn_n_neighbors': 35, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:37,069] Trial 322 finished with value: 0.8114754098360656 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 5, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:37,238] Trial 323 finished with value: 0.8114754098360656 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:37,414] Trial 324 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:37,582] Trial 325 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:37,750] Trial 326 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:37,915] Trial 327 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:38,075] Trial 328 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:38,258] Trial 329 finished with value: 0.7459016393442623 and parameters: {'knn_n_neighbors': 18, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:38,417] Trial 330 finished with value: 0.7213114754098361 and parameters: {'knn_n_neighbors': 13, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:38,586] Trial 331 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:38,770] Trial 332 finished with value: 0.7540983606557377 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'entropy', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:38,937] Trial 333 finished with value: 0.8114754098360656 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:39,102] Trial 334 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:39,268] Trial 335 finished with value: 0.860655737704918 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'entropy'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:39,432] Trial 336 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:39,599] Trial 337 finished with value: 0.8852459016393442 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:39,764] Trial 338 finished with value: 0.8114754098360656 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'uniform', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:39,940] Trial 339 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:40,115] Trial 340 finished with value: 0.8114754098360656 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:40,268] Trial 341 finished with value: 0.860655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:40,431] Trial 342 finished with value: 0.7868852459016393 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:40,589] Trial 343 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:40,704] Trial 344 finished with value: 0.8114754098360656 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 1, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:40,873] Trial 345 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:41,037] Trial 346 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:41,202] Trial 347 finished with value: 0.8524590163934426 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 10, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:41,356] Trial 348 finished with value: 0.860655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:41,527] Trial 349 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:41,701] Trial 350 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:41,880] Trial 351 finished with value: 0.8032786885245902 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'entropy', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:42,068] Trial 352 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:42,226] Trial 353 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:42,409] Trial 354 finished with value: 0.7786885245901639 and parameters: {'knn_n_neighbors': 15, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:42,558] Trial 355 finished with value: 0.8114754098360656 and parameters: {'knn_n_neighbors': 7, 'knn_weights': 'distance', 'dt_max_depth': 7, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'entropy'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:42,727] Trial 356 finished with value: 0.7459016393442623 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'uniform', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:42,899] Trial 357 finished with value: 0.6885245901639344 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:43,069] Trial 358 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 81 with value: 0.8852459016393442.\n",
      "[I 2023-12-03 17:14:43,249] Trial 359 finished with value: 0.8934426229508197 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:43,423] Trial 360 finished with value: 0.7704918032786885 and parameters: {'knn_n_neighbors': 45, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:43,585] Trial 361 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:43,753] Trial 362 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:43,915] Trial 363 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:44,080] Trial 364 finished with value: 0.7704918032786885 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:44,237] Trial 365 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:44,403] Trial 366 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:44,576] Trial 367 finished with value: 0.8032786885245902 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:44,763] Trial 368 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:44,949] Trial 369 finished with value: 0.8524590163934426 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:45,134] Trial 370 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'entropy', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:45,305] Trial 371 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:45,484] Trial 372 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:45,649] Trial 373 finished with value: 0.7704918032786885 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 3, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:45,812] Trial 374 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:45,977] Trial 375 finished with value: 0.7540983606557377 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'uniform', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'entropy'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:46,148] Trial 376 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:46,302] Trial 377 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:46,461] Trial 378 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:46,635] Trial 379 finished with value: 0.7868852459016393 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:46,822] Trial 380 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:46,985] Trial 381 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:47,149] Trial 382 finished with value: 0.8032786885245902 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:47,322] Trial 383 finished with value: 0.8852459016393442 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:47,498] Trial 384 finished with value: 0.860655737704918 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:47,677] Trial 385 finished with value: 0.7704918032786885 and parameters: {'knn_n_neighbors': 40, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:47,845] Trial 386 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:48,010] Trial 387 finished with value: 0.7950819672131147 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 6, 'dt_criterion': 'gini', 'final_dt_max_depth': 5, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:48,182] Trial 388 finished with value: 0.7868852459016393 and parameters: {'knn_n_neighbors': 8, 'knn_weights': 'distance', 'dt_max_depth': 8, 'dt_criterion': 'gini', 'final_dt_max_depth': 10, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:48,357] Trial 389 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 10, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:48,549] Trial 390 finished with value: 0.7786885245901639 and parameters: {'knn_n_neighbors': 5, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'entropy', 'final_dt_max_depth': 6, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:48,731] Trial 391 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:48,900] Trial 392 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 7, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:49,063] Trial 393 finished with value: 0.8278688524590164 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:49,235] Trial 394 finished with value: 0.8770491803278688 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'entropy'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:49,398] Trial 395 finished with value: 0.8032786885245902 and parameters: {'knn_n_neighbors': 2, 'knn_weights': 'uniform', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:49,569] Trial 396 finished with value: 0.8442622950819673 and parameters: {'knn_n_neighbors': 6, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 9, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:49,735] Trial 397 finished with value: 0.8360655737704918 and parameters: {'knn_n_neighbors': 4, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:49,888] Trial 398 finished with value: 0.8688524590163934 and parameters: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n",
      "[I 2023-12-03 17:14:50,080] Trial 399 finished with value: 0.819672131147541 and parameters: {'knn_n_neighbors': 1, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}. Best is trial 359 with value: 0.8934426229508197.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Found: {'knn_n_neighbors': 3, 'knn_weights': 'distance', 'dt_max_depth': 9, 'dt_criterion': 'gini', 'final_dt_max_depth': 8, 'final_dt_criterion': 'gini'}\n",
      "Corresponding Accuracy: 0.8934426229508197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "'''\n",
    "def objective(trial):\n",
    "    # KNN parameters\n",
    "    knn_n_neighbors = trial.suggest_int('knn_n_neighbors', 1, 50)\n",
    "    knn_weights = trial.suggest_categorical('knn_weights', ['uniform', 'distance'])\n",
    "    \n",
    "    # Decision Tree parameters\n",
    "    dt_max_depth = trial.suggest_int('dt_max_depth', 1, 10)\n",
    "    dt_criterion = trial.suggest_categorical('dt_criterion', ['gini', 'entropy'])\n",
    "    \n",
    "    # Final estimator (Decision Tree) parameters for Stacking Classifier\n",
    "    final_dt_max_depth = trial.suggest_int('final_dt_max_depth', 1, 10)\n",
    "    final_dt_criterion = trial.suggest_categorical('final_dt_criterion', ['gini', 'entropy'])\n",
    "\n",
    "    # Initialize KNN and Decision Tree classifiers\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=knn_n_neighbors, weights=knn_weights)\n",
    "    dt_model = DecisionTreeClassifier(max_depth=dt_max_depth, criterion=dt_criterion)\n",
    "    final_dt_model = DecisionTreeClassifier(max_depth=final_dt_max_depth, criterion=final_dt_criterion)\n",
    "\n",
    "    # Stacking Classifier with KNN and Decision Tree as base estimators\n",
    "    estimators = [('knn', knn_model), ('decision_tree', dt_model)]\n",
    "    stacking_model = StackingClassifier(estimators=estimators, final_estimator=final_dt_model)\n",
    "    stacking_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = stacking_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=400)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Parameters Found:\", best_params)\n",
    "print(\"Corresponding Accuracy:\", best_accuracy)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;knn&#x27;,\n",
       "                                KNeighborsClassifier(n_neighbors=3,\n",
       "                                                     weights=&#x27;distance&#x27;)),\n",
       "                               (&#x27;decision_tree&#x27;,\n",
       "                                DecisionTreeClassifier(max_depth=9))],\n",
       "                   final_estimator=DecisionTreeClassifier(max_depth=8))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;knn&#x27;,\n",
       "                                KNeighborsClassifier(n_neighbors=3,\n",
       "                                                     weights=&#x27;distance&#x27;)),\n",
       "                               (&#x27;decision_tree&#x27;,\n",
       "                                DecisionTreeClassifier(max_depth=9))],\n",
       "                   final_estimator=DecisionTreeClassifier(max_depth=8))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>knn</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>decision_tree</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=9)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=8)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(estimators=[('knn',\n",
       "                                KNeighborsClassifier(n_neighbors=3,\n",
       "                                                     weights='distance')),\n",
       "                               ('decision_tree',\n",
       "                                DecisionTreeClassifier(max_depth=9))],\n",
       "                   final_estimator=DecisionTreeClassifier(max_depth=8))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Entrenar un nuevo modelo con los mejores parámetros encontrados por Optuna\n",
    "best_knn_n_neighbors = best_params['knn_n_neighbors']\n",
    "best_knn_weights = best_params['knn_weights']\n",
    "best_dt_max_depth = best_params['dt_max_depth']\n",
    "best_dt_criterion = best_params['dt_criterion']\n",
    "best_final_dt_max_depth = best_params['final_dt_max_depth']\n",
    "best_final_dt_criterion = best_params['final_dt_criterion']\n",
    "\n",
    "best_knn_model = KNeighborsClassifier(n_neighbors=best_knn_n_neighbors, weights=best_knn_weights)\n",
    "best_dt_model = DecisionTreeClassifier(max_depth=best_dt_max_depth, criterion=best_dt_criterion)\n",
    "best_final_dt_model = DecisionTreeClassifier(max_depth=best_final_dt_max_depth, criterion=best_final_dt_criterion)\n",
    "\n",
    "best_estimators = [('knn', best_knn_model), ('decision_tree', best_dt_model)]\n",
    "best_stacking_model = StackingClassifier(estimators=best_estimators, final_estimator=best_final_dt_model)\n",
    "best_stacking_model.fit(X_train, y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Guardar el modelo\n",
    "with open('best_stacking_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(best_stacking_model, model_file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo\n",
    "with open('best_stacking_model.pkl', 'rb') as model_file:\n",
    "    loaded_model = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88        61\n",
      "           1       0.91      0.82      0.86        61\n",
      "\n",
      "    accuracy                           0.87       122\n",
      "   macro avg       0.87      0.87      0.87       122\n",
      "weighted avg       0.87      0.87      0.87       122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones en el conjunto de validación\n",
    "y_pred_val = loaded_model.predict(X_test)\n",
    "\n",
    "# Obtener el classification report\n",
    "classification_rep = classification_report(y_test, y_pred_val)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab_6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
