{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antes de ejecutar este código es importante leer el archivo README de la carpeta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primero el dataset de logs_entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "logs_entrenamiento = pd.read_csv('logs_entrenamiento.csv')\n",
    "\n",
    "# Configuración de pandas\n",
    "pd.set_option('display.max_columns', None) # Que se muestren todas las columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede notar que los datos son de los momentos en que una persona interactúa con la página. Existen tipos de interacciones o eventos. Ellos estan asociados a una persona, una momento en el tiempo y una sección (chapter) y subsección (sequential) de página."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificamos existencia de NA's\n",
    "logs_entrenamiento.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que los NA estan asociados a las variables de chapter y sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_entrenamiento.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se busca los grouped_event_type asociados a chapter\n",
    "\n",
    "valores_unicos = logs_entrenamiento.loc[logs_entrenamiento['chapter'].isna(), 'grouped_event_type'].unique()\n",
    "print(valores_unicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se busca los grouped_event_type asociados a sequential\n",
    "\n",
    "valores_unicos = logs_entrenamiento.loc[logs_entrenamiento['sequential'].isna(), 'grouped_event_type'].unique()\n",
    "print(valores_unicos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que los NA estan asociados a un típico específico de dato, es decir, es probable que estos NA no se deban a una falta de un dato existente, sino que, el tipo de registro asociado a edx no posee chapter ni sequential. En consecuencia, se decide no eliminar los NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(logs_entrenamiento['username'], bins=500, edgecolor='black')  # 'bins' define el número de barras en el histograma\n",
    "\n",
    "# Personaliza el título y las etiquetas de los ejes\n",
    "plt.title('Cantidad de veces que un usuario interactuó')\n",
    "\n",
    "# Muestra el histograma\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la eliminación de outlayers, se debe notar que es posible que aquellas personas que menos interactúan con la página, sean las personas que tienen las peores notas. Por lo tanto, se decide eliminar a los outlayers superiores únicamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el número mínimo y máximo de registros basados en el 5% más extremo\n",
    "umbral_minimo = logs_entrenamiento['username'].value_counts().quantile(0.00)\n",
    "umbral_maximo = logs_entrenamiento['username'].value_counts().quantile(0.90)\n",
    "\n",
    "# Filtra el DataFrame para eliminar las filas correspondientes\n",
    "logs_entrenamiento_filtrado = logs_entrenamiento[logs_entrenamiento.groupby('username')['username'].transform('count').between(umbral_minimo, umbral_maximo)]\n",
    "\n",
    "# Se omite la exportación del csv para este notebook en particular\n",
    "#logs_entrenamiento_filtrado.to_csv('logs_entrenamiento_filtrado.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora el dataset de notas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notas = pd.read_csv('notas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se modifica Not Atempted por -1\n",
    "notas = notas.replace('Not Attempted', -1)\n",
    "\n",
    "for col in notas.columns:\n",
    "    columnas_listas = ['Unnamed: 0','Username','Grade','Grade Scaled','Quiz (Avg)']\n",
    "    if col in columnas_listas:\n",
    "        continue\n",
    "    \n",
    "    notas[col] = pd.to_numeric(notas[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se verifica que funcionó\n",
    "notas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos existencia de NA's (No hay, se traspasó bien el type object a float)\n",
    "notas.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De la revisión del CSV, se observa que Quiz 17 contiene sólo casos 'No Atempted'\n",
    "notas['Quiz 17: Introducción'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos dicha columna\n",
    "notas = notas.drop('Quiz 17: Introducción', axis=1)    \n",
    "\n",
    "# Se observa que las columnas Grade y Grade Scalated contienen la misma información, se decide por querdarse con la original\n",
    "notas = notas.drop('Grade Scaled',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamiento de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "notas_df = notas\n",
    "\n",
    "# Reemplaza 'Not Attempted' con -1 y convierte las cadenas a flotantes\n",
    "quiz_columns = [col for col in notas_df.columns if 'Quiz' in col]\n",
    "notas_df[quiz_columns] = notas_df[quiz_columns].replace('Not Attempted', -1).astype(float)\n",
    "\n",
    "# Determinamos el número de filas para los subplots\n",
    "n_rows = (len(quiz_columns) + 1) // 2\n",
    "\n",
    "# Crear una figura con subplots en dos columnas\n",
    "fig = make_subplots(rows=n_rows, cols=2, subplot_titles=quiz_columns)\n",
    "\n",
    "# Añadir un histograma para cada cuestionario en la posición adecuada\n",
    "for idx, col in enumerate(quiz_columns):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=notas_df[col], name=col),\n",
    "        row=(idx // 2) + 1,  # Incrementar la fila después de cada dos cuestionarios\n",
    "        col=(idx % 2) + 1    # Alternar entre columna 1 y 2\n",
    "    )\n",
    "\n",
    "# Actualizar el layout para que se ajuste bien\n",
    "fig.update_layout(\n",
    "    height=300 * n_rows,  # Ajustar la altura si es necesario para acomodar todos los subplots\n",
    "    title_text=\"Distribución de Puntuaciones por Cuestionario\",\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Mostrar la figura\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al analizar los datos se puede ver que las variables se encuentran distribuidas dentro de rangos esperados, es decir, dentro de (0,1) con valores ocasionales de -1, los cuales son los eventos en que un estudiante decidió no intentar el Quiz.\n",
    "\n",
    "En el caso excepcional del Quiz 1, se observa una alta tasa de No Atempt, esto se puede deber a que el curso está comenzando y que el primer quiz es sin nota y ademas introductorio a EOL.\n",
    "\n",
    "Otra cosa a tomar en cuenta, es la fuerte concentración de registros alrededor de la nota 1.0 en todos los EOL, esto puede significar un trabajo futuro para el balanceo de clases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.boxplot(x=notas['Grade'])\n",
    "plt.title('Box Plot de notas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que en el agregado de notas, se tiene una fuerte tendencia a centrarse entre el 0.8 y el 1.0, se decide no eliminar aquellos outliers que nunca respondieron ningún quiz, por lo que obtuvieron nota 0. Esto porque pueden contener información de si la persona pertenece a la clase a identificar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay 26 outliers, lo que representa aproximadamente el 4.43% del total de datos.\n",
    "Los límites para considerar un valor como atípico están dados por:\n",
    "Límite inferior : 0.655\n",
    "Límite superior : 1.175\n",
    "Esto significa que cualquier calificación por debajo de 0.655 se considera un outlier. Dado que la escala de calificaciones no ha sido especificada, asumimos que está entre 0 y 1, donde 1 es la calificación más alta posible.\n",
    "\n",
    "Las estadísticas descriptivas de los outliers son:\n",
    "\n",
    "Media (Mean): 0.41, lo que indica que en promedio, los outliers están por debajo del promedio general.\n",
    "Desviación estándar (Std): 0.25, lo que muestra una variabilidad considerable entre los valores atípicos.\n",
    "Mínimo (Min): 0.00, la calificación más baja posible, lo que sugiere que algunos estudiantes no obtuvieron ningún punto.\n",
    "Cuartiles (25%, 50%, 75%): Los valores de los cuartiles indican que la mitad de los outliers tiene calificaciones entre 0.2475 y 0.5975, lo que muestra que no todos los outliers están en el extremo más bajo.\n",
    "Este pequeño porcentaje de outliers podría representar casos de estudiantes que tuvieron un rendimiento significativamente por debajo del promedio.\n",
    "A partir de esto consideramos importante no eliminar estos outliers dado que representan personas con baja califacion, por lo cual puede ser importante en el modelo que estas personas sean parte de los datos, para que el modelo tambien aprenda de estos usuarios, que pueden ser parte importante de los que reprobaron el ramo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de los outliers encontrados en logs entrenamiento, los quitamos del dataframe de notas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos los usuarios del df filtrados\n",
    "usernames_filtrados = set(logs_entrenamiento_filtrado['username'].unique())\n",
    "len(usernames_filtrados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos los usuarios del df sin filtrar\n",
    "logs_entrenamiento = pd.read_csv('logs_entrenamiento.csv')\n",
    "usernames_sin_filtrar = set(logs_entrenamiento['username'].unique())\n",
    "len(usernames_sin_filtrar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usernames_diferencia = usernames_sin_filtrar - usernames_filtrados\n",
    "# Obtenemos los usuarios que fueron eliminados, es decir, los outliers del logs entrenamiento\n",
    "len(usernames_diferencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notas_df_filtrado = notas_df[~notas_df['Username'].isin(usernames_diferencia)]\n",
    "len(notas_df_filtrado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cruce de los datos y generación de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventos = logs_entrenamiento_filtrado.copy()\n",
    "\n",
    "notas = notas_df_filtrado.copy()\n",
    "\n",
    "chapter = pd.read_csv('/map_displayname_to_chap_seq_id.csv')\n",
    "\n",
    "column_names_df = notas.columns\n",
    "\n",
    "\n",
    "column_names_eventos = eventos.columns\n",
    "\n",
    "# Print the column names\n",
    "print(\"Column names of 'df':\", column_names_df)\n",
    "print(\"Column names of 'eventos':\", column_names_eventos)\n",
    "\n",
    "# Rename a single column\n",
    "notas.rename(columns={'Username': 'username'}, inplace=True)\n",
    "\n",
    "notas = notas.replace('Not Attempted', 0)\n",
    "\n",
    "notas.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
