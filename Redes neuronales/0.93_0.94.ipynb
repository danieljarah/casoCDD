{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entrenamiento = pd.read_csv('C:/Users/tomas/OneDrive - Universidad de Chile/Semestre 2023-2 Archivos/Laboratorio de Programación Científica/Laboratorios/Github/casoCDD/Cruce/data_para_entrenar.csv')\n",
    "df_entrenamiento = pd.read_csv('C:/Users/tomas/OneDrive - Universidad de Chile/Semestre 2023-2 Archivos/Laboratorio de Programación Científica/Laboratorios/Github/casoCDD/Oversampling/df_entrenamiento_sobre.csv')\n",
    "df_validacion = pd.read_csv('C:/Users/tomas/OneDrive - Universidad de Chile/Semestre 2023-2 Archivos/Laboratorio de Programación Científica/Laboratorios/Github/casoCDD/data_para_validar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>grade</th>\n",
       "      <th>seq_4_avg</th>\n",
       "      <th>quiz_avg</th>\n",
       "      <th>seq_0_avg</th>\n",
       "      <th>seq_1_avg</th>\n",
       "      <th>seq_2_avg</th>\n",
       "      <th>seq_3_avg</th>\n",
       "      <th>duracion_sesion_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>pause_video_mean</th>\n",
       "      <th>pause_video_std</th>\n",
       "      <th>speed_change_video_mean</th>\n",
       "      <th>speed_change_video_std</th>\n",
       "      <th>num_eventos_seq_0</th>\n",
       "      <th>num_eventos_seq_1</th>\n",
       "      <th>num_eventos_seq_2</th>\n",
       "      <th>num_eventos_seq_3</th>\n",
       "      <th>num_eventos_seq_4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.944454</td>\n",
       "      <td>...</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>7.409453</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.674949</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1032</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.410485</td>\n",
       "      <td>...</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>5.957727</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.363137</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1734</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.794893</td>\n",
       "      <td>...</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>10.399863</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2898</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.850690</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.907778</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.008391</td>\n",
       "      <td>...</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>22.487457</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.298351</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>9.352263</td>\n",
       "      <td>...</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>25.263319</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.060275</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>810.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>603</td>\n",
       "      <td>282522</td>\n",
       "      <td>0.940363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.868407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.804222</td>\n",
       "      <td>0.779122</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.003087</td>\n",
       "      <td>...</td>\n",
       "      <td>6.908206</td>\n",
       "      <td>10.864660</td>\n",
       "      <td>0.122678</td>\n",
       "      <td>0.272942</td>\n",
       "      <td>67.602155</td>\n",
       "      <td>244.612931</td>\n",
       "      <td>156.119639</td>\n",
       "      <td>8.036288</td>\n",
       "      <td>3.012096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>604</td>\n",
       "      <td>129478</td>\n",
       "      <td>0.842813</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.813376</td>\n",
       "      <td>0.866209</td>\n",
       "      <td>0.762787</td>\n",
       "      <td>0.704212</td>\n",
       "      <td>0.69011</td>\n",
       "      <td>5.248995</td>\n",
       "      <td>...</td>\n",
       "      <td>9.150560</td>\n",
       "      <td>9.437040</td>\n",
       "      <td>0.200196</td>\n",
       "      <td>0.477776</td>\n",
       "      <td>134.394506</td>\n",
       "      <td>451.265933</td>\n",
       "      <td>186.107700</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.929670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>605</td>\n",
       "      <td>310479</td>\n",
       "      <td>0.839504</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.809557</td>\n",
       "      <td>0.947313</td>\n",
       "      <td>0.703419</td>\n",
       "      <td>0.532586</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.482947</td>\n",
       "      <td>...</td>\n",
       "      <td>5.525875</td>\n",
       "      <td>7.274908</td>\n",
       "      <td>0.106805</td>\n",
       "      <td>0.295753</td>\n",
       "      <td>94.586866</td>\n",
       "      <td>419.706268</td>\n",
       "      <td>135.533134</td>\n",
       "      <td>22.314030</td>\n",
       "      <td>11.318209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>606</td>\n",
       "      <td>168867</td>\n",
       "      <td>0.881915</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852923</td>\n",
       "      <td>0.717063</td>\n",
       "      <td>0.817364</td>\n",
       "      <td>0.902334</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.551731</td>\n",
       "      <td>...</td>\n",
       "      <td>15.414130</td>\n",
       "      <td>18.579293</td>\n",
       "      <td>1.461072</td>\n",
       "      <td>2.026446</td>\n",
       "      <td>127.521237</td>\n",
       "      <td>556.190787</td>\n",
       "      <td>222.634988</td>\n",
       "      <td>29.964003</td>\n",
       "      <td>10.982002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>607</td>\n",
       "      <td>154541</td>\n",
       "      <td>0.935885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.903971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854285</td>\n",
       "      <td>0.979781</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.702868</td>\n",
       "      <td>...</td>\n",
       "      <td>11.687961</td>\n",
       "      <td>17.541553</td>\n",
       "      <td>0.710228</td>\n",
       "      <td>1.122771</td>\n",
       "      <td>150.003533</td>\n",
       "      <td>407.662693</td>\n",
       "      <td>253.674614</td>\n",
       "      <td>18.691391</td>\n",
       "      <td>6.345695</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.1  Unnamed: 0     grade  seq_4_avg  quiz_avg  seq_0_avg  \\\n",
       "0               0           0  1.000000        1.0  0.965517   1.000000   \n",
       "1               1        1032  0.990000        1.0  0.956897   1.000000   \n",
       "2               2        1734  1.000000        1.0  0.965517   1.000000   \n",
       "3               3        2898  0.880000        1.0  0.850690   0.625000   \n",
       "4               4        4203  1.000000        1.0  0.965517   1.000000   \n",
       "..            ...         ...       ...        ...       ...        ...   \n",
       "603           603      282522  0.940363        1.0  0.868407   1.000000   \n",
       "604           604      129478  0.842813        1.0  0.813376   0.866209   \n",
       "605           605      310479  0.839504        1.0  0.809557   0.947313   \n",
       "606           606      168867  0.881915        1.0  0.852923   0.717063   \n",
       "607           607      154541  0.935885        1.0  0.903971   1.000000   \n",
       "\n",
       "     seq_1_avg  seq_2_avg  seq_3_avg  duracion_sesion_avg  ...  \\\n",
       "0     1.000000   1.000000    1.00000             4.944454  ...   \n",
       "1     0.977273   1.000000    1.00000             2.410485  ...   \n",
       "2     1.000000   1.000000    1.00000             3.794893  ...   \n",
       "3     0.909091   0.907778    1.00000             4.008391  ...   \n",
       "4     1.000000   1.000000    1.00000             9.352263  ...   \n",
       "..         ...        ...        ...                  ...  ...   \n",
       "603   0.804222   0.779122    1.00000             5.003087  ...   \n",
       "604   0.762787   0.704212    0.69011             5.248995  ...   \n",
       "605   0.703419   0.532586    1.00000             6.482947  ...   \n",
       "606   0.817364   0.902334    1.00000             5.551731  ...   \n",
       "607   0.854285   0.979781    1.00000             4.702868  ...   \n",
       "\n",
       "     pause_video_mean  pause_video_std  speed_change_video_mean  \\\n",
       "0            8.700000         7.409453                 0.300000   \n",
       "1            4.428571         5.957727                 0.142857   \n",
       "2            7.571429        10.399863                 0.142857   \n",
       "3           13.600000        22.487457                 0.600000   \n",
       "4           15.333333        25.263319                 0.777778   \n",
       "..                ...              ...                      ...   \n",
       "603          6.908206        10.864660                 0.122678   \n",
       "604          9.150560         9.437040                 0.200196   \n",
       "605          5.525875         7.274908                 0.106805   \n",
       "606         15.414130        18.579293                 1.461072   \n",
       "607         11.687961        17.541553                 0.710228   \n",
       "\n",
       "     speed_change_video_std  num_eventos_seq_0  num_eventos_seq_1  \\\n",
       "0                  0.674949          76.000000         384.000000   \n",
       "1                  0.363137          70.000000         168.000000   \n",
       "2                  0.478091         197.000000         346.000000   \n",
       "3                  1.298351         177.000000         466.000000   \n",
       "4                  1.060275         264.000000         810.000000   \n",
       "..                      ...                ...                ...   \n",
       "603                0.272942          67.602155         244.612931   \n",
       "604                0.477776         134.394506         451.265933   \n",
       "605                0.295753          94.586866         419.706268   \n",
       "606                2.026446         127.521237         556.190787   \n",
       "607                1.122771         150.003533         407.662693   \n",
       "\n",
       "     num_eventos_seq_2  num_eventos_seq_3  num_eventos_seq_4  label  \n",
       "0           128.000000          16.000000          20.000000      1  \n",
       "1            90.000000          16.000000           6.000000      1  \n",
       "2           151.000000          47.000000           8.000000      1  \n",
       "3           201.000000          33.000000           9.000000      1  \n",
       "4            80.000000          19.000000          11.000000      0  \n",
       "..                 ...                ...                ...    ...  \n",
       "603         156.119639           8.036288           3.012096      0  \n",
       "604         186.107700          13.000000           2.929670      0  \n",
       "605         135.533134          22.314030          11.318209      0  \n",
       "606         222.634988          29.964003          10.982002      0  \n",
       "607         253.674614          18.691391           6.345695      0  \n",
       "\n",
       "[608 rows x 43 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'grade', 'seq_4_avg', 'quiz_avg',\n",
       "       'seq_0_avg', 'seq_1_avg', 'seq_2_avg', 'seq_3_avg',\n",
       "       'duracion_sesion_avg', 'duracion_sesion_std', 'duracion_EOL',\n",
       "       'num_sesiones_agosto', 'num_sesiones_septiembre',\n",
       "       'num_sesiones_noviembre', 'page_close_mean', 'page_close_std',\n",
       "       'problem_graded_mean', 'problem_graded_std', 'problem_check_mean',\n",
       "       'problem_check_std', 'problem_show_mean', 'problem_show_std',\n",
       "       'seg_prev_mean', 'seg_prev_std', 'seg_next_mean', 'seg_next_std',\n",
       "       'seg_goto_mean', 'seg_goto_std', 'load_video_mean', 'load_video_std',\n",
       "       'play_video_mean', 'play_video_std', 'pause_video_mean',\n",
       "       'pause_video_std', 'speed_change_video_mean', 'speed_change_video_std',\n",
       "       'num_eventos_seq_0', 'num_eventos_seq_1', 'num_eventos_seq_2',\n",
       "       'num_eventos_seq_3', 'num_eventos_seq_4', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entrenamiento.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entrenamiento.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>seq_4_avg</th>\n",
       "      <th>quiz_avg</th>\n",
       "      <th>seq_0_avg</th>\n",
       "      <th>seq_1_avg</th>\n",
       "      <th>seq_2_avg</th>\n",
       "      <th>seq_3_avg</th>\n",
       "      <th>duracion_sesion_avg</th>\n",
       "      <th>duracion_sesion_std</th>\n",
       "      <th>duracion_EOL</th>\n",
       "      <th>...</th>\n",
       "      <th>pause_video_mean</th>\n",
       "      <th>pause_video_std</th>\n",
       "      <th>speed_change_video_mean</th>\n",
       "      <th>speed_change_video_std</th>\n",
       "      <th>num_eventos_seq_0</th>\n",
       "      <th>num_eventos_seq_1</th>\n",
       "      <th>num_eventos_seq_2</th>\n",
       "      <th>num_eventos_seq_3</th>\n",
       "      <th>num_eventos_seq_4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.944454</td>\n",
       "      <td>5.131721</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>7.409453</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.674949</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.990000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.410485</td>\n",
       "      <td>2.627586</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>5.957727</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.363137</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.794893</td>\n",
       "      <td>5.967056</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>10.399863</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.850690</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.907778</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.008391</td>\n",
       "      <td>5.076566</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>22.487457</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.298351</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>9.352263</td>\n",
       "      <td>8.270573</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>25.263319</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.060275</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>810.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>0.940363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.868407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.804222</td>\n",
       "      <td>0.779122</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.003087</td>\n",
       "      <td>7.729962</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.908206</td>\n",
       "      <td>10.864660</td>\n",
       "      <td>0.122678</td>\n",
       "      <td>0.272942</td>\n",
       "      <td>67.602155</td>\n",
       "      <td>244.612931</td>\n",
       "      <td>156.119639</td>\n",
       "      <td>8.036288</td>\n",
       "      <td>3.012096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>0.842813</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.813376</td>\n",
       "      <td>0.866209</td>\n",
       "      <td>0.762787</td>\n",
       "      <td>0.704212</td>\n",
       "      <td>0.69011</td>\n",
       "      <td>5.248995</td>\n",
       "      <td>6.035853</td>\n",
       "      <td>56.394506</td>\n",
       "      <td>...</td>\n",
       "      <td>9.150560</td>\n",
       "      <td>9.437040</td>\n",
       "      <td>0.200196</td>\n",
       "      <td>0.477776</td>\n",
       "      <td>134.394506</td>\n",
       "      <td>451.265933</td>\n",
       "      <td>186.107700</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.929670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>0.839504</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.809557</td>\n",
       "      <td>0.947313</td>\n",
       "      <td>0.703419</td>\n",
       "      <td>0.532586</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.482947</td>\n",
       "      <td>6.920673</td>\n",
       "      <td>53.842985</td>\n",
       "      <td>...</td>\n",
       "      <td>5.525875</td>\n",
       "      <td>7.274908</td>\n",
       "      <td>0.106805</td>\n",
       "      <td>0.295753</td>\n",
       "      <td>94.586866</td>\n",
       "      <td>419.706268</td>\n",
       "      <td>135.533134</td>\n",
       "      <td>22.314030</td>\n",
       "      <td>11.318209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>0.881915</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852923</td>\n",
       "      <td>0.717063</td>\n",
       "      <td>0.817364</td>\n",
       "      <td>0.902334</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.551731</td>\n",
       "      <td>6.395383</td>\n",
       "      <td>55.263499</td>\n",
       "      <td>...</td>\n",
       "      <td>15.414130</td>\n",
       "      <td>18.579293</td>\n",
       "      <td>1.461072</td>\n",
       "      <td>2.026446</td>\n",
       "      <td>127.521237</td>\n",
       "      <td>556.190787</td>\n",
       "      <td>222.634988</td>\n",
       "      <td>29.964003</td>\n",
       "      <td>10.982002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>0.935885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.903971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854285</td>\n",
       "      <td>0.979781</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.702868</td>\n",
       "      <td>4.789794</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.687961</td>\n",
       "      <td>17.541553</td>\n",
       "      <td>0.710228</td>\n",
       "      <td>1.122771</td>\n",
       "      <td>150.003533</td>\n",
       "      <td>407.662693</td>\n",
       "      <td>253.674614</td>\n",
       "      <td>18.691391</td>\n",
       "      <td>6.345695</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        grade  seq_4_avg  quiz_avg  seq_0_avg  seq_1_avg  seq_2_avg  \\\n",
       "0    1.000000        1.0  0.965517   1.000000   1.000000   1.000000   \n",
       "1    0.990000        1.0  0.956897   1.000000   0.977273   1.000000   \n",
       "2    1.000000        1.0  0.965517   1.000000   1.000000   1.000000   \n",
       "3    0.880000        1.0  0.850690   0.625000   0.909091   0.907778   \n",
       "4    1.000000        1.0  0.965517   1.000000   1.000000   1.000000   \n",
       "..        ...        ...       ...        ...        ...        ...   \n",
       "603  0.940363        1.0  0.868407   1.000000   0.804222   0.779122   \n",
       "604  0.842813        1.0  0.813376   0.866209   0.762787   0.704212   \n",
       "605  0.839504        1.0  0.809557   0.947313   0.703419   0.532586   \n",
       "606  0.881915        1.0  0.852923   0.717063   0.817364   0.902334   \n",
       "607  0.935885        1.0  0.903971   1.000000   0.854285   0.979781   \n",
       "\n",
       "     seq_3_avg  duracion_sesion_avg  duracion_sesion_std  duracion_EOL  ...  \\\n",
       "0      1.00000             4.944454             5.131721     64.000000  ...   \n",
       "1      1.00000             2.410485             2.627586     60.000000  ...   \n",
       "2      1.00000             3.794893             5.967056     59.000000  ...   \n",
       "3      1.00000             4.008391             5.076566     58.000000  ...   \n",
       "4      1.00000             9.352263             8.270573     58.000000  ...   \n",
       "..         ...                  ...                  ...           ...  ...   \n",
       "603    1.00000             5.003087             7.729962     52.000000  ...   \n",
       "604    0.69011             5.248995             6.035853     56.394506  ...   \n",
       "605    1.00000             6.482947             6.920673     53.842985  ...   \n",
       "606    1.00000             5.551731             6.395383     55.263499  ...   \n",
       "607    1.00000             4.702868             4.789794     59.000000  ...   \n",
       "\n",
       "     pause_video_mean  pause_video_std  speed_change_video_mean  \\\n",
       "0            8.700000         7.409453                 0.300000   \n",
       "1            4.428571         5.957727                 0.142857   \n",
       "2            7.571429        10.399863                 0.142857   \n",
       "3           13.600000        22.487457                 0.600000   \n",
       "4           15.333333        25.263319                 0.777778   \n",
       "..                ...              ...                      ...   \n",
       "603          6.908206        10.864660                 0.122678   \n",
       "604          9.150560         9.437040                 0.200196   \n",
       "605          5.525875         7.274908                 0.106805   \n",
       "606         15.414130        18.579293                 1.461072   \n",
       "607         11.687961        17.541553                 0.710228   \n",
       "\n",
       "     speed_change_video_std  num_eventos_seq_0  num_eventos_seq_1  \\\n",
       "0                  0.674949          76.000000         384.000000   \n",
       "1                  0.363137          70.000000         168.000000   \n",
       "2                  0.478091         197.000000         346.000000   \n",
       "3                  1.298351         177.000000         466.000000   \n",
       "4                  1.060275         264.000000         810.000000   \n",
       "..                      ...                ...                ...   \n",
       "603                0.272942          67.602155         244.612931   \n",
       "604                0.477776         134.394506         451.265933   \n",
       "605                0.295753          94.586866         419.706268   \n",
       "606                2.026446         127.521237         556.190787   \n",
       "607                1.122771         150.003533         407.662693   \n",
       "\n",
       "     num_eventos_seq_2  num_eventos_seq_3  num_eventos_seq_4  label  \n",
       "0           128.000000          16.000000          20.000000      1  \n",
       "1            90.000000          16.000000           6.000000      1  \n",
       "2           151.000000          47.000000           8.000000      1  \n",
       "3           201.000000          33.000000           9.000000      1  \n",
       "4            80.000000          19.000000          11.000000      0  \n",
       "..                 ...                ...                ...    ...  \n",
       "603         156.119639           8.036288           3.012096      0  \n",
       "604         186.107700          13.000000           2.929670      0  \n",
       "605         135.533134          22.314030          11.318209      0  \n",
       "606         222.634988          29.964003          10.982002      0  \n",
       "607         253.674614          18.691391           6.345695      0  \n",
       "\n",
       "[608 rows x 41 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "seed = 314159\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_entrenamiento.drop(columns=['label'])  # Características\n",
    "y = df_entrenamiento['label']  # Etiquetas\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=314159, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Crea un objeto StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Ajusta el scaler a tus datos de entrenamiento y luego transforma los datos\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transforma también los datos de prueba usando el mismo scaler\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "input_shape = [X_train.shape[1]]\n",
    "model = keras.Sequential([\n",
    "    layers.BatchNormalization(input_shape=input_shape),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256, activation='relu'), \n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=50,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 0.4327 - accuracy: 0.8128 - val_loss: 0.6945 - val_accuracy: 0.7623\n",
      "Epoch 2/500\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 0.4203 - accuracy: 0.8107 - val_loss: 0.5377 - val_accuracy: 0.7705\n",
      "Epoch 3/500\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.4126 - accuracy: 0.7963 - val_loss: 0.5982 - val_accuracy: 0.8115\n",
      "Epoch 4/500\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.4352 - accuracy: 0.8086 - val_loss: 0.5964 - val_accuracy: 0.7951\n",
      "Epoch 5/500\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.4426 - accuracy: 0.8086 - val_loss: 0.5889 - val_accuracy: 0.7623\n",
      "Epoch 6/500\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.4063 - accuracy: 0.8230 - val_loss: 0.5923 - val_accuracy: 0.7705\n",
      "Epoch 7/500\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 0.4285 - accuracy: 0.8230 - val_loss: 0.5630 - val_accuracy: 0.8115\n",
      "Epoch 8/500\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 0.3911 - accuracy: 0.8477 - val_loss: 0.5951 - val_accuracy: 0.7787\n",
      "Epoch 9/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.4319 - accuracy: 0.7922 - val_loss: 0.4883 - val_accuracy: 0.7869\n",
      "Epoch 10/500\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.4247 - accuracy: 0.8086 - val_loss: 0.7712 - val_accuracy: 0.7787\n",
      "Epoch 11/500\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.3709 - accuracy: 0.8395 - val_loss: 0.5529 - val_accuracy: 0.7787\n",
      "Epoch 12/500\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.3641 - accuracy: 0.8395 - val_loss: 0.6704 - val_accuracy: 0.7213\n",
      "Epoch 13/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.3900 - accuracy: 0.8210 - val_loss: 0.5571 - val_accuracy: 0.7787\n",
      "Epoch 14/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.3383 - accuracy: 0.8436 - val_loss: 0.6050 - val_accuracy: 0.7869\n",
      "Epoch 15/500\n",
      "61/61 [==============================] - 1s 10ms/step - loss: 0.3112 - accuracy: 0.8539 - val_loss: 0.6732 - val_accuracy: 0.7951\n",
      "Epoch 16/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.4070 - accuracy: 0.8148 - val_loss: 0.5404 - val_accuracy: 0.7869\n",
      "Epoch 17/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.3121 - accuracy: 0.8683 - val_loss: 0.4934 - val_accuracy: 0.7787\n",
      "Epoch 18/500\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.3644 - accuracy: 0.8374 - val_loss: 0.4709 - val_accuracy: 0.8033\n",
      "Epoch 19/500\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.3460 - accuracy: 0.8333 - val_loss: 0.5444 - val_accuracy: 0.7705\n",
      "Epoch 20/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.2974 - accuracy: 0.8683 - val_loss: 0.5865 - val_accuracy: 0.7705\n",
      "Epoch 21/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.3404 - accuracy: 0.8416 - val_loss: 0.5391 - val_accuracy: 0.8115\n",
      "Epoch 22/500\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.3509 - accuracy: 0.8519 - val_loss: 0.7304 - val_accuracy: 0.7541\n",
      "Epoch 23/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.3034 - accuracy: 0.8580 - val_loss: 0.5468 - val_accuracy: 0.7705\n",
      "Epoch 24/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.3649 - accuracy: 0.8436 - val_loss: 0.4753 - val_accuracy: 0.8115\n",
      "Epoch 25/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.3714 - accuracy: 0.8457 - val_loss: 0.6314 - val_accuracy: 0.7623\n",
      "Epoch 26/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.3036 - accuracy: 0.8704 - val_loss: 0.5337 - val_accuracy: 0.8197\n",
      "Epoch 27/500\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.3180 - accuracy: 0.8560 - val_loss: 0.5804 - val_accuracy: 0.7869\n",
      "Epoch 28/500\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.3251 - accuracy: 0.8416 - val_loss: 0.4807 - val_accuracy: 0.7705\n",
      "Epoch 29/500\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 0.2966 - accuracy: 0.8745 - val_loss: 0.5164 - val_accuracy: 0.7705\n",
      "Epoch 30/500\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 0.3741 - accuracy: 0.8333 - val_loss: 0.5699 - val_accuracy: 0.7623\n",
      "Epoch 31/500\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.3393 - accuracy: 0.8539 - val_loss: 0.4839 - val_accuracy: 0.7869\n",
      "Epoch 32/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.3388 - accuracy: 0.8539 - val_loss: 0.4796 - val_accuracy: 0.8033\n",
      "Epoch 33/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.3004 - accuracy: 0.8765 - val_loss: 0.5155 - val_accuracy: 0.7787\n",
      "Epoch 34/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.3120 - accuracy: 0.8642 - val_loss: 0.4837 - val_accuracy: 0.8197\n",
      "Epoch 35/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.3442 - accuracy: 0.8436 - val_loss: 0.5066 - val_accuracy: 0.7869\n",
      "Epoch 36/500\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 0.3596 - accuracy: 0.8498 - val_loss: 0.4910 - val_accuracy: 0.7951\n",
      "Epoch 37/500\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 0.2939 - accuracy: 0.8827 - val_loss: 0.4491 - val_accuracy: 0.8115\n",
      "Epoch 38/500\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 0.3056 - accuracy: 0.8580 - val_loss: 0.5072 - val_accuracy: 0.7787\n",
      "Epoch 39/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.2940 - accuracy: 0.8683 - val_loss: 0.4574 - val_accuracy: 0.7787\n",
      "Epoch 40/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.3352 - accuracy: 0.8560 - val_loss: 0.4476 - val_accuracy: 0.8033\n",
      "Epoch 41/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.3314 - accuracy: 0.8436 - val_loss: 0.5572 - val_accuracy: 0.8115\n",
      "Epoch 42/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.2846 - accuracy: 0.8786 - val_loss: 0.5801 - val_accuracy: 0.7623\n",
      "Epoch 43/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.3148 - accuracy: 0.8539 - val_loss: 0.4410 - val_accuracy: 0.7787\n",
      "Epoch 44/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.3079 - accuracy: 0.8765 - val_loss: 0.5228 - val_accuracy: 0.7869\n",
      "Epoch 45/500\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.3201 - accuracy: 0.8683 - val_loss: 0.5352 - val_accuracy: 0.7951\n",
      "Epoch 46/500\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.3470 - accuracy: 0.8539 - val_loss: 0.5135 - val_accuracy: 0.7787\n",
      "Epoch 47/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.2601 - accuracy: 0.8971 - val_loss: 0.4834 - val_accuracy: 0.8033\n",
      "Epoch 48/500\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2730 - accuracy: 0.8724 - val_loss: 0.5191 - val_accuracy: 0.8033\n",
      "Epoch 49/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.3067 - accuracy: 0.8765 - val_loss: 0.5785 - val_accuracy: 0.8197\n",
      "Epoch 50/500\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 0.3210 - accuracy: 0.8704 - val_loss: 0.6096 - val_accuracy: 0.7787\n",
      "Epoch 51/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.2781 - accuracy: 0.8765 - val_loss: 0.6125 - val_accuracy: 0.8033\n",
      "Epoch 52/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.2860 - accuracy: 0.8704 - val_loss: 0.6052 - val_accuracy: 0.7951\n",
      "Epoch 53/500\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.3327 - accuracy: 0.8560 - val_loss: 0.6100 - val_accuracy: 0.7705\n",
      "Epoch 54/500\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.3551 - accuracy: 0.8580 - val_loss: 0.6262 - val_accuracy: 0.7951\n",
      "Epoch 55/500\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.3032 - accuracy: 0.8704 - val_loss: 0.5539 - val_accuracy: 0.7869\n",
      "Epoch 56/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.3503 - accuracy: 0.8519 - val_loss: 0.6011 - val_accuracy: 0.7705\n",
      "Epoch 57/500\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2933 - accuracy: 0.8930 - val_loss: 0.6988 - val_accuracy: 0.7459\n",
      "Epoch 58/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.3005 - accuracy: 0.8745 - val_loss: 0.6700 - val_accuracy: 0.7869\n",
      "Epoch 59/500\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2834 - accuracy: 0.8827 - val_loss: 0.6252 - val_accuracy: 0.7869\n",
      "Epoch 60/500\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.3005 - accuracy: 0.8848 - val_loss: 0.4823 - val_accuracy: 0.8033\n",
      "Epoch 61/500\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.3077 - accuracy: 0.8560 - val_loss: 0.5486 - val_accuracy: 0.8279\n",
      "Epoch 62/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.2710 - accuracy: 0.9074 - val_loss: 0.6143 - val_accuracy: 0.7623\n",
      "Epoch 63/500\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.3032 - accuracy: 0.8683 - val_loss: 0.4965 - val_accuracy: 0.8279\n",
      "Epoch 64/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.3069 - accuracy: 0.8539 - val_loss: 0.5593 - val_accuracy: 0.7869\n",
      "Epoch 65/500\n",
      "61/61 [==============================] - 1s 8ms/step - loss: 0.2661 - accuracy: 0.8848 - val_loss: 0.6107 - val_accuracy: 0.7541\n",
      "Epoch 66/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.2563 - accuracy: 0.8971 - val_loss: 0.5462 - val_accuracy: 0.8197\n",
      "Epoch 67/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.3178 - accuracy: 0.8601 - val_loss: 0.5879 - val_accuracy: 0.7787\n",
      "Epoch 68/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.3261 - accuracy: 0.8580 - val_loss: 0.4888 - val_accuracy: 0.8197\n",
      "Epoch 69/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.3200 - accuracy: 0.8519 - val_loss: 0.5014 - val_accuracy: 0.7951\n",
      "Epoch 70/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.2708 - accuracy: 0.8827 - val_loss: 0.6593 - val_accuracy: 0.7951\n",
      "Epoch 71/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.2719 - accuracy: 0.8848 - val_loss: 0.6012 - val_accuracy: 0.7951\n",
      "Epoch 72/500\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.2929 - accuracy: 0.8724 - val_loss: 0.6375 - val_accuracy: 0.8033\n",
      "Epoch 73/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.3075 - accuracy: 0.8745 - val_loss: 0.6746 - val_accuracy: 0.8115\n",
      "Epoch 74/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.2939 - accuracy: 0.8724 - val_loss: 0.5967 - val_accuracy: 0.8279\n",
      "Epoch 75/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.3212 - accuracy: 0.8745 - val_loss: 0.6623 - val_accuracy: 0.8115\n",
      "Epoch 76/500\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2719 - accuracy: 0.8807 - val_loss: 0.4822 - val_accuracy: 0.8197\n",
      "Epoch 77/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.2961 - accuracy: 0.8745 - val_loss: 0.5479 - val_accuracy: 0.8033\n",
      "Epoch 78/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.2884 - accuracy: 0.8683 - val_loss: 0.5775 - val_accuracy: 0.7623\n",
      "Epoch 79/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.2747 - accuracy: 0.8827 - val_loss: 0.5509 - val_accuracy: 0.7705\n",
      "Epoch 80/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.2899 - accuracy: 0.8683 - val_loss: 0.4419 - val_accuracy: 0.8033\n",
      "Epoch 81/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.2842 - accuracy: 0.8683 - val_loss: 0.5585 - val_accuracy: 0.7541\n",
      "Epoch 82/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.3243 - accuracy: 0.8621 - val_loss: 0.4855 - val_accuracy: 0.8033\n",
      "Epoch 83/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.2417 - accuracy: 0.9053 - val_loss: 0.4744 - val_accuracy: 0.8197\n",
      "Epoch 84/500\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2752 - accuracy: 0.8848 - val_loss: 0.4711 - val_accuracy: 0.8115\n",
      "Epoch 85/500\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.3240 - accuracy: 0.8663 - val_loss: 0.4493 - val_accuracy: 0.8197\n",
      "Epoch 86/500\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2325 - accuracy: 0.9012 - val_loss: 0.4761 - val_accuracy: 0.7869\n",
      "Epoch 87/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.3079 - accuracy: 0.8724 - val_loss: 0.5620 - val_accuracy: 0.7787\n",
      "Epoch 88/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.2630 - accuracy: 0.9053 - val_loss: 0.5622 - val_accuracy: 0.7787\n",
      "Epoch 89/500\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.2491 - accuracy: 0.8848 - val_loss: 0.4441 - val_accuracy: 0.8197\n",
      "Epoch 90/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.2746 - accuracy: 0.8930 - val_loss: 0.5323 - val_accuracy: 0.7787\n",
      "Epoch 91/500\n",
      "61/61 [==============================] - 0s 7ms/step - loss: 0.2682 - accuracy: 0.8807 - val_loss: 0.5072 - val_accuracy: 0.8033\n",
      "Epoch 92/500\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.2847 - accuracy: 0.8848 - val_loss: 0.4561 - val_accuracy: 0.8443\n",
      "Epoch 93/500\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 0.2895 - accuracy: 0.8868 - val_loss: 0.4691 - val_accuracy: 0.8033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x241affe7010>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=500, batch_size=8, validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.7787\n",
      "Exactitud en datos de prueba: 0.7786885499954224\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Exactitud en datos de prueba:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.93      0.93      0.93        30\n",
      "     Clase 1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.93        61\n",
      "   macro avg       0.93      0.93      0.93        61\n",
      "weighted avg       0.93      0.93      0.93        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Supongamos que ya tienes un modelo entrenado\n",
    "# Reemplaza esto con tus datos reales\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convierte las predicciones en etiquetas binarias aplicando un umbral (por ejemplo, 0.5)\n",
    "threshold = 0.5\n",
    "y_pred_binary = (y_pred > threshold).astype(int)\n",
    "\n",
    "# Calcula el informe de clasificación\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred_binary, target_names=[\"Clase 0\", \"Clase 1\"])  # Reemplaza con las etiquetas reales\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv('C:/Users/tomas/OneDrive - Universidad de Chile/Semestre 2023-2 Archivos/Laboratorio de Programación Científica/Laboratorios/Github/casoCDD/Cruce/data_para_validar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = df_val.drop(['username', 'Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta el scaler a tus datos de entrenamiento y luego transforma los datos\n",
    "X_val = scaler.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones con el modelo cargado\n",
    "y_pred = (model.predict(X_val) > 0.5).astype(int)\n",
    "\n",
    "# Agregar las predicciones como una nueva columna al conjunto de datos original\n",
    "resultados = pd.DataFrame({'username': df_val['username'], 'Prediccion': y_pred.flatten()})\n",
    "\n",
    "# Guardar los resultados en un archivo CSV\n",
    "resultados.to_csv('resultados_predichos.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab_6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
