{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entrenamiento = pd.read_csv('C:/Users/tomas/OneDrive - Universidad de Chile/Semestre 2023-2 Archivos/Laboratorio de Programación Científica/Laboratorios/Github/casoCDD/Cruce/data_para_entrenar.csv')\n",
    "df_entrenamiento = pd.read_csv('C:/Users/tomas/OneDrive - Universidad de Chile/Semestre 2023-2 Archivos/Laboratorio de Programación Científica/Laboratorios/Github/casoCDD/Oversampling/df_entrenamiento_sobre.csv')\n",
    "df_validacion = pd.read_csv('C:/Users/tomas/OneDrive - Universidad de Chile/Semestre 2023-2 Archivos/Laboratorio de Programación Científica/Laboratorios/Github/casoCDD/data_para_validar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>grade</th>\n",
       "      <th>seq_4_avg</th>\n",
       "      <th>quiz_avg</th>\n",
       "      <th>seq_0_avg</th>\n",
       "      <th>seq_1_avg</th>\n",
       "      <th>seq_2_avg</th>\n",
       "      <th>seq_3_avg</th>\n",
       "      <th>duracion_sesion_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>pause_video_mean</th>\n",
       "      <th>pause_video_std</th>\n",
       "      <th>speed_change_video_mean</th>\n",
       "      <th>speed_change_video_std</th>\n",
       "      <th>num_eventos_seq_0</th>\n",
       "      <th>num_eventos_seq_1</th>\n",
       "      <th>num_eventos_seq_2</th>\n",
       "      <th>num_eventos_seq_3</th>\n",
       "      <th>num_eventos_seq_4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.944454</td>\n",
       "      <td>...</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>7.409453</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.674949</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1032</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.410485</td>\n",
       "      <td>...</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>5.957727</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.363137</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1734</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.794893</td>\n",
       "      <td>...</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>10.399863</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2898</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.850690</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.907778</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.008391</td>\n",
       "      <td>...</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>22.487457</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.298351</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>9.352263</td>\n",
       "      <td>...</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>25.263319</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.060275</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>810.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>603</td>\n",
       "      <td>282522</td>\n",
       "      <td>0.940363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.868407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.804222</td>\n",
       "      <td>0.779122</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.003087</td>\n",
       "      <td>...</td>\n",
       "      <td>6.908206</td>\n",
       "      <td>10.864660</td>\n",
       "      <td>0.122678</td>\n",
       "      <td>0.272942</td>\n",
       "      <td>67.602155</td>\n",
       "      <td>244.612931</td>\n",
       "      <td>156.119639</td>\n",
       "      <td>8.036288</td>\n",
       "      <td>3.012096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>604</td>\n",
       "      <td>129478</td>\n",
       "      <td>0.842813</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.813376</td>\n",
       "      <td>0.866209</td>\n",
       "      <td>0.762787</td>\n",
       "      <td>0.704212</td>\n",
       "      <td>0.69011</td>\n",
       "      <td>5.248995</td>\n",
       "      <td>...</td>\n",
       "      <td>9.150560</td>\n",
       "      <td>9.437040</td>\n",
       "      <td>0.200196</td>\n",
       "      <td>0.477776</td>\n",
       "      <td>134.394506</td>\n",
       "      <td>451.265933</td>\n",
       "      <td>186.107700</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.929670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>605</td>\n",
       "      <td>310479</td>\n",
       "      <td>0.839504</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.809557</td>\n",
       "      <td>0.947313</td>\n",
       "      <td>0.703419</td>\n",
       "      <td>0.532586</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.482947</td>\n",
       "      <td>...</td>\n",
       "      <td>5.525875</td>\n",
       "      <td>7.274908</td>\n",
       "      <td>0.106805</td>\n",
       "      <td>0.295753</td>\n",
       "      <td>94.586866</td>\n",
       "      <td>419.706268</td>\n",
       "      <td>135.533134</td>\n",
       "      <td>22.314030</td>\n",
       "      <td>11.318209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>606</td>\n",
       "      <td>168867</td>\n",
       "      <td>0.881915</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852923</td>\n",
       "      <td>0.717063</td>\n",
       "      <td>0.817364</td>\n",
       "      <td>0.902334</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.551731</td>\n",
       "      <td>...</td>\n",
       "      <td>15.414130</td>\n",
       "      <td>18.579293</td>\n",
       "      <td>1.461072</td>\n",
       "      <td>2.026446</td>\n",
       "      <td>127.521237</td>\n",
       "      <td>556.190787</td>\n",
       "      <td>222.634988</td>\n",
       "      <td>29.964003</td>\n",
       "      <td>10.982002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>607</td>\n",
       "      <td>154541</td>\n",
       "      <td>0.935885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.903971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854285</td>\n",
       "      <td>0.979781</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.702868</td>\n",
       "      <td>...</td>\n",
       "      <td>11.687961</td>\n",
       "      <td>17.541553</td>\n",
       "      <td>0.710228</td>\n",
       "      <td>1.122771</td>\n",
       "      <td>150.003533</td>\n",
       "      <td>407.662693</td>\n",
       "      <td>253.674614</td>\n",
       "      <td>18.691391</td>\n",
       "      <td>6.345695</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.1  Unnamed: 0     grade  seq_4_avg  quiz_avg  seq_0_avg  \\\n",
       "0               0           0  1.000000        1.0  0.965517   1.000000   \n",
       "1               1        1032  0.990000        1.0  0.956897   1.000000   \n",
       "2               2        1734  1.000000        1.0  0.965517   1.000000   \n",
       "3               3        2898  0.880000        1.0  0.850690   0.625000   \n",
       "4               4        4203  1.000000        1.0  0.965517   1.000000   \n",
       "..            ...         ...       ...        ...       ...        ...   \n",
       "603           603      282522  0.940363        1.0  0.868407   1.000000   \n",
       "604           604      129478  0.842813        1.0  0.813376   0.866209   \n",
       "605           605      310479  0.839504        1.0  0.809557   0.947313   \n",
       "606           606      168867  0.881915        1.0  0.852923   0.717063   \n",
       "607           607      154541  0.935885        1.0  0.903971   1.000000   \n",
       "\n",
       "     seq_1_avg  seq_2_avg  seq_3_avg  duracion_sesion_avg  ...  \\\n",
       "0     1.000000   1.000000    1.00000             4.944454  ...   \n",
       "1     0.977273   1.000000    1.00000             2.410485  ...   \n",
       "2     1.000000   1.000000    1.00000             3.794893  ...   \n",
       "3     0.909091   0.907778    1.00000             4.008391  ...   \n",
       "4     1.000000   1.000000    1.00000             9.352263  ...   \n",
       "..         ...        ...        ...                  ...  ...   \n",
       "603   0.804222   0.779122    1.00000             5.003087  ...   \n",
       "604   0.762787   0.704212    0.69011             5.248995  ...   \n",
       "605   0.703419   0.532586    1.00000             6.482947  ...   \n",
       "606   0.817364   0.902334    1.00000             5.551731  ...   \n",
       "607   0.854285   0.979781    1.00000             4.702868  ...   \n",
       "\n",
       "     pause_video_mean  pause_video_std  speed_change_video_mean  \\\n",
       "0            8.700000         7.409453                 0.300000   \n",
       "1            4.428571         5.957727                 0.142857   \n",
       "2            7.571429        10.399863                 0.142857   \n",
       "3           13.600000        22.487457                 0.600000   \n",
       "4           15.333333        25.263319                 0.777778   \n",
       "..                ...              ...                      ...   \n",
       "603          6.908206        10.864660                 0.122678   \n",
       "604          9.150560         9.437040                 0.200196   \n",
       "605          5.525875         7.274908                 0.106805   \n",
       "606         15.414130        18.579293                 1.461072   \n",
       "607         11.687961        17.541553                 0.710228   \n",
       "\n",
       "     speed_change_video_std  num_eventos_seq_0  num_eventos_seq_1  \\\n",
       "0                  0.674949          76.000000         384.000000   \n",
       "1                  0.363137          70.000000         168.000000   \n",
       "2                  0.478091         197.000000         346.000000   \n",
       "3                  1.298351         177.000000         466.000000   \n",
       "4                  1.060275         264.000000         810.000000   \n",
       "..                      ...                ...                ...   \n",
       "603                0.272942          67.602155         244.612931   \n",
       "604                0.477776         134.394506         451.265933   \n",
       "605                0.295753          94.586866         419.706268   \n",
       "606                2.026446         127.521237         556.190787   \n",
       "607                1.122771         150.003533         407.662693   \n",
       "\n",
       "     num_eventos_seq_2  num_eventos_seq_3  num_eventos_seq_4  label  \n",
       "0           128.000000          16.000000          20.000000      1  \n",
       "1            90.000000          16.000000           6.000000      1  \n",
       "2           151.000000          47.000000           8.000000      1  \n",
       "3           201.000000          33.000000           9.000000      1  \n",
       "4            80.000000          19.000000          11.000000      0  \n",
       "..                 ...                ...                ...    ...  \n",
       "603         156.119639           8.036288           3.012096      0  \n",
       "604         186.107700          13.000000           2.929670      0  \n",
       "605         135.533134          22.314030          11.318209      0  \n",
       "606         222.634988          29.964003          10.982002      0  \n",
       "607         253.674614          18.691391           6.345695      0  \n",
       "\n",
       "[608 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'grade', 'seq_4_avg', 'quiz_avg',\n",
       "       'seq_0_avg', 'seq_1_avg', 'seq_2_avg', 'seq_3_avg',\n",
       "       'duracion_sesion_avg', 'duracion_sesion_std', 'duracion_EOL',\n",
       "       'num_sesiones_agosto', 'num_sesiones_septiembre',\n",
       "       'num_sesiones_noviembre', 'page_close_mean', 'page_close_std',\n",
       "       'problem_graded_mean', 'problem_graded_std', 'problem_check_mean',\n",
       "       'problem_check_std', 'problem_show_mean', 'problem_show_std',\n",
       "       'seg_prev_mean', 'seg_prev_std', 'seg_next_mean', 'seg_next_std',\n",
       "       'seg_goto_mean', 'seg_goto_std', 'load_video_mean', 'load_video_std',\n",
       "       'play_video_mean', 'play_video_std', 'pause_video_mean',\n",
       "       'pause_video_std', 'speed_change_video_mean', 'speed_change_video_std',\n",
       "       'num_eventos_seq_0', 'num_eventos_seq_1', 'num_eventos_seq_2',\n",
       "       'num_eventos_seq_3', 'num_eventos_seq_4', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entrenamiento.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entrenamiento.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>seq_4_avg</th>\n",
       "      <th>quiz_avg</th>\n",
       "      <th>seq_0_avg</th>\n",
       "      <th>seq_1_avg</th>\n",
       "      <th>seq_2_avg</th>\n",
       "      <th>seq_3_avg</th>\n",
       "      <th>duracion_sesion_avg</th>\n",
       "      <th>duracion_sesion_std</th>\n",
       "      <th>duracion_EOL</th>\n",
       "      <th>...</th>\n",
       "      <th>pause_video_mean</th>\n",
       "      <th>pause_video_std</th>\n",
       "      <th>speed_change_video_mean</th>\n",
       "      <th>speed_change_video_std</th>\n",
       "      <th>num_eventos_seq_0</th>\n",
       "      <th>num_eventos_seq_1</th>\n",
       "      <th>num_eventos_seq_2</th>\n",
       "      <th>num_eventos_seq_3</th>\n",
       "      <th>num_eventos_seq_4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.944454</td>\n",
       "      <td>5.131721</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>7.409453</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.674949</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.990000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.410485</td>\n",
       "      <td>2.627586</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>5.957727</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.363137</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.794893</td>\n",
       "      <td>5.967056</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>10.399863</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.850690</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.907778</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.008391</td>\n",
       "      <td>5.076566</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>22.487457</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.298351</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>9.352263</td>\n",
       "      <td>8.270573</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>25.263319</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.060275</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>810.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>0.940363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.868407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.804222</td>\n",
       "      <td>0.779122</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.003087</td>\n",
       "      <td>7.729962</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.908206</td>\n",
       "      <td>10.864660</td>\n",
       "      <td>0.122678</td>\n",
       "      <td>0.272942</td>\n",
       "      <td>67.602155</td>\n",
       "      <td>244.612931</td>\n",
       "      <td>156.119639</td>\n",
       "      <td>8.036288</td>\n",
       "      <td>3.012096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>0.842813</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.813376</td>\n",
       "      <td>0.866209</td>\n",
       "      <td>0.762787</td>\n",
       "      <td>0.704212</td>\n",
       "      <td>0.69011</td>\n",
       "      <td>5.248995</td>\n",
       "      <td>6.035853</td>\n",
       "      <td>56.394506</td>\n",
       "      <td>...</td>\n",
       "      <td>9.150560</td>\n",
       "      <td>9.437040</td>\n",
       "      <td>0.200196</td>\n",
       "      <td>0.477776</td>\n",
       "      <td>134.394506</td>\n",
       "      <td>451.265933</td>\n",
       "      <td>186.107700</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.929670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>0.839504</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.809557</td>\n",
       "      <td>0.947313</td>\n",
       "      <td>0.703419</td>\n",
       "      <td>0.532586</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.482947</td>\n",
       "      <td>6.920673</td>\n",
       "      <td>53.842985</td>\n",
       "      <td>...</td>\n",
       "      <td>5.525875</td>\n",
       "      <td>7.274908</td>\n",
       "      <td>0.106805</td>\n",
       "      <td>0.295753</td>\n",
       "      <td>94.586866</td>\n",
       "      <td>419.706268</td>\n",
       "      <td>135.533134</td>\n",
       "      <td>22.314030</td>\n",
       "      <td>11.318209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>0.881915</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852923</td>\n",
       "      <td>0.717063</td>\n",
       "      <td>0.817364</td>\n",
       "      <td>0.902334</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.551731</td>\n",
       "      <td>6.395383</td>\n",
       "      <td>55.263499</td>\n",
       "      <td>...</td>\n",
       "      <td>15.414130</td>\n",
       "      <td>18.579293</td>\n",
       "      <td>1.461072</td>\n",
       "      <td>2.026446</td>\n",
       "      <td>127.521237</td>\n",
       "      <td>556.190787</td>\n",
       "      <td>222.634988</td>\n",
       "      <td>29.964003</td>\n",
       "      <td>10.982002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>0.935885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.903971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854285</td>\n",
       "      <td>0.979781</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.702868</td>\n",
       "      <td>4.789794</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.687961</td>\n",
       "      <td>17.541553</td>\n",
       "      <td>0.710228</td>\n",
       "      <td>1.122771</td>\n",
       "      <td>150.003533</td>\n",
       "      <td>407.662693</td>\n",
       "      <td>253.674614</td>\n",
       "      <td>18.691391</td>\n",
       "      <td>6.345695</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        grade  seq_4_avg  quiz_avg  seq_0_avg  seq_1_avg  seq_2_avg  \\\n",
       "0    1.000000        1.0  0.965517   1.000000   1.000000   1.000000   \n",
       "1    0.990000        1.0  0.956897   1.000000   0.977273   1.000000   \n",
       "2    1.000000        1.0  0.965517   1.000000   1.000000   1.000000   \n",
       "3    0.880000        1.0  0.850690   0.625000   0.909091   0.907778   \n",
       "4    1.000000        1.0  0.965517   1.000000   1.000000   1.000000   \n",
       "..        ...        ...       ...        ...        ...        ...   \n",
       "603  0.940363        1.0  0.868407   1.000000   0.804222   0.779122   \n",
       "604  0.842813        1.0  0.813376   0.866209   0.762787   0.704212   \n",
       "605  0.839504        1.0  0.809557   0.947313   0.703419   0.532586   \n",
       "606  0.881915        1.0  0.852923   0.717063   0.817364   0.902334   \n",
       "607  0.935885        1.0  0.903971   1.000000   0.854285   0.979781   \n",
       "\n",
       "     seq_3_avg  duracion_sesion_avg  duracion_sesion_std  duracion_EOL  ...  \\\n",
       "0      1.00000             4.944454             5.131721     64.000000  ...   \n",
       "1      1.00000             2.410485             2.627586     60.000000  ...   \n",
       "2      1.00000             3.794893             5.967056     59.000000  ...   \n",
       "3      1.00000             4.008391             5.076566     58.000000  ...   \n",
       "4      1.00000             9.352263             8.270573     58.000000  ...   \n",
       "..         ...                  ...                  ...           ...  ...   \n",
       "603    1.00000             5.003087             7.729962     52.000000  ...   \n",
       "604    0.69011             5.248995             6.035853     56.394506  ...   \n",
       "605    1.00000             6.482947             6.920673     53.842985  ...   \n",
       "606    1.00000             5.551731             6.395383     55.263499  ...   \n",
       "607    1.00000             4.702868             4.789794     59.000000  ...   \n",
       "\n",
       "     pause_video_mean  pause_video_std  speed_change_video_mean  \\\n",
       "0            8.700000         7.409453                 0.300000   \n",
       "1            4.428571         5.957727                 0.142857   \n",
       "2            7.571429        10.399863                 0.142857   \n",
       "3           13.600000        22.487457                 0.600000   \n",
       "4           15.333333        25.263319                 0.777778   \n",
       "..                ...              ...                      ...   \n",
       "603          6.908206        10.864660                 0.122678   \n",
       "604          9.150560         9.437040                 0.200196   \n",
       "605          5.525875         7.274908                 0.106805   \n",
       "606         15.414130        18.579293                 1.461072   \n",
       "607         11.687961        17.541553                 0.710228   \n",
       "\n",
       "     speed_change_video_std  num_eventos_seq_0  num_eventos_seq_1  \\\n",
       "0                  0.674949          76.000000         384.000000   \n",
       "1                  0.363137          70.000000         168.000000   \n",
       "2                  0.478091         197.000000         346.000000   \n",
       "3                  1.298351         177.000000         466.000000   \n",
       "4                  1.060275         264.000000         810.000000   \n",
       "..                      ...                ...                ...   \n",
       "603                0.272942          67.602155         244.612931   \n",
       "604                0.477776         134.394506         451.265933   \n",
       "605                0.295753          94.586866         419.706268   \n",
       "606                2.026446         127.521237         556.190787   \n",
       "607                1.122771         150.003533         407.662693   \n",
       "\n",
       "     num_eventos_seq_2  num_eventos_seq_3  num_eventos_seq_4  label  \n",
       "0           128.000000          16.000000          20.000000      1  \n",
       "1            90.000000          16.000000           6.000000      1  \n",
       "2           151.000000          47.000000           8.000000      1  \n",
       "3           201.000000          33.000000           9.000000      1  \n",
       "4            80.000000          19.000000          11.000000      0  \n",
       "..                 ...                ...                ...    ...  \n",
       "603         156.119639           8.036288           3.012096      0  \n",
       "604         186.107700          13.000000           2.929670      0  \n",
       "605         135.533134          22.314030          11.318209      0  \n",
       "606         222.634988          29.964003          10.982002      0  \n",
       "607         253.674614          18.691391           6.345695      0  \n",
       "\n",
       "[608 rows x 41 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Establecer la semilla en TensorFlow para la reproducibilidad\n",
    "tf.random.set_seed(314159)\n",
    "\n",
    "# Establecer la semilla para el generador de números aleatorios de numpy (si se usa)\n",
    "np.random.seed(314159)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_entrenamiento.drop(columns=['label'])  # Características\n",
    "y = df_entrenamiento['label']  # Etiquetas\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=314159, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Crea un objeto StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Ajusta el scaler a tus datos de entrenamiento y luego transforma los datos\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transforma también los datos de prueba usando el mismo scaler\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "input_shape = [X_train.shape[1]]\n",
    "model = keras.Sequential([\n",
    "    layers.BatchNormalization(input_shape=input_shape),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256, activation='relu'), \n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=20,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "35/35 [==============================] - 5s 24ms/step - loss: 0.9262 - accuracy: 0.5430 - val_loss: 0.6961 - val_accuracy: 0.5082\n",
      "Epoch 2/500\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.7173 - accuracy: 0.6782 - val_loss: 0.6846 - val_accuracy: 0.4918\n",
      "Epoch 3/500\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.6309 - accuracy: 0.6746 - val_loss: 0.6641 - val_accuracy: 0.6393\n",
      "Epoch 4/500\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.5807 - accuracy: 0.7112 - val_loss: 0.6618 - val_accuracy: 0.5574\n",
      "Epoch 5/500\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.5236 - accuracy: 0.7514 - val_loss: 0.6519 - val_accuracy: 0.6066\n",
      "Epoch 6/500\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.4820 - accuracy: 0.7733 - val_loss: 0.6884 - val_accuracy: 0.5574\n",
      "Epoch 7/500\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.4573 - accuracy: 0.7916 - val_loss: 0.6490 - val_accuracy: 0.6066\n",
      "Epoch 8/500\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.4764 - accuracy: 0.7788 - val_loss: 0.6808 - val_accuracy: 0.5738\n",
      "Epoch 9/500\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.4509 - accuracy: 0.7952 - val_loss: 0.6087 - val_accuracy: 0.6230\n",
      "Epoch 10/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.4171 - accuracy: 0.8245 - val_loss: 0.5525 - val_accuracy: 0.6721\n",
      "Epoch 11/500\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.3924 - accuracy: 0.8172 - val_loss: 0.5463 - val_accuracy: 0.6557\n",
      "Epoch 12/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.3799 - accuracy: 0.8227 - val_loss: 0.4484 - val_accuracy: 0.8197\n",
      "Epoch 13/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.4044 - accuracy: 0.8263 - val_loss: 0.3871 - val_accuracy: 0.8689\n",
      "Epoch 14/500\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.4146 - accuracy: 0.8099 - val_loss: 0.3898 - val_accuracy: 0.8361\n",
      "Epoch 15/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.3897 - accuracy: 0.8300 - val_loss: 0.3478 - val_accuracy: 0.8525\n",
      "Epoch 16/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.3486 - accuracy: 0.8483 - val_loss: 0.3801 - val_accuracy: 0.8361\n",
      "Epoch 17/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3848 - accuracy: 0.8190 - val_loss: 0.3832 - val_accuracy: 0.8361\n",
      "Epoch 18/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3586 - accuracy: 0.8483 - val_loss: 0.3597 - val_accuracy: 0.8361\n",
      "Epoch 19/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3687 - accuracy: 0.8501 - val_loss: 0.3192 - val_accuracy: 0.9180\n",
      "Epoch 20/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.2957 - accuracy: 0.8812 - val_loss: 0.3190 - val_accuracy: 0.8689\n",
      "Epoch 21/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3492 - accuracy: 0.8318 - val_loss: 0.2878 - val_accuracy: 0.9016\n",
      "Epoch 22/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.2861 - accuracy: 0.8848 - val_loss: 0.2797 - val_accuracy: 0.9344\n",
      "Epoch 23/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3488 - accuracy: 0.8501 - val_loss: 0.2542 - val_accuracy: 0.9344\n",
      "Epoch 24/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.3450 - accuracy: 0.8556 - val_loss: 0.2800 - val_accuracy: 0.8852\n",
      "Epoch 25/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3020 - accuracy: 0.8665 - val_loss: 0.2736 - val_accuracy: 0.9016\n",
      "Epoch 26/500\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.3086 - accuracy: 0.8739 - val_loss: 0.2869 - val_accuracy: 0.8852\n",
      "Epoch 27/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.3112 - accuracy: 0.8793 - val_loss: 0.3070 - val_accuracy: 0.8852\n",
      "Epoch 28/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.2819 - accuracy: 0.8775 - val_loss: 0.2794 - val_accuracy: 0.9016\n",
      "Epoch 29/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.2937 - accuracy: 0.8775 - val_loss: 0.3584 - val_accuracy: 0.8361\n",
      "Epoch 30/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.2579 - accuracy: 0.8995 - val_loss: 0.2979 - val_accuracy: 0.8689\n",
      "Epoch 31/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.2662 - accuracy: 0.8921 - val_loss: 0.2619 - val_accuracy: 0.9016\n",
      "Epoch 32/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.2832 - accuracy: 0.8720 - val_loss: 0.2709 - val_accuracy: 0.8852\n",
      "Epoch 33/500\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.2564 - accuracy: 0.8885 - val_loss: 0.2807 - val_accuracy: 0.9180\n",
      "Epoch 34/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.2712 - accuracy: 0.8958 - val_loss: 0.3427 - val_accuracy: 0.8525\n",
      "Epoch 35/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.3192 - accuracy: 0.8611 - val_loss: 0.2979 - val_accuracy: 0.9016\n",
      "Epoch 36/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2847 - accuracy: 0.8647 - val_loss: 0.3335 - val_accuracy: 0.8689\n",
      "Epoch 37/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2788 - accuracy: 0.8885 - val_loss: 0.3145 - val_accuracy: 0.8689\n",
      "Epoch 38/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2529 - accuracy: 0.9049 - val_loss: 0.2914 - val_accuracy: 0.8525\n",
      "Epoch 39/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.2376 - accuracy: 0.9049 - val_loss: 0.2524 - val_accuracy: 0.9180\n",
      "Epoch 40/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.2687 - accuracy: 0.8867 - val_loss: 0.2716 - val_accuracy: 0.9016\n",
      "Epoch 41/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2536 - accuracy: 0.9068 - val_loss: 0.3714 - val_accuracy: 0.8852\n",
      "Epoch 42/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2334 - accuracy: 0.8995 - val_loss: 0.3656 - val_accuracy: 0.8852\n",
      "Epoch 43/500\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.2759 - accuracy: 0.9049 - val_loss: 0.3241 - val_accuracy: 0.8852\n",
      "Epoch 44/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.3213 - accuracy: 0.8720 - val_loss: 0.3244 - val_accuracy: 0.8852\n",
      "Epoch 45/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.3023 - accuracy: 0.8665 - val_loss: 0.3200 - val_accuracy: 0.8852\n",
      "Epoch 46/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2634 - accuracy: 0.8812 - val_loss: 0.3345 - val_accuracy: 0.8852\n",
      "Epoch 47/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.2299 - accuracy: 0.9086 - val_loss: 0.3396 - val_accuracy: 0.8852\n",
      "Epoch 48/500\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.2876 - accuracy: 0.8958 - val_loss: 0.2666 - val_accuracy: 0.9016\n",
      "Epoch 49/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2428 - accuracy: 0.9104 - val_loss: 0.2548 - val_accuracy: 0.9016\n",
      "Epoch 50/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.2040 - accuracy: 0.9232 - val_loss: 0.3115 - val_accuracy: 0.9180\n",
      "Epoch 51/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2261 - accuracy: 0.9031 - val_loss: 0.2861 - val_accuracy: 0.9344\n",
      "Epoch 52/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2008 - accuracy: 0.9177 - val_loss: 0.3121 - val_accuracy: 0.9016\n",
      "Epoch 53/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.2427 - accuracy: 0.9031 - val_loss: 0.3695 - val_accuracy: 0.8689\n",
      "Epoch 54/500\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.2789 - accuracy: 0.8793 - val_loss: 0.3180 - val_accuracy: 0.8689\n",
      "Epoch 55/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2658 - accuracy: 0.8812 - val_loss: 0.2778 - val_accuracy: 0.9180\n",
      "Epoch 56/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.1902 - accuracy: 0.9177 - val_loss: 0.2455 - val_accuracy: 0.9180\n",
      "Epoch 57/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.2401 - accuracy: 0.8903 - val_loss: 0.2531 - val_accuracy: 0.9016\n",
      "Epoch 58/500\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.2315 - accuracy: 0.9104 - val_loss: 0.2881 - val_accuracy: 0.8689\n",
      "Epoch 59/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2937 - accuracy: 0.8757 - val_loss: 0.2572 - val_accuracy: 0.8852\n",
      "Epoch 60/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2602 - accuracy: 0.9068 - val_loss: 0.2178 - val_accuracy: 0.9016\n",
      "Epoch 61/500\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.2499 - accuracy: 0.8976 - val_loss: 0.2022 - val_accuracy: 0.9180\n",
      "Epoch 62/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2124 - accuracy: 0.9068 - val_loss: 0.2284 - val_accuracy: 0.9016\n",
      "Epoch 63/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.1979 - accuracy: 0.9250 - val_loss: 0.2218 - val_accuracy: 0.9180\n",
      "Epoch 64/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.2508 - accuracy: 0.8903 - val_loss: 0.2022 - val_accuracy: 0.9016\n",
      "Epoch 65/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.2342 - accuracy: 0.9049 - val_loss: 0.2355 - val_accuracy: 0.9016\n",
      "Epoch 66/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.2114 - accuracy: 0.9177 - val_loss: 0.2126 - val_accuracy: 0.9016\n",
      "Epoch 67/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.1946 - accuracy: 0.9214 - val_loss: 0.2154 - val_accuracy: 0.9180\n",
      "Epoch 68/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2344 - accuracy: 0.8995 - val_loss: 0.2103 - val_accuracy: 0.9180\n",
      "Epoch 69/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.2250 - accuracy: 0.9031 - val_loss: 0.2347 - val_accuracy: 0.9180\n",
      "Epoch 70/500\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.2116 - accuracy: 0.9086 - val_loss: 0.1954 - val_accuracy: 0.9344\n",
      "Epoch 71/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.2265 - accuracy: 0.9068 - val_loss: 0.2259 - val_accuracy: 0.9180\n",
      "Epoch 72/500\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.2146 - accuracy: 0.9141 - val_loss: 0.2021 - val_accuracy: 0.9016\n",
      "Epoch 73/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.1857 - accuracy: 0.9232 - val_loss: 0.1994 - val_accuracy: 0.9180\n",
      "Epoch 74/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.1853 - accuracy: 0.9196 - val_loss: 0.2337 - val_accuracy: 0.9180\n",
      "Epoch 75/500\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.2160 - accuracy: 0.9141 - val_loss: 0.3141 - val_accuracy: 0.9016\n",
      "Epoch 76/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2128 - accuracy: 0.9068 - val_loss: 0.3424 - val_accuracy: 0.8689\n",
      "Epoch 77/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.2290 - accuracy: 0.8995 - val_loss: 0.3512 - val_accuracy: 0.8852\n",
      "Epoch 78/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2297 - accuracy: 0.9104 - val_loss: 0.3031 - val_accuracy: 0.9016\n",
      "Epoch 79/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2189 - accuracy: 0.9104 - val_loss: 0.3382 - val_accuracy: 0.8852\n",
      "Epoch 80/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2313 - accuracy: 0.8995 - val_loss: 0.2962 - val_accuracy: 0.8852\n",
      "Epoch 81/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.2310 - accuracy: 0.8885 - val_loss: 0.3058 - val_accuracy: 0.8852\n",
      "Epoch 82/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2210 - accuracy: 0.9141 - val_loss: 0.2664 - val_accuracy: 0.9016\n",
      "Epoch 83/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2354 - accuracy: 0.9086 - val_loss: 0.2645 - val_accuracy: 0.9016\n",
      "Epoch 84/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.1707 - accuracy: 0.9232 - val_loss: 0.2348 - val_accuracy: 0.9180\n",
      "Epoch 85/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.2147 - accuracy: 0.9214 - val_loss: 0.2003 - val_accuracy: 0.9180\n",
      "Epoch 86/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2294 - accuracy: 0.9196 - val_loss: 0.2064 - val_accuracy: 0.9180\n",
      "Epoch 87/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.1951 - accuracy: 0.9031 - val_loss: 0.2021 - val_accuracy: 0.8852\n",
      "Epoch 88/500\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.1902 - accuracy: 0.9232 - val_loss: 0.2460 - val_accuracy: 0.8852\n",
      "Epoch 89/500\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2316 - accuracy: 0.9068 - val_loss: 0.2048 - val_accuracy: 0.9180\n",
      "Epoch 90/500\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.2156 - accuracy: 0.9086 - val_loss: 0.2795 - val_accuracy: 0.9180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d247e69dd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=500, batch_size=16, validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1954 - accuracy: 0.9344\n",
      "Exactitud en datos de prueba: 0.9344262480735779\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Exactitud en datos de prueba:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.93      0.93      0.93        30\n",
      "     Clase 1       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.93        61\n",
      "   macro avg       0.93      0.93      0.93        61\n",
      "weighted avg       0.93      0.93      0.93        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Supongamos que ya tienes un modelo entrenado\n",
    "# Reemplaza esto con tus datos reales\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convierte las predicciones en etiquetas binarias aplicando un umbral (por ejemplo, 0.5)\n",
    "threshold = 0.5\n",
    "y_pred_binary = (y_pred > threshold).astype(int)\n",
    "\n",
    "# Calcula el informe de clasificación\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred_binary, target_names=[\"Clase 0\", \"Clase 1\"])  # Reemplaza con las etiquetas reales\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab_6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
